[2022-06-07 00:00:10,125] {processor.py:163} INFO - Started process (PID=654943) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:00:10,126] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:00:10,126] {logging_mixin.py:109} INFO - [2022-06-07 00:00:10,126] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:00:40,134] {logging_mixin.py:109} INFO - [2022-06-07 00:00:40,133] {timeout.py:36} ERROR - Process timed out, PID: 654943
[2022-06-07 00:00:40,134] {logging_mixin.py:109} INFO - [2022-06-07 00:00:40,134] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 654943
[2022-06-07 00:00:40,134] {logging_mixin.py:109} INFO - [2022-06-07 00:00:40,134] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:00:40,135] {logging_mixin.py:109} INFO - [2022-06-07 00:00:40,134] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 654943

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:00:40,135] {logging_mixin.py:109} INFO - [2022-06-07 00:00:40,135] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:00:40,135] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:00:40,148] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 00:01:10,302] {processor.py:163} INFO - Started process (PID=656038) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:01:10,302] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:01:10,302] {logging_mixin.py:109} INFO - [2022-06-07 00:01:10,302] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:01:40,311] {logging_mixin.py:109} INFO - [2022-06-07 00:01:40,311] {timeout.py:36} ERROR - Process timed out, PID: 656038
[2022-06-07 00:01:40,312] {logging_mixin.py:109} INFO - [2022-06-07 00:01:40,311] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 656038
[2022-06-07 00:01:40,312] {logging_mixin.py:109} INFO - [2022-06-07 00:01:40,312] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:01:40,312] {logging_mixin.py:109} INFO - [2022-06-07 00:01:40,312] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 656038

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:01:40,313] {logging_mixin.py:109} INFO - [2022-06-07 00:01:40,313] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:01:40,313] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:01:40,325] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 00:02:10,563] {processor.py:163} INFO - Started process (PID=657127) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:02:10,564] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:02:10,564] {logging_mixin.py:109} INFO - [2022-06-07 00:02:10,564] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:02:40,566] {logging_mixin.py:109} INFO - [2022-06-07 00:02:40,566] {timeout.py:36} ERROR - Process timed out, PID: 657127
[2022-06-07 00:02:40,567] {logging_mixin.py:109} INFO - [2022-06-07 00:02:40,566] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 657127
[2022-06-07 00:02:40,567] {logging_mixin.py:109} INFO - [2022-06-07 00:02:40,567] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:02:40,567] {logging_mixin.py:109} INFO - [2022-06-07 00:02:40,567] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 657127

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:02:40,568] {logging_mixin.py:109} INFO - [2022-06-07 00:02:40,568] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:02:40,568] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:02:40,581] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 00:03:10,926] {processor.py:163} INFO - Started process (PID=658222) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:03:10,927] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:03:10,927] {logging_mixin.py:109} INFO - [2022-06-07 00:03:10,927] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:03:40,930] {logging_mixin.py:109} INFO - [2022-06-07 00:03:40,930] {timeout.py:36} ERROR - Process timed out, PID: 658222
[2022-06-07 00:03:40,931] {logging_mixin.py:109} INFO - [2022-06-07 00:03:40,931] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 658222
[2022-06-07 00:03:40,931] {logging_mixin.py:109} INFO - [2022-06-07 00:03:40,931] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:03:40,932] {logging_mixin.py:109} INFO - [2022-06-07 00:03:40,931] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 658222

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:03:40,932] {logging_mixin.py:109} INFO - [2022-06-07 00:03:40,932] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:03:40,932] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:03:40,944] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 00:04:11,149] {processor.py:163} INFO - Started process (PID=659315) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:04:11,150] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:04:11,150] {logging_mixin.py:109} INFO - [2022-06-07 00:04:11,150] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:04:41,156] {logging_mixin.py:109} INFO - [2022-06-07 00:04:41,156] {timeout.py:36} ERROR - Process timed out, PID: 659315
[2022-06-07 00:04:41,157] {logging_mixin.py:109} INFO - [2022-06-07 00:04:41,156] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 659315
[2022-06-07 00:04:41,157] {logging_mixin.py:109} INFO - [2022-06-07 00:04:41,157] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:04:41,157] {logging_mixin.py:109} INFO - [2022-06-07 00:04:41,157] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 659315

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:04:41,158] {logging_mixin.py:109} INFO - [2022-06-07 00:04:41,157] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:04:41,158] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:04:41,170] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 00:05:11,391] {processor.py:163} INFO - Started process (PID=660409) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:05:11,392] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:05:11,392] {logging_mixin.py:109} INFO - [2022-06-07 00:05:11,392] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:05:41,401] {logging_mixin.py:109} INFO - [2022-06-07 00:05:41,400] {timeout.py:36} ERROR - Process timed out, PID: 660409
[2022-06-07 00:05:41,401] {logging_mixin.py:109} INFO - [2022-06-07 00:05:41,401] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 660409
[2022-06-07 00:05:41,401] {logging_mixin.py:109} INFO - [2022-06-07 00:05:41,401] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:05:41,402] {logging_mixin.py:109} INFO - [2022-06-07 00:05:41,402] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 660409

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:05:41,402] {logging_mixin.py:109} INFO - [2022-06-07 00:05:41,402] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:05:41,403] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:05:41,414] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 00:06:11,684] {processor.py:163} INFO - Started process (PID=661502) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:06:11,684] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:06:11,684] {logging_mixin.py:109} INFO - [2022-06-07 00:06:11,684] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:06:41,686] {logging_mixin.py:109} INFO - [2022-06-07 00:06:41,686] {timeout.py:36} ERROR - Process timed out, PID: 661502
[2022-06-07 00:06:41,687] {logging_mixin.py:109} INFO - [2022-06-07 00:06:41,686] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 661502
[2022-06-07 00:06:41,687] {logging_mixin.py:109} INFO - [2022-06-07 00:06:41,687] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:06:41,687] {logging_mixin.py:109} INFO - [2022-06-07 00:06:41,687] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 661502

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:06:41,688] {logging_mixin.py:109} INFO - [2022-06-07 00:06:41,687] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:06:41,688] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:06:41,699] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:07:11,944] {processor.py:163} INFO - Started process (PID=662594) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:07:11,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:07:11,945] {logging_mixin.py:109} INFO - [2022-06-07 00:07:11,944] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:07:41,946] {logging_mixin.py:109} INFO - [2022-06-07 00:07:41,946] {timeout.py:36} ERROR - Process timed out, PID: 662594
[2022-06-07 00:07:41,947] {logging_mixin.py:109} INFO - [2022-06-07 00:07:41,946] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 662594
[2022-06-07 00:07:41,947] {logging_mixin.py:109} INFO - [2022-06-07 00:07:41,947] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:07:41,947] {logging_mixin.py:109} INFO - [2022-06-07 00:07:41,947] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 662594

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:07:41,948] {logging_mixin.py:109} INFO - [2022-06-07 00:07:41,947] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:07:41,948] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:07:41,959] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:08:12,261] {processor.py:163} INFO - Started process (PID=663689) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:08:12,261] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:08:12,261] {logging_mixin.py:109} INFO - [2022-06-07 00:08:12,261] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:08:42,263] {logging_mixin.py:109} INFO - [2022-06-07 00:08:42,262] {timeout.py:36} ERROR - Process timed out, PID: 663689
[2022-06-07 00:08:42,263] {logging_mixin.py:109} INFO - [2022-06-07 00:08:42,263] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 663689
[2022-06-07 00:08:42,263] {logging_mixin.py:109} INFO - [2022-06-07 00:08:42,263] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:08:42,264] {logging_mixin.py:109} INFO - [2022-06-07 00:08:42,264] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 663689

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:08:42,264] {logging_mixin.py:109} INFO - [2022-06-07 00:08:42,264] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:08:42,265] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:08:42,277] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:09:12,608] {processor.py:163} INFO - Started process (PID=664781) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:09:12,608] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:09:12,609] {logging_mixin.py:109} INFO - [2022-06-07 00:09:12,609] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:09:42,615] {logging_mixin.py:109} INFO - [2022-06-07 00:09:42,614] {timeout.py:36} ERROR - Process timed out, PID: 664781
[2022-06-07 00:09:42,615] {logging_mixin.py:109} INFO - [2022-06-07 00:09:42,615] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 664781
[2022-06-07 00:09:42,615] {logging_mixin.py:109} INFO - [2022-06-07 00:09:42,615] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:09:42,616] {logging_mixin.py:109} INFO - [2022-06-07 00:09:42,615] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 664781

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:09:42,616] {logging_mixin.py:109} INFO - [2022-06-07 00:09:42,616] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:09:42,616] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:09:42,628] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 00:10:12,914] {processor.py:163} INFO - Started process (PID=665875) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:10:12,914] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:10:12,915] {logging_mixin.py:109} INFO - [2022-06-07 00:10:12,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:10:42,919] {logging_mixin.py:109} INFO - [2022-06-07 00:10:42,918] {timeout.py:36} ERROR - Process timed out, PID: 665875
[2022-06-07 00:10:42,919] {logging_mixin.py:109} INFO - [2022-06-07 00:10:42,919] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 665875
[2022-06-07 00:10:42,919] {logging_mixin.py:109} INFO - [2022-06-07 00:10:42,919] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:10:42,920] {logging_mixin.py:109} INFO - [2022-06-07 00:10:42,919] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 665875

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:10:42,920] {logging_mixin.py:109} INFO - [2022-06-07 00:10:42,920] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:10:42,920] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:10:42,932] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 00:11:13,224] {processor.py:163} INFO - Started process (PID=666967) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:11:13,224] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:11:13,225] {logging_mixin.py:109} INFO - [2022-06-07 00:11:13,225] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:11:43,226] {logging_mixin.py:109} INFO - [2022-06-07 00:11:43,225] {timeout.py:36} ERROR - Process timed out, PID: 666967
[2022-06-07 00:11:43,226] {logging_mixin.py:109} INFO - [2022-06-07 00:11:43,226] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 666967
[2022-06-07 00:11:43,227] {logging_mixin.py:109} INFO - [2022-06-07 00:11:43,226] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:11:43,227] {logging_mixin.py:109} INFO - [2022-06-07 00:11:43,227] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 666967

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:11:43,227] {logging_mixin.py:109} INFO - [2022-06-07 00:11:43,227] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:11:43,228] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:11:43,240] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:12:13,456] {processor.py:163} INFO - Started process (PID=668061) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:12:13,456] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:12:13,456] {logging_mixin.py:109} INFO - [2022-06-07 00:12:13,456] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:12:43,458] {logging_mixin.py:109} INFO - [2022-06-07 00:12:43,458] {timeout.py:36} ERROR - Process timed out, PID: 668061
[2022-06-07 00:12:43,459] {logging_mixin.py:109} INFO - [2022-06-07 00:12:43,458] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 668061
[2022-06-07 00:12:43,459] {logging_mixin.py:109} INFO - [2022-06-07 00:12:43,459] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:12:43,460] {logging_mixin.py:109} INFO - [2022-06-07 00:12:43,459] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 668061

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:12:43,460] {logging_mixin.py:109} INFO - [2022-06-07 00:12:43,460] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:12:43,460] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:12:43,472] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:13:13,732] {processor.py:163} INFO - Started process (PID=669154) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:13:13,732] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:13:13,733] {logging_mixin.py:109} INFO - [2022-06-07 00:13:13,733] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:13:43,734] {logging_mixin.py:109} INFO - [2022-06-07 00:13:43,734] {timeout.py:36} ERROR - Process timed out, PID: 669154
[2022-06-07 00:13:43,735] {logging_mixin.py:109} INFO - [2022-06-07 00:13:43,734] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 669154
[2022-06-07 00:13:43,735] {logging_mixin.py:109} INFO - [2022-06-07 00:13:43,735] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:13:43,736] {logging_mixin.py:109} INFO - [2022-06-07 00:13:43,735] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 669154

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:13:43,736] {logging_mixin.py:109} INFO - [2022-06-07 00:13:43,736] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:13:43,736] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:13:43,748] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:14:13,801] {processor.py:163} INFO - Started process (PID=670216) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:14:13,802] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:14:13,802] {logging_mixin.py:109} INFO - [2022-06-07 00:14:13,802] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:14:43,804] {logging_mixin.py:109} INFO - [2022-06-07 00:14:43,803] {timeout.py:36} ERROR - Process timed out, PID: 670216
[2022-06-07 00:14:43,804] {logging_mixin.py:109} INFO - [2022-06-07 00:14:43,804] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 670216
[2022-06-07 00:14:43,804] {logging_mixin.py:109} INFO - [2022-06-07 00:14:43,804] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:14:43,805] {logging_mixin.py:109} INFO - [2022-06-07 00:14:43,805] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 670216

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:14:43,805] {logging_mixin.py:109} INFO - [2022-06-07 00:14:43,805] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:14:43,806] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:14:43,818] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:15:14,386] {processor.py:163} INFO - Started process (PID=671277) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:15:14,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:15:14,387] {logging_mixin.py:109} INFO - [2022-06-07 00:15:14,387] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:15:44,388] {logging_mixin.py:109} INFO - [2022-06-07 00:15:44,388] {timeout.py:36} ERROR - Process timed out, PID: 671277
[2022-06-07 00:15:44,389] {logging_mixin.py:109} INFO - [2022-06-07 00:15:44,389] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 671277
[2022-06-07 00:15:44,389] {logging_mixin.py:109} INFO - [2022-06-07 00:15:44,389] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:15:44,390] {logging_mixin.py:109} INFO - [2022-06-07 00:15:44,389] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 671277

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:15:44,390] {logging_mixin.py:109} INFO - [2022-06-07 00:15:44,390] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:15:44,390] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:15:44,402] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:16:14,610] {processor.py:163} INFO - Started process (PID=672370) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:16:14,610] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:16:14,611] {logging_mixin.py:109} INFO - [2022-06-07 00:16:14,611] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:16:44,612] {logging_mixin.py:109} INFO - [2022-06-07 00:16:44,611] {timeout.py:36} ERROR - Process timed out, PID: 672370
[2022-06-07 00:16:44,612] {logging_mixin.py:109} INFO - [2022-06-07 00:16:44,612] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 672370
[2022-06-07 00:16:44,612] {logging_mixin.py:109} INFO - [2022-06-07 00:16:44,612] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:16:44,613] {logging_mixin.py:109} INFO - [2022-06-07 00:16:44,612] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 672370

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:16:44,613] {logging_mixin.py:109} INFO - [2022-06-07 00:16:44,613] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:16:44,613] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:16:44,626] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:17:14,980] {processor.py:163} INFO - Started process (PID=673464) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:17:14,980] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:17:14,980] {logging_mixin.py:109} INFO - [2022-06-07 00:17:14,980] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:17:44,981] {logging_mixin.py:109} INFO - [2022-06-07 00:17:44,981] {timeout.py:36} ERROR - Process timed out, PID: 673464
[2022-06-07 00:17:44,982] {logging_mixin.py:109} INFO - [2022-06-07 00:17:44,981] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 673464
[2022-06-07 00:17:44,982] {logging_mixin.py:109} INFO - [2022-06-07 00:17:44,982] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:17:44,982] {logging_mixin.py:109} INFO - [2022-06-07 00:17:44,982] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 673464

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:17:44,983] {logging_mixin.py:109} INFO - [2022-06-07 00:17:44,982] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:17:44,983] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:17:44,994] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 00:18:15,284] {processor.py:163} INFO - Started process (PID=674557) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:18:15,284] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:18:15,285] {logging_mixin.py:109} INFO - [2022-06-07 00:18:15,285] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:18:45,293] {logging_mixin.py:109} INFO - [2022-06-07 00:18:45,293] {timeout.py:36} ERROR - Process timed out, PID: 674557
[2022-06-07 00:18:45,294] {logging_mixin.py:109} INFO - [2022-06-07 00:18:45,294] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 674557
[2022-06-07 00:18:45,294] {logging_mixin.py:109} INFO - [2022-06-07 00:18:45,294] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:18:45,295] {logging_mixin.py:109} INFO - [2022-06-07 00:18:45,294] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 674557

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:18:45,295] {logging_mixin.py:109} INFO - [2022-06-07 00:18:45,295] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:18:45,295] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:18:45,307] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 00:19:15,610] {processor.py:163} INFO - Started process (PID=675651) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:19:15,611] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:19:15,611] {logging_mixin.py:109} INFO - [2022-06-07 00:19:15,611] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:19:45,613] {logging_mixin.py:109} INFO - [2022-06-07 00:19:45,613] {timeout.py:36} ERROR - Process timed out, PID: 675651
[2022-06-07 00:19:45,614] {logging_mixin.py:109} INFO - [2022-06-07 00:19:45,613] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 675651
[2022-06-07 00:19:45,614] {logging_mixin.py:109} INFO - [2022-06-07 00:19:45,614] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:19:45,617] {logging_mixin.py:109} INFO - [2022-06-07 00:19:45,614] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 675651

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:19:45,618] {logging_mixin.py:109} INFO - [2022-06-07 00:19:45,618] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:19:45,618] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:19:45,629] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 00:20:16,020] {processor.py:163} INFO - Started process (PID=676745) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:20:16,021] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:20:16,021] {logging_mixin.py:109} INFO - [2022-06-07 00:20:16,021] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:20:46,025] {logging_mixin.py:109} INFO - [2022-06-07 00:20:46,025] {timeout.py:36} ERROR - Process timed out, PID: 676745
[2022-06-07 00:20:46,026] {logging_mixin.py:109} INFO - [2022-06-07 00:20:46,025] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 676745
[2022-06-07 00:20:46,026] {logging_mixin.py:109} INFO - [2022-06-07 00:20:46,026] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:20:46,026] {logging_mixin.py:109} INFO - [2022-06-07 00:20:46,026] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 676745

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:20:46,027] {logging_mixin.py:109} INFO - [2022-06-07 00:20:46,026] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:20:46,027] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:20:46,039] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 00:21:16,062] {processor.py:163} INFO - Started process (PID=677839) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:21:16,062] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:21:16,062] {logging_mixin.py:109} INFO - [2022-06-07 00:21:16,062] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:21:46,064] {logging_mixin.py:109} INFO - [2022-06-07 00:21:46,064] {timeout.py:36} ERROR - Process timed out, PID: 677839
[2022-06-07 00:21:46,065] {logging_mixin.py:109} INFO - [2022-06-07 00:21:46,065] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 677839
[2022-06-07 00:21:46,065] {logging_mixin.py:109} INFO - [2022-06-07 00:21:46,065] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:21:46,066] {logging_mixin.py:109} INFO - [2022-06-07 00:21:46,065] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 677839

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:21:46,066] {logging_mixin.py:109} INFO - [2022-06-07 00:21:46,066] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:21:46,066] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:21:46,078] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:22:16,141] {processor.py:163} INFO - Started process (PID=678932) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:22:16,141] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:22:16,142] {logging_mixin.py:109} INFO - [2022-06-07 00:22:16,142] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:22:46,143] {logging_mixin.py:109} INFO - [2022-06-07 00:22:46,143] {timeout.py:36} ERROR - Process timed out, PID: 678932
[2022-06-07 00:22:46,144] {logging_mixin.py:109} INFO - [2022-06-07 00:22:46,143] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 678932
[2022-06-07 00:22:46,144] {logging_mixin.py:109} INFO - [2022-06-07 00:22:46,144] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:22:46,144] {logging_mixin.py:109} INFO - [2022-06-07 00:22:46,144] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 678932

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:22:46,145] {logging_mixin.py:109} INFO - [2022-06-07 00:22:46,144] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:22:46,145] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:22:46,156] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:23:17,163] {processor.py:163} INFO - Started process (PID=680026) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:23:17,163] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:23:17,163] {logging_mixin.py:109} INFO - [2022-06-07 00:23:17,163] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:23:47,165] {logging_mixin.py:109} INFO - [2022-06-07 00:23:47,165] {timeout.py:36} ERROR - Process timed out, PID: 680026
[2022-06-07 00:23:47,166] {logging_mixin.py:109} INFO - [2022-06-07 00:23:47,165] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 680026
[2022-06-07 00:23:47,166] {logging_mixin.py:109} INFO - [2022-06-07 00:23:47,166] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:23:47,166] {logging_mixin.py:109} INFO - [2022-06-07 00:23:47,166] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 680026

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:23:47,167] {logging_mixin.py:109} INFO - [2022-06-07 00:23:47,166] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:23:47,167] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:23:47,179] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:24:17,208] {processor.py:163} INFO - Started process (PID=681105) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:24:17,208] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:24:17,208] {logging_mixin.py:109} INFO - [2022-06-07 00:24:17,208] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:24:47,210] {logging_mixin.py:109} INFO - [2022-06-07 00:24:47,210] {timeout.py:36} ERROR - Process timed out, PID: 681105
[2022-06-07 00:24:47,211] {logging_mixin.py:109} INFO - [2022-06-07 00:24:47,210] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 681105
[2022-06-07 00:24:47,211] {logging_mixin.py:109} INFO - [2022-06-07 00:24:47,211] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:24:47,211] {logging_mixin.py:109} INFO - [2022-06-07 00:24:47,211] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 681105

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:24:47,211] {logging_mixin.py:109} INFO - [2022-06-07 00:24:47,211] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:24:47,212] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:24:47,223] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:25:17,453] {processor.py:163} INFO - Started process (PID=682183) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:25:17,454] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:25:17,454] {logging_mixin.py:109} INFO - [2022-06-07 00:25:17,454] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:25:47,456] {logging_mixin.py:109} INFO - [2022-06-07 00:25:47,455] {timeout.py:36} ERROR - Process timed out, PID: 682183
[2022-06-07 00:25:47,456] {logging_mixin.py:109} INFO - [2022-06-07 00:25:47,456] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 682183
[2022-06-07 00:25:47,456] {logging_mixin.py:109} INFO - [2022-06-07 00:25:47,456] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:25:47,457] {logging_mixin.py:109} INFO - [2022-06-07 00:25:47,457] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 682183

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:25:47,457] {logging_mixin.py:109} INFO - [2022-06-07 00:25:47,457] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:25:47,458] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:25:47,469] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:26:17,536] {processor.py:163} INFO - Started process (PID=683277) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:26:17,536] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:26:17,537] {logging_mixin.py:109} INFO - [2022-06-07 00:26:17,537] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:26:47,543] {logging_mixin.py:109} INFO - [2022-06-07 00:26:47,543] {timeout.py:36} ERROR - Process timed out, PID: 683277
[2022-06-07 00:26:47,544] {logging_mixin.py:109} INFO - [2022-06-07 00:26:47,544] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 683277
[2022-06-07 00:26:47,544] {logging_mixin.py:109} INFO - [2022-06-07 00:26:47,544] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:26:47,545] {logging_mixin.py:109} INFO - [2022-06-07 00:26:47,544] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 683277

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:26:47,545] {logging_mixin.py:109} INFO - [2022-06-07 00:26:47,545] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:26:47,546] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:26:47,556] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 00:27:17,575] {processor.py:163} INFO - Started process (PID=684372) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:27:17,575] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:27:17,576] {logging_mixin.py:109} INFO - [2022-06-07 00:27:17,576] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:27:47,577] {logging_mixin.py:109} INFO - [2022-06-07 00:27:47,576] {timeout.py:36} ERROR - Process timed out, PID: 684372
[2022-06-07 00:27:47,577] {logging_mixin.py:109} INFO - [2022-06-07 00:27:47,577] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 684372
[2022-06-07 00:27:47,578] {logging_mixin.py:109} INFO - [2022-06-07 00:27:47,578] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:27:47,578] {logging_mixin.py:109} INFO - [2022-06-07 00:27:47,578] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 684372

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:27:47,578] {logging_mixin.py:109} INFO - [2022-06-07 00:27:47,578] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:27:47,579] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:27:47,590] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:28:17,770] {processor.py:163} INFO - Started process (PID=685462) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:28:17,770] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:28:17,771] {logging_mixin.py:109} INFO - [2022-06-07 00:28:17,771] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:28:47,772] {logging_mixin.py:109} INFO - [2022-06-07 00:28:47,772] {timeout.py:36} ERROR - Process timed out, PID: 685462
[2022-06-07 00:28:47,773] {logging_mixin.py:109} INFO - [2022-06-07 00:28:47,773] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 685462
[2022-06-07 00:28:47,773] {logging_mixin.py:109} INFO - [2022-06-07 00:28:47,773] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:28:47,774] {logging_mixin.py:109} INFO - [2022-06-07 00:28:47,773] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 685462

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:28:47,774] {logging_mixin.py:109} INFO - [2022-06-07 00:28:47,774] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:28:47,774] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:28:47,786] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:29:17,919] {processor.py:163} INFO - Started process (PID=686557) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:29:17,919] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:29:17,920] {logging_mixin.py:109} INFO - [2022-06-07 00:29:17,920] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:29:47,921] {logging_mixin.py:109} INFO - [2022-06-07 00:29:47,921] {timeout.py:36} ERROR - Process timed out, PID: 686557
[2022-06-07 00:29:47,922] {logging_mixin.py:109} INFO - [2022-06-07 00:29:47,922] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 686557
[2022-06-07 00:29:47,922] {logging_mixin.py:109} INFO - [2022-06-07 00:29:47,922] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:29:47,923] {logging_mixin.py:109} INFO - [2022-06-07 00:29:47,922] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 686557

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:29:47,923] {logging_mixin.py:109} INFO - [2022-06-07 00:29:47,923] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:29:47,923] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:29:47,935] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:30:18,130] {processor.py:163} INFO - Started process (PID=687652) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:30:18,131] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:30:18,131] {logging_mixin.py:109} INFO - [2022-06-07 00:30:18,131] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:30:48,132] {logging_mixin.py:109} INFO - [2022-06-07 00:30:48,132] {timeout.py:36} ERROR - Process timed out, PID: 687652
[2022-06-07 00:30:48,133] {logging_mixin.py:109} INFO - [2022-06-07 00:30:48,132] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 687652
[2022-06-07 00:30:48,133] {logging_mixin.py:109} INFO - [2022-06-07 00:30:48,133] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:30:48,133] {logging_mixin.py:109} INFO - [2022-06-07 00:30:48,133] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 687652

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:30:48,134] {logging_mixin.py:109} INFO - [2022-06-07 00:30:48,134] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:30:48,134] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:30:48,146] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 00:31:18,168] {processor.py:163} INFO - Started process (PID=688720) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:31:18,168] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:31:18,169] {logging_mixin.py:109} INFO - [2022-06-07 00:31:18,169] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:31:48,175] {logging_mixin.py:109} INFO - [2022-06-07 00:31:48,175] {timeout.py:36} ERROR - Process timed out, PID: 688720
[2022-06-07 00:31:48,176] {logging_mixin.py:109} INFO - [2022-06-07 00:31:48,175] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 688720
[2022-06-07 00:31:48,176] {logging_mixin.py:109} INFO - [2022-06-07 00:31:48,176] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:31:48,176] {logging_mixin.py:109} INFO - [2022-06-07 00:31:48,176] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 688720

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:31:48,177] {logging_mixin.py:109} INFO - [2022-06-07 00:31:48,176] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:31:48,177] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:31:48,189] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 00:32:18,330] {processor.py:163} INFO - Started process (PID=689779) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:32:18,330] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:32:18,330] {logging_mixin.py:109} INFO - [2022-06-07 00:32:18,330] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:32:48,333] {logging_mixin.py:109} INFO - [2022-06-07 00:32:48,333] {timeout.py:36} ERROR - Process timed out, PID: 689779
[2022-06-07 00:32:48,334] {logging_mixin.py:109} INFO - [2022-06-07 00:32:48,333] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 689779
[2022-06-07 00:32:48,334] {logging_mixin.py:109} INFO - [2022-06-07 00:32:48,334] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:32:48,334] {logging_mixin.py:109} INFO - [2022-06-07 00:32:48,334] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 689779

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:32:48,335] {logging_mixin.py:109} INFO - [2022-06-07 00:32:48,335] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:32:48,335] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:32:48,347] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 00:33:19,309] {processor.py:163} INFO - Started process (PID=690871) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:33:19,310] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:33:19,310] {logging_mixin.py:109} INFO - [2022-06-07 00:33:19,310] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:33:49,312] {logging_mixin.py:109} INFO - [2022-06-07 00:33:49,311] {timeout.py:36} ERROR - Process timed out, PID: 690871
[2022-06-07 00:33:49,313] {logging_mixin.py:109} INFO - [2022-06-07 00:33:49,312] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 690871
[2022-06-07 00:33:49,313] {logging_mixin.py:109} INFO - [2022-06-07 00:33:49,313] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:33:49,313] {logging_mixin.py:109} INFO - [2022-06-07 00:33:49,313] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 690871

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:33:49,314] {logging_mixin.py:109} INFO - [2022-06-07 00:33:49,313] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:33:49,314] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:33:49,325] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:34:19,530] {processor.py:163} INFO - Started process (PID=691966) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:34:19,531] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:34:19,531] {logging_mixin.py:109} INFO - [2022-06-07 00:34:19,531] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:34:49,535] {logging_mixin.py:109} INFO - [2022-06-07 00:34:49,534] {timeout.py:36} ERROR - Process timed out, PID: 691966
[2022-06-07 00:34:49,535] {logging_mixin.py:109} INFO - [2022-06-07 00:34:49,535] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 691966
[2022-06-07 00:34:49,535] {logging_mixin.py:109} INFO - [2022-06-07 00:34:49,535] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:34:49,536] {logging_mixin.py:109} INFO - [2022-06-07 00:34:49,536] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 691966

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:34:49,536] {logging_mixin.py:109} INFO - [2022-06-07 00:34:49,536] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:34:49,537] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:34:49,548] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 00:35:19,684] {processor.py:163} INFO - Started process (PID=693059) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:35:19,684] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:35:19,685] {logging_mixin.py:109} INFO - [2022-06-07 00:35:19,685] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:35:49,686] {logging_mixin.py:109} INFO - [2022-06-07 00:35:49,686] {timeout.py:36} ERROR - Process timed out, PID: 693059
[2022-06-07 00:35:49,687] {logging_mixin.py:109} INFO - [2022-06-07 00:35:49,686] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 693059
[2022-06-07 00:35:49,687] {logging_mixin.py:109} INFO - [2022-06-07 00:35:49,687] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:35:49,687] {logging_mixin.py:109} INFO - [2022-06-07 00:35:49,687] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 693059

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:35:49,688] {logging_mixin.py:109} INFO - [2022-06-07 00:35:49,688] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:35:49,688] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:35:49,700] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:36:19,791] {processor.py:163} INFO - Started process (PID=694153) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:36:19,792] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:36:19,792] {logging_mixin.py:109} INFO - [2022-06-07 00:36:19,792] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:36:49,807] {logging_mixin.py:109} INFO - [2022-06-07 00:36:49,807] {timeout.py:36} ERROR - Process timed out, PID: 694153
[2022-06-07 00:36:49,808] {logging_mixin.py:109} INFO - [2022-06-07 00:36:49,807] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 694153
[2022-06-07 00:36:49,808] {logging_mixin.py:109} INFO - [2022-06-07 00:36:49,808] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:36:49,808] {logging_mixin.py:109} INFO - [2022-06-07 00:36:49,808] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 694153

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:36:49,809] {logging_mixin.py:109} INFO - [2022-06-07 00:36:49,808] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:36:49,809] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:36:49,820] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.030 seconds
[2022-06-07 00:37:19,862] {processor.py:163} INFO - Started process (PID=695249) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:37:19,863] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:37:19,863] {logging_mixin.py:109} INFO - [2022-06-07 00:37:19,863] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:37:49,871] {logging_mixin.py:109} INFO - [2022-06-07 00:37:49,870] {timeout.py:36} ERROR - Process timed out, PID: 695249
[2022-06-07 00:37:49,871] {logging_mixin.py:109} INFO - [2022-06-07 00:37:49,871] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 695249
[2022-06-07 00:37:49,871] {logging_mixin.py:109} INFO - [2022-06-07 00:37:49,871] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:37:49,872] {logging_mixin.py:109} INFO - [2022-06-07 00:37:49,872] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 695249

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:37:49,872] {logging_mixin.py:109} INFO - [2022-06-07 00:37:49,872] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:37:49,873] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:37:49,884] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 00:38:20,012] {processor.py:163} INFO - Started process (PID=696342) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:38:20,013] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:38:20,013] {logging_mixin.py:109} INFO - [2022-06-07 00:38:20,013] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:38:50,018] {logging_mixin.py:109} INFO - [2022-06-07 00:38:50,017] {timeout.py:36} ERROR - Process timed out, PID: 696342
[2022-06-07 00:38:50,018] {logging_mixin.py:109} INFO - [2022-06-07 00:38:50,018] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 696342
[2022-06-07 00:38:50,019] {logging_mixin.py:109} INFO - [2022-06-07 00:38:50,019] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:38:50,019] {logging_mixin.py:109} INFO - [2022-06-07 00:38:50,019] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 696342

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:38:50,019] {logging_mixin.py:109} INFO - [2022-06-07 00:38:50,019] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:38:50,020] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:38:50,032] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 00:39:20,152] {processor.py:163} INFO - Started process (PID=697435) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:39:20,152] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:39:20,152] {logging_mixin.py:109} INFO - [2022-06-07 00:39:20,152] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:39:50,155] {logging_mixin.py:109} INFO - [2022-06-07 00:39:50,155] {timeout.py:36} ERROR - Process timed out, PID: 697435
[2022-06-07 00:39:50,156] {logging_mixin.py:109} INFO - [2022-06-07 00:39:50,155] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 697435
[2022-06-07 00:39:50,156] {logging_mixin.py:109} INFO - [2022-06-07 00:39:50,156] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:39:50,157] {logging_mixin.py:109} INFO - [2022-06-07 00:39:50,156] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 697435

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:39:50,157] {logging_mixin.py:109} INFO - [2022-06-07 00:39:50,157] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:39:50,157] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:39:50,170] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 00:40:20,272] {processor.py:163} INFO - Started process (PID=698529) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:40:20,272] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:40:20,273] {logging_mixin.py:109} INFO - [2022-06-07 00:40:20,273] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:40:50,276] {logging_mixin.py:109} INFO - [2022-06-07 00:40:50,275] {timeout.py:36} ERROR - Process timed out, PID: 698529
[2022-06-07 00:40:50,276] {logging_mixin.py:109} INFO - [2022-06-07 00:40:50,276] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 698529
[2022-06-07 00:40:50,276] {logging_mixin.py:109} INFO - [2022-06-07 00:40:50,276] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:40:50,277] {logging_mixin.py:109} INFO - [2022-06-07 00:40:50,276] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 698529

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:40:50,277] {logging_mixin.py:109} INFO - [2022-06-07 00:40:50,277] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:40:50,277] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:40:50,290] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 00:41:20,500] {processor.py:163} INFO - Started process (PID=699623) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:41:20,501] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:41:20,501] {logging_mixin.py:109} INFO - [2022-06-07 00:41:20,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:41:50,506] {logging_mixin.py:109} INFO - [2022-06-07 00:41:50,506] {timeout.py:36} ERROR - Process timed out, PID: 699623
[2022-06-07 00:41:50,507] {logging_mixin.py:109} INFO - [2022-06-07 00:41:50,506] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 699623
[2022-06-07 00:41:50,507] {logging_mixin.py:109} INFO - [2022-06-07 00:41:50,507] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:41:50,507] {logging_mixin.py:109} INFO - [2022-06-07 00:41:50,507] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 699623

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:41:50,508] {logging_mixin.py:109} INFO - [2022-06-07 00:41:50,508] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:41:50,508] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:41:50,523] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 00:42:21,413] {processor.py:163} INFO - Started process (PID=700718) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:42:21,413] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:42:21,413] {logging_mixin.py:109} INFO - [2022-06-07 00:42:21,413] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:42:51,415] {logging_mixin.py:109} INFO - [2022-06-07 00:42:51,415] {timeout.py:36} ERROR - Process timed out, PID: 700718
[2022-06-07 00:42:51,416] {logging_mixin.py:109} INFO - [2022-06-07 00:42:51,415] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 700718
[2022-06-07 00:42:51,416] {logging_mixin.py:109} INFO - [2022-06-07 00:42:51,416] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:42:51,416] {logging_mixin.py:109} INFO - [2022-06-07 00:42:51,416] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 700718

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:42:51,417] {logging_mixin.py:109} INFO - [2022-06-07 00:42:51,416] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:42:51,417] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:42:51,429] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:43:22,213] {processor.py:163} INFO - Started process (PID=701813) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:43:22,213] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:43:22,213] {logging_mixin.py:109} INFO - [2022-06-07 00:43:22,213] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:43:52,216] {logging_mixin.py:109} INFO - [2022-06-07 00:43:52,216] {timeout.py:36} ERROR - Process timed out, PID: 701813
[2022-06-07 00:43:52,217] {logging_mixin.py:109} INFO - [2022-06-07 00:43:52,216] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 701813
[2022-06-07 00:43:52,217] {logging_mixin.py:109} INFO - [2022-06-07 00:43:52,217] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:43:52,218] {logging_mixin.py:109} INFO - [2022-06-07 00:43:52,217] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 701813

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:43:52,218] {logging_mixin.py:109} INFO - [2022-06-07 00:43:52,218] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:43:52,218] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:43:52,232] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 00:44:22,262] {processor.py:163} INFO - Started process (PID=702906) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:44:22,262] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:44:22,263] {logging_mixin.py:109} INFO - [2022-06-07 00:44:22,263] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:44:52,280] {logging_mixin.py:109} INFO - [2022-06-07 00:44:52,279] {timeout.py:36} ERROR - Process timed out, PID: 702906
[2022-06-07 00:44:52,280] {logging_mixin.py:109} INFO - [2022-06-07 00:44:52,280] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 702906
[2022-06-07 00:44:52,281] {logging_mixin.py:109} INFO - [2022-06-07 00:44:52,281] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:44:52,281] {logging_mixin.py:109} INFO - [2022-06-07 00:44:52,281] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 702906

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:44:52,282] {logging_mixin.py:109} INFO - [2022-06-07 00:44:52,281] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:44:52,282] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:44:52,294] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.033 seconds
[2022-06-07 00:45:22,354] {processor.py:163} INFO - Started process (PID=704000) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:45:22,354] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:45:22,354] {logging_mixin.py:109} INFO - [2022-06-07 00:45:22,354] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:45:52,357] {logging_mixin.py:109} INFO - [2022-06-07 00:45:52,356] {timeout.py:36} ERROR - Process timed out, PID: 704000
[2022-06-07 00:45:52,357] {logging_mixin.py:109} INFO - [2022-06-07 00:45:52,357] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 704000
[2022-06-07 00:45:52,358] {logging_mixin.py:109} INFO - [2022-06-07 00:45:52,358] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:45:52,358] {logging_mixin.py:109} INFO - [2022-06-07 00:45:52,358] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 704000

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:45:52,359] {logging_mixin.py:109} INFO - [2022-06-07 00:45:52,358] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:45:52,359] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:45:52,371] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 00:46:22,647] {processor.py:163} INFO - Started process (PID=705095) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:46:22,647] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:46:22,647] {logging_mixin.py:109} INFO - [2022-06-07 00:46:22,647] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:46:52,648] {logging_mixin.py:109} INFO - [2022-06-07 00:46:52,648] {timeout.py:36} ERROR - Process timed out, PID: 705095
[2022-06-07 00:46:52,649] {logging_mixin.py:109} INFO - [2022-06-07 00:46:52,648] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 705095
[2022-06-07 00:46:52,649] {logging_mixin.py:109} INFO - [2022-06-07 00:46:52,649] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:46:52,650] {logging_mixin.py:109} INFO - [2022-06-07 00:46:52,649] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 705095

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:46:52,650] {logging_mixin.py:109} INFO - [2022-06-07 00:46:52,650] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:46:52,650] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:46:52,661] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 00:47:23,628] {processor.py:163} INFO - Started process (PID=706189) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:47:23,628] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:47:23,629] {logging_mixin.py:109} INFO - [2022-06-07 00:47:23,629] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:47:53,632] {logging_mixin.py:109} INFO - [2022-06-07 00:47:53,632] {timeout.py:36} ERROR - Process timed out, PID: 706189
[2022-06-07 00:47:53,633] {logging_mixin.py:109} INFO - [2022-06-07 00:47:53,632] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 706189
[2022-06-07 00:47:53,633] {logging_mixin.py:109} INFO - [2022-06-07 00:47:53,633] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:47:53,633] {logging_mixin.py:109} INFO - [2022-06-07 00:47:53,633] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 706189

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:47:53,634] {logging_mixin.py:109} INFO - [2022-06-07 00:47:53,633] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:47:53,634] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:47:53,645] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 00:48:24,634] {processor.py:163} INFO - Started process (PID=707283) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:48:24,635] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:48:24,635] {logging_mixin.py:109} INFO - [2022-06-07 00:48:24,635] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:48:54,637] {logging_mixin.py:109} INFO - [2022-06-07 00:48:54,636] {timeout.py:36} ERROR - Process timed out, PID: 707283
[2022-06-07 00:48:54,637] {logging_mixin.py:109} INFO - [2022-06-07 00:48:54,637] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 707283
[2022-06-07 00:48:54,637] {logging_mixin.py:109} INFO - [2022-06-07 00:48:54,637] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:48:54,638] {logging_mixin.py:109} INFO - [2022-06-07 00:48:54,637] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 707283

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:48:54,638] {logging_mixin.py:109} INFO - [2022-06-07 00:48:54,638] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:48:54,638] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:48:54,651] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:49:25,620] {processor.py:163} INFO - Started process (PID=708377) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:49:25,621] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:49:25,621] {logging_mixin.py:109} INFO - [2022-06-07 00:49:25,621] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:49:55,632] {logging_mixin.py:109} INFO - [2022-06-07 00:49:55,631] {timeout.py:36} ERROR - Process timed out, PID: 708377
[2022-06-07 00:49:55,632] {logging_mixin.py:109} INFO - [2022-06-07 00:49:55,632] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 708377
[2022-06-07 00:49:55,633] {logging_mixin.py:109} INFO - [2022-06-07 00:49:55,632] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:49:55,633] {logging_mixin.py:109} INFO - [2022-06-07 00:49:55,633] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 708377

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:49:55,633] {logging_mixin.py:109} INFO - [2022-06-07 00:49:55,633] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:49:55,634] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:49:55,646] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.027 seconds
[2022-06-07 00:50:25,744] {processor.py:163} INFO - Started process (PID=709468) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:50:25,744] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:50:25,745] {logging_mixin.py:109} INFO - [2022-06-07 00:50:25,745] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:50:55,747] {logging_mixin.py:109} INFO - [2022-06-07 00:50:55,746] {timeout.py:36} ERROR - Process timed out, PID: 709468
[2022-06-07 00:50:55,747] {logging_mixin.py:109} INFO - [2022-06-07 00:50:55,747] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 709468
[2022-06-07 00:50:55,747] {logging_mixin.py:109} INFO - [2022-06-07 00:50:55,747] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:50:55,748] {logging_mixin.py:109} INFO - [2022-06-07 00:50:55,747] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 709468

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:50:55,748] {logging_mixin.py:109} INFO - [2022-06-07 00:50:55,748] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:50:55,748] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:50:55,760] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:51:25,996] {processor.py:163} INFO - Started process (PID=710562) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:51:25,997] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:51:25,997] {logging_mixin.py:109} INFO - [2022-06-07 00:51:25,997] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:51:55,998] {logging_mixin.py:109} INFO - [2022-06-07 00:51:55,998] {timeout.py:36} ERROR - Process timed out, PID: 710562
[2022-06-07 00:51:55,999] {logging_mixin.py:109} INFO - [2022-06-07 00:51:55,998] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 710562
[2022-06-07 00:51:55,999] {logging_mixin.py:109} INFO - [2022-06-07 00:51:55,999] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:51:55,999] {logging_mixin.py:109} INFO - [2022-06-07 00:51:55,999] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 710562

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:51:56,000] {logging_mixin.py:109} INFO - [2022-06-07 00:51:55,999] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:51:56,000] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:51:56,013] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 00:52:26,214] {processor.py:163} INFO - Started process (PID=711657) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:52:26,215] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:52:26,215] {logging_mixin.py:109} INFO - [2022-06-07 00:52:26,215] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:52:56,219] {logging_mixin.py:109} INFO - [2022-06-07 00:52:56,218] {timeout.py:36} ERROR - Process timed out, PID: 711657
[2022-06-07 00:52:56,219] {logging_mixin.py:109} INFO - [2022-06-07 00:52:56,219] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 711657
[2022-06-07 00:52:56,219] {logging_mixin.py:109} INFO - [2022-06-07 00:52:56,219] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:52:56,220] {logging_mixin.py:109} INFO - [2022-06-07 00:52:56,220] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 711657

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:52:56,220] {logging_mixin.py:109} INFO - [2022-06-07 00:52:56,220] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:52:56,220] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:52:56,232] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 00:53:26,438] {processor.py:163} INFO - Started process (PID=712694) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:53:26,438] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:53:26,439] {logging_mixin.py:109} INFO - [2022-06-07 00:53:26,439] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:53:56,441] {logging_mixin.py:109} INFO - [2022-06-07 00:53:56,441] {timeout.py:36} ERROR - Process timed out, PID: 712694
[2022-06-07 00:53:56,442] {logging_mixin.py:109} INFO - [2022-06-07 00:53:56,441] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 712694
[2022-06-07 00:53:56,442] {logging_mixin.py:109} INFO - [2022-06-07 00:53:56,442] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:53:56,442] {logging_mixin.py:109} INFO - [2022-06-07 00:53:56,442] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 712694

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:53:56,443] {logging_mixin.py:109} INFO - [2022-06-07 00:53:56,442] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:53:56,443] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:53:56,454] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 00:54:26,725] {processor.py:163} INFO - Started process (PID=713789) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:54:26,726] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:54:26,726] {logging_mixin.py:109} INFO - [2022-06-07 00:54:26,726] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:54:56,731] {logging_mixin.py:109} INFO - [2022-06-07 00:54:56,730] {timeout.py:36} ERROR - Process timed out, PID: 713789
[2022-06-07 00:54:56,731] {logging_mixin.py:109} INFO - [2022-06-07 00:54:56,731] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 713789
[2022-06-07 00:54:56,731] {logging_mixin.py:109} INFO - [2022-06-07 00:54:56,731] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:54:56,732] {logging_mixin.py:109} INFO - [2022-06-07 00:54:56,732] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 713789

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:54:56,732] {logging_mixin.py:109} INFO - [2022-06-07 00:54:56,732] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:54:56,733] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:54:56,745] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 00:55:26,943] {processor.py:163} INFO - Started process (PID=714883) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:55:26,944] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:55:26,944] {logging_mixin.py:109} INFO - [2022-06-07 00:55:26,944] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:55:56,959] {logging_mixin.py:109} INFO - [2022-06-07 00:55:56,959] {timeout.py:36} ERROR - Process timed out, PID: 714883
[2022-06-07 00:55:56,960] {logging_mixin.py:109} INFO - [2022-06-07 00:55:56,959] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 714883
[2022-06-07 00:55:56,960] {logging_mixin.py:109} INFO - [2022-06-07 00:55:56,960] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:55:56,960] {logging_mixin.py:109} INFO - [2022-06-07 00:55:56,960] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 714883

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:55:56,961] {logging_mixin.py:109} INFO - [2022-06-07 00:55:56,960] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:55:56,961] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:55:56,972] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.030 seconds
[2022-06-07 00:56:27,169] {processor.py:163} INFO - Started process (PID=715979) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:56:27,170] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:56:27,170] {logging_mixin.py:109} INFO - [2022-06-07 00:56:27,170] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:56:57,172] {logging_mixin.py:109} INFO - [2022-06-07 00:56:57,171] {timeout.py:36} ERROR - Process timed out, PID: 715979
[2022-06-07 00:56:57,172] {logging_mixin.py:109} INFO - [2022-06-07 00:56:57,172] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 715979
[2022-06-07 00:56:57,172] {logging_mixin.py:109} INFO - [2022-06-07 00:56:57,172] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:56:57,173] {logging_mixin.py:109} INFO - [2022-06-07 00:56:57,172] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 715979

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:56:57,173] {logging_mixin.py:109} INFO - [2022-06-07 00:56:57,173] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:56:57,173] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:56:57,186] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 00:57:27,500] {processor.py:163} INFO - Started process (PID=717059) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:57:27,501] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:57:27,501] {logging_mixin.py:109} INFO - [2022-06-07 00:57:27,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:57:57,503] {logging_mixin.py:109} INFO - [2022-06-07 00:57:57,503] {timeout.py:36} ERROR - Process timed out, PID: 717059
[2022-06-07 00:57:57,504] {logging_mixin.py:109} INFO - [2022-06-07 00:57:57,503] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 717059
[2022-06-07 00:57:57,504] {logging_mixin.py:109} INFO - [2022-06-07 00:57:57,504] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:57:57,504] {logging_mixin.py:109} INFO - [2022-06-07 00:57:57,504] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 717059

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:57:57,505] {logging_mixin.py:109} INFO - [2022-06-07 00:57:57,505] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:57:57,505] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:57:57,520] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 00:58:27,618] {processor.py:163} INFO - Started process (PID=718154) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:58:27,618] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:58:27,619] {logging_mixin.py:109} INFO - [2022-06-07 00:58:27,619] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:58:57,620] {logging_mixin.py:109} INFO - [2022-06-07 00:58:57,619] {timeout.py:36} ERROR - Process timed out, PID: 718154
[2022-06-07 00:58:57,620] {logging_mixin.py:109} INFO - [2022-06-07 00:58:57,620] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 718154
[2022-06-07 00:58:57,621] {logging_mixin.py:109} INFO - [2022-06-07 00:58:57,621] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:58:57,621] {logging_mixin.py:109} INFO - [2022-06-07 00:58:57,621] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 718154

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:58:57,621] {logging_mixin.py:109} INFO - [2022-06-07 00:58:57,621] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:58:57,622] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:58:57,633] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 00:59:27,653] {processor.py:163} INFO - Started process (PID=719248) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 00:59:27,654] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 00:59:27,654] {logging_mixin.py:109} INFO - [2022-06-07 00:59:27,654] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:59:57,656] {logging_mixin.py:109} INFO - [2022-06-07 00:59:57,655] {timeout.py:36} ERROR - Process timed out, PID: 719248
[2022-06-07 00:59:57,656] {logging_mixin.py:109} INFO - [2022-06-07 00:59:57,656] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 719248
[2022-06-07 00:59:57,656] {logging_mixin.py:109} INFO - [2022-06-07 00:59:57,656] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 00:59:57,657] {logging_mixin.py:109} INFO - [2022-06-07 00:59:57,656] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 719248

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 00:59:57,657] {logging_mixin.py:109} INFO - [2022-06-07 00:59:57,657] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 00:59:57,657] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 00:59:57,668] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 01:00:27,907] {processor.py:163} INFO - Started process (PID=720341) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:00:27,908] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:00:27,908] {logging_mixin.py:109} INFO - [2022-06-07 01:00:27,908] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:00:57,909] {logging_mixin.py:109} INFO - [2022-06-07 01:00:57,909] {timeout.py:36} ERROR - Process timed out, PID: 720341
[2022-06-07 01:00:57,910] {logging_mixin.py:109} INFO - [2022-06-07 01:00:57,909] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 720341
[2022-06-07 01:00:57,910] {logging_mixin.py:109} INFO - [2022-06-07 01:00:57,910] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:00:57,910] {logging_mixin.py:109} INFO - [2022-06-07 01:00:57,910] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 720341

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:00:57,911] {logging_mixin.py:109} INFO - [2022-06-07 01:00:57,910] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:00:57,911] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:00:57,923] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 01:01:28,169] {processor.py:163} INFO - Started process (PID=721410) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:01:28,170] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:01:28,170] {logging_mixin.py:109} INFO - [2022-06-07 01:01:28,170] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:01:58,174] {logging_mixin.py:109} INFO - [2022-06-07 01:01:58,173] {timeout.py:36} ERROR - Process timed out, PID: 721410
[2022-06-07 01:01:58,174] {logging_mixin.py:109} INFO - [2022-06-07 01:01:58,174] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 721410
[2022-06-07 01:01:58,174] {logging_mixin.py:109} INFO - [2022-06-07 01:01:58,174] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:01:58,175] {logging_mixin.py:109} INFO - [2022-06-07 01:01:58,174] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 721410

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:01:58,175] {logging_mixin.py:109} INFO - [2022-06-07 01:01:58,175] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:01:58,175] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:01:58,187] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:02:28,266] {processor.py:163} INFO - Started process (PID=722501) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:02:28,266] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:02:28,267] {logging_mixin.py:109} INFO - [2022-06-07 01:02:28,267] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:02:58,268] {logging_mixin.py:109} INFO - [2022-06-07 01:02:58,267] {timeout.py:36} ERROR - Process timed out, PID: 722501
[2022-06-07 01:02:58,268] {logging_mixin.py:109} INFO - [2022-06-07 01:02:58,268] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 722501
[2022-06-07 01:02:58,268] {logging_mixin.py:109} INFO - [2022-06-07 01:02:58,268] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:02:58,269] {logging_mixin.py:109} INFO - [2022-06-07 01:02:58,268] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 722501

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:02:58,269] {logging_mixin.py:109} INFO - [2022-06-07 01:02:58,269] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:02:58,269] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:02:58,281] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 01:03:28,379] {processor.py:163} INFO - Started process (PID=723595) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:03:28,380] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:03:28,380] {logging_mixin.py:109} INFO - [2022-06-07 01:03:28,380] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:03:58,381] {logging_mixin.py:109} INFO - [2022-06-07 01:03:58,381] {timeout.py:36} ERROR - Process timed out, PID: 723595
[2022-06-07 01:03:58,382] {logging_mixin.py:109} INFO - [2022-06-07 01:03:58,381] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 723595
[2022-06-07 01:03:58,382] {logging_mixin.py:109} INFO - [2022-06-07 01:03:58,382] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:03:58,383] {logging_mixin.py:109} INFO - [2022-06-07 01:03:58,382] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 723595

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:03:58,383] {logging_mixin.py:109} INFO - [2022-06-07 01:03:58,383] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:03:58,383] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:03:58,395] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 01:04:28,563] {processor.py:163} INFO - Started process (PID=724685) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:04:28,564] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:04:28,564] {logging_mixin.py:109} INFO - [2022-06-07 01:04:28,564] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:04:58,565] {logging_mixin.py:109} INFO - [2022-06-07 01:04:58,565] {timeout.py:36} ERROR - Process timed out, PID: 724685
[2022-06-07 01:04:58,566] {logging_mixin.py:109} INFO - [2022-06-07 01:04:58,565] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 724685
[2022-06-07 01:04:58,566] {logging_mixin.py:109} INFO - [2022-06-07 01:04:58,566] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:04:58,566] {logging_mixin.py:109} INFO - [2022-06-07 01:04:58,566] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 724685

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:04:58,567] {logging_mixin.py:109} INFO - [2022-06-07 01:04:58,566] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:04:58,567] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:04:58,579] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:05:28,722] {processor.py:163} INFO - Started process (PID=725780) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:05:28,722] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:05:28,723] {logging_mixin.py:109} INFO - [2022-06-07 01:05:28,722] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:05:58,725] {logging_mixin.py:109} INFO - [2022-06-07 01:05:58,724] {timeout.py:36} ERROR - Process timed out, PID: 725780
[2022-06-07 01:05:58,725] {logging_mixin.py:109} INFO - [2022-06-07 01:05:58,725] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 725780
[2022-06-07 01:05:58,725] {logging_mixin.py:109} INFO - [2022-06-07 01:05:58,725] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:05:58,726] {logging_mixin.py:109} INFO - [2022-06-07 01:05:58,726] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 725780

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:05:58,726] {logging_mixin.py:109} INFO - [2022-06-07 01:05:58,726] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:05:58,727] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:05:58,738] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:06:28,923] {processor.py:163} INFO - Started process (PID=726874) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:06:28,923] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:06:28,923] {logging_mixin.py:109} INFO - [2022-06-07 01:06:28,923] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:06:58,925] {logging_mixin.py:109} INFO - [2022-06-07 01:06:58,924] {timeout.py:36} ERROR - Process timed out, PID: 726874
[2022-06-07 01:06:58,925] {logging_mixin.py:109} INFO - [2022-06-07 01:06:58,925] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 726874
[2022-06-07 01:06:58,925] {logging_mixin.py:109} INFO - [2022-06-07 01:06:58,925] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:06:58,926] {logging_mixin.py:109} INFO - [2022-06-07 01:06:58,926] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 726874

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:06:58,926] {logging_mixin.py:109} INFO - [2022-06-07 01:06:58,926] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:06:58,927] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:06:58,938] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 01:07:29,097] {processor.py:163} INFO - Started process (PID=727933) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:07:29,097] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:07:29,097] {logging_mixin.py:109} INFO - [2022-06-07 01:07:29,097] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:07:59,103] {logging_mixin.py:109} INFO - [2022-06-07 01:07:59,103] {timeout.py:36} ERROR - Process timed out, PID: 727933
[2022-06-07 01:07:59,104] {logging_mixin.py:109} INFO - [2022-06-07 01:07:59,104] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 727933
[2022-06-07 01:07:59,104] {logging_mixin.py:109} INFO - [2022-06-07 01:07:59,104] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:07:59,105] {logging_mixin.py:109} INFO - [2022-06-07 01:07:59,104] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 727933

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:07:59,105] {logging_mixin.py:109} INFO - [2022-06-07 01:07:59,105] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:07:59,105] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:07:59,117] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 01:08:29,216] {processor.py:163} INFO - Started process (PID=729016) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:08:29,217] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:08:29,217] {logging_mixin.py:109} INFO - [2022-06-07 01:08:29,217] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:08:59,218] {logging_mixin.py:109} INFO - [2022-06-07 01:08:59,218] {timeout.py:36} ERROR - Process timed out, PID: 729016
[2022-06-07 01:08:59,219] {logging_mixin.py:109} INFO - [2022-06-07 01:08:59,218] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 729016
[2022-06-07 01:08:59,219] {logging_mixin.py:109} INFO - [2022-06-07 01:08:59,219] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:08:59,219] {logging_mixin.py:109} INFO - [2022-06-07 01:08:59,219] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 729016

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:08:59,220] {logging_mixin.py:109} INFO - [2022-06-07 01:08:59,220] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:08:59,220] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:08:59,232] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 01:09:29,277] {processor.py:163} INFO - Started process (PID=730098) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:09:29,277] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:09:29,277] {logging_mixin.py:109} INFO - [2022-06-07 01:09:29,277] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:09:59,279] {logging_mixin.py:109} INFO - [2022-06-07 01:09:59,278] {timeout.py:36} ERROR - Process timed out, PID: 730098
[2022-06-07 01:09:59,279] {logging_mixin.py:109} INFO - [2022-06-07 01:09:59,279] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 730098
[2022-06-07 01:09:59,279] {logging_mixin.py:109} INFO - [2022-06-07 01:09:59,279] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:09:59,280] {logging_mixin.py:109} INFO - [2022-06-07 01:09:59,279] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 730098

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:09:59,280] {logging_mixin.py:109} INFO - [2022-06-07 01:09:59,280] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:09:59,280] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:09:59,292] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 01:10:29,398] {processor.py:163} INFO - Started process (PID=731185) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:10:29,399] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:10:29,399] {logging_mixin.py:109} INFO - [2022-06-07 01:10:29,399] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:10:59,410] {logging_mixin.py:109} INFO - [2022-06-07 01:10:59,409] {timeout.py:36} ERROR - Process timed out, PID: 731185
[2022-06-07 01:10:59,411] {logging_mixin.py:109} INFO - [2022-06-07 01:10:59,410] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 731185
[2022-06-07 01:10:59,411] {logging_mixin.py:109} INFO - [2022-06-07 01:10:59,411] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:10:59,411] {logging_mixin.py:109} INFO - [2022-06-07 01:10:59,411] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 731185

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:10:59,412] {logging_mixin.py:109} INFO - [2022-06-07 01:10:59,411] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:10:59,412] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:10:59,424] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 01:11:29,612] {processor.py:163} INFO - Started process (PID=732278) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:11:29,612] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:11:29,613] {logging_mixin.py:109} INFO - [2022-06-07 01:11:29,613] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:11:59,619] {logging_mixin.py:109} INFO - [2022-06-07 01:11:59,619] {timeout.py:36} ERROR - Process timed out, PID: 732278
[2022-06-07 01:11:59,620] {logging_mixin.py:109} INFO - [2022-06-07 01:11:59,620] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 732278
[2022-06-07 01:11:59,620] {logging_mixin.py:109} INFO - [2022-06-07 01:11:59,620] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:11:59,621] {logging_mixin.py:109} INFO - [2022-06-07 01:11:59,620] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 732278

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:11:59,621] {logging_mixin.py:109} INFO - [2022-06-07 01:11:59,621] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:11:59,621] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:11:59,634] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 01:12:29,917] {processor.py:163} INFO - Started process (PID=733371) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:12:29,917] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:12:29,918] {logging_mixin.py:109} INFO - [2022-06-07 01:12:29,918] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:12:59,926] {logging_mixin.py:109} INFO - [2022-06-07 01:12:59,925] {timeout.py:36} ERROR - Process timed out, PID: 733371
[2022-06-07 01:12:59,926] {logging_mixin.py:109} INFO - [2022-06-07 01:12:59,926] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 733371
[2022-06-07 01:12:59,927] {logging_mixin.py:109} INFO - [2022-06-07 01:12:59,927] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:12:59,927] {logging_mixin.py:109} INFO - [2022-06-07 01:12:59,927] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 733371

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:12:59,927] {logging_mixin.py:109} INFO - [2022-06-07 01:12:59,927] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:12:59,928] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:12:59,938] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 01:13:30,138] {processor.py:163} INFO - Started process (PID=734465) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:13:30,139] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:13:30,139] {logging_mixin.py:109} INFO - [2022-06-07 01:13:30,139] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:14:00,149] {logging_mixin.py:109} INFO - [2022-06-07 01:14:00,149] {timeout.py:36} ERROR - Process timed out, PID: 734465
[2022-06-07 01:14:00,150] {logging_mixin.py:109} INFO - [2022-06-07 01:14:00,149] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 734465
[2022-06-07 01:14:00,150] {logging_mixin.py:109} INFO - [2022-06-07 01:14:00,150] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:14:00,150] {logging_mixin.py:109} INFO - [2022-06-07 01:14:00,150] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 734465

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:14:00,151] {logging_mixin.py:109} INFO - [2022-06-07 01:14:00,151] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:14:00,151] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:14:00,163] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 01:14:30,622] {processor.py:163} INFO - Started process (PID=735558) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:14:30,622] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:14:30,622] {logging_mixin.py:109} INFO - [2022-06-07 01:14:30,622] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:15:00,624] {logging_mixin.py:109} INFO - [2022-06-07 01:15:00,624] {timeout.py:36} ERROR - Process timed out, PID: 735558
[2022-06-07 01:15:00,625] {logging_mixin.py:109} INFO - [2022-06-07 01:15:00,625] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 735558
[2022-06-07 01:15:00,625] {logging_mixin.py:109} INFO - [2022-06-07 01:15:00,625] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:15:00,626] {logging_mixin.py:109} INFO - [2022-06-07 01:15:00,625] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 735558

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:15:00,626] {logging_mixin.py:109} INFO - [2022-06-07 01:15:00,626] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:15:00,626] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:15:00,638] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:15:30,900] {processor.py:163} INFO - Started process (PID=736651) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:15:30,900] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:15:30,900] {logging_mixin.py:109} INFO - [2022-06-07 01:15:30,900] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:16:00,902] {logging_mixin.py:109} INFO - [2022-06-07 01:16:00,902] {timeout.py:36} ERROR - Process timed out, PID: 736651
[2022-06-07 01:16:00,903] {logging_mixin.py:109} INFO - [2022-06-07 01:16:00,902] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 736651
[2022-06-07 01:16:00,903] {logging_mixin.py:109} INFO - [2022-06-07 01:16:00,903] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:16:00,903] {logging_mixin.py:109} INFO - [2022-06-07 01:16:00,903] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 736651

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:16:00,904] {logging_mixin.py:109} INFO - [2022-06-07 01:16:00,903] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:16:00,904] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:16:00,916] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:16:31,111] {processor.py:163} INFO - Started process (PID=737744) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:16:31,112] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:16:31,112] {logging_mixin.py:109} INFO - [2022-06-07 01:16:31,112] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:17:01,116] {logging_mixin.py:109} INFO - [2022-06-07 01:17:01,116] {timeout.py:36} ERROR - Process timed out, PID: 737744
[2022-06-07 01:17:01,117] {logging_mixin.py:109} INFO - [2022-06-07 01:17:01,116] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 737744
[2022-06-07 01:17:01,117] {logging_mixin.py:109} INFO - [2022-06-07 01:17:01,117] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:17:01,118] {logging_mixin.py:109} INFO - [2022-06-07 01:17:01,117] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 737744

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:17:01,118] {logging_mixin.py:109} INFO - [2022-06-07 01:17:01,118] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:17:01,118] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:17:01,129] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:17:31,500] {processor.py:163} INFO - Started process (PID=738838) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:17:31,500] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:17:31,500] {logging_mixin.py:109} INFO - [2022-06-07 01:17:31,500] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:18:01,503] {logging_mixin.py:109} INFO - [2022-06-07 01:18:01,503] {timeout.py:36} ERROR - Process timed out, PID: 738838
[2022-06-07 01:18:01,504] {logging_mixin.py:109} INFO - [2022-06-07 01:18:01,503] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 738838
[2022-06-07 01:18:01,504] {logging_mixin.py:109} INFO - [2022-06-07 01:18:01,504] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:18:01,504] {logging_mixin.py:109} INFO - [2022-06-07 01:18:01,504] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 738838

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:18:01,504] {logging_mixin.py:109} INFO - [2022-06-07 01:18:01,504] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:18:01,505] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:18:01,517] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:18:32,518] {processor.py:163} INFO - Started process (PID=739932) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:18:32,519] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:18:32,519] {logging_mixin.py:109} INFO - [2022-06-07 01:18:32,519] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:19:02,522] {logging_mixin.py:109} INFO - [2022-06-07 01:19:02,522] {timeout.py:36} ERROR - Process timed out, PID: 739932
[2022-06-07 01:19:02,523] {logging_mixin.py:109} INFO - [2022-06-07 01:19:02,522] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 739932
[2022-06-07 01:19:02,523] {logging_mixin.py:109} INFO - [2022-06-07 01:19:02,523] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:19:02,524] {logging_mixin.py:109} INFO - [2022-06-07 01:19:02,523] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 739932

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:19:02,524] {logging_mixin.py:109} INFO - [2022-06-07 01:19:02,524] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:19:02,524] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:19:02,535] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:19:32,647] {processor.py:163} INFO - Started process (PID=741026) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:19:32,648] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:19:32,648] {logging_mixin.py:109} INFO - [2022-06-07 01:19:32,648] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:20:02,650] {logging_mixin.py:109} INFO - [2022-06-07 01:20:02,649] {timeout.py:36} ERROR - Process timed out, PID: 741026
[2022-06-07 01:20:02,650] {logging_mixin.py:109} INFO - [2022-06-07 01:20:02,650] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 741026
[2022-06-07 01:20:02,650] {logging_mixin.py:109} INFO - [2022-06-07 01:20:02,650] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:20:02,651] {logging_mixin.py:109} INFO - [2022-06-07 01:20:02,650] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 741026

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:20:02,651] {logging_mixin.py:109} INFO - [2022-06-07 01:20:02,651] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:20:02,651] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:20:02,663] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 01:20:32,758] {processor.py:163} INFO - Started process (PID=742121) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:20:32,759] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:20:32,759] {logging_mixin.py:109} INFO - [2022-06-07 01:20:32,759] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:21:02,760] {logging_mixin.py:109} INFO - [2022-06-07 01:21:02,759] {timeout.py:36} ERROR - Process timed out, PID: 742121
[2022-06-07 01:21:02,760] {logging_mixin.py:109} INFO - [2022-06-07 01:21:02,760] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 742121
[2022-06-07 01:21:02,761] {logging_mixin.py:109} INFO - [2022-06-07 01:21:02,761] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:21:02,761] {logging_mixin.py:109} INFO - [2022-06-07 01:21:02,761] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 742121

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:21:02,762] {logging_mixin.py:109} INFO - [2022-06-07 01:21:02,761] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:21:02,762] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:21:02,774] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 01:21:32,926] {processor.py:163} INFO - Started process (PID=743214) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:21:32,926] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:21:32,926] {logging_mixin.py:109} INFO - [2022-06-07 01:21:32,926] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:22:02,929] {logging_mixin.py:109} INFO - [2022-06-07 01:22:02,928] {timeout.py:36} ERROR - Process timed out, PID: 743214
[2022-06-07 01:22:02,929] {logging_mixin.py:109} INFO - [2022-06-07 01:22:02,929] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 743214
[2022-06-07 01:22:02,929] {logging_mixin.py:109} INFO - [2022-06-07 01:22:02,929] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:22:02,930] {logging_mixin.py:109} INFO - [2022-06-07 01:22:02,930] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 743214

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:22:02,930] {logging_mixin.py:109} INFO - [2022-06-07 01:22:02,930] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:22:02,930] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:22:02,943] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:22:33,298] {processor.py:163} INFO - Started process (PID=744308) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:22:33,298] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:22:33,299] {logging_mixin.py:109} INFO - [2022-06-07 01:22:33,299] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:23:03,302] {logging_mixin.py:109} INFO - [2022-06-07 01:23:03,301] {timeout.py:36} ERROR - Process timed out, PID: 744308
[2022-06-07 01:23:03,302] {logging_mixin.py:109} INFO - [2022-06-07 01:23:03,302] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 744308
[2022-06-07 01:23:03,302] {logging_mixin.py:109} INFO - [2022-06-07 01:23:03,302] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:23:03,303] {logging_mixin.py:109} INFO - [2022-06-07 01:23:03,302] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 744308

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:23:03,303] {logging_mixin.py:109} INFO - [2022-06-07 01:23:03,303] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:23:03,303] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:23:03,315] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:23:33,388] {processor.py:163} INFO - Started process (PID=745382) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:23:33,389] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:23:33,389] {logging_mixin.py:109} INFO - [2022-06-07 01:23:33,389] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:24:03,396] {logging_mixin.py:109} INFO - [2022-06-07 01:24:03,396] {timeout.py:36} ERROR - Process timed out, PID: 745382
[2022-06-07 01:24:03,397] {logging_mixin.py:109} INFO - [2022-06-07 01:24:03,396] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 745382
[2022-06-07 01:24:03,397] {logging_mixin.py:109} INFO - [2022-06-07 01:24:03,397] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:24:03,397] {logging_mixin.py:109} INFO - [2022-06-07 01:24:03,397] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 745382

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:24:03,398] {logging_mixin.py:109} INFO - [2022-06-07 01:24:03,398] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:24:03,398] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:24:03,410] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 01:24:33,861] {processor.py:163} INFO - Started process (PID=746441) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:24:33,862] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:24:33,862] {logging_mixin.py:109} INFO - [2022-06-07 01:24:33,862] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:25:03,864] {logging_mixin.py:109} INFO - [2022-06-07 01:25:03,863] {timeout.py:36} ERROR - Process timed out, PID: 746441
[2022-06-07 01:25:03,864] {logging_mixin.py:109} INFO - [2022-06-07 01:25:03,864] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 746441
[2022-06-07 01:25:03,864] {logging_mixin.py:109} INFO - [2022-06-07 01:25:03,864] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:25:03,865] {logging_mixin.py:109} INFO - [2022-06-07 01:25:03,865] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 746441

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:25:03,865] {logging_mixin.py:109} INFO - [2022-06-07 01:25:03,865] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:25:03,866] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:25:03,877] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:25:34,035] {processor.py:163} INFO - Started process (PID=747534) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:25:34,036] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:25:34,036] {logging_mixin.py:109} INFO - [2022-06-07 01:25:34,036] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:26:04,042] {logging_mixin.py:109} INFO - [2022-06-07 01:26:04,042] {timeout.py:36} ERROR - Process timed out, PID: 747534
[2022-06-07 01:26:04,043] {logging_mixin.py:109} INFO - [2022-06-07 01:26:04,042] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 747534
[2022-06-07 01:26:04,043] {logging_mixin.py:109} INFO - [2022-06-07 01:26:04,043] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:26:04,043] {logging_mixin.py:109} INFO - [2022-06-07 01:26:04,043] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 747534

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:26:04,044] {logging_mixin.py:109} INFO - [2022-06-07 01:26:04,044] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:26:04,044] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:26:04,056] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 01:26:34,487] {processor.py:163} INFO - Started process (PID=748627) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:26:34,488] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:26:34,488] {logging_mixin.py:109} INFO - [2022-06-07 01:26:34,488] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:27:04,497] {logging_mixin.py:109} INFO - [2022-06-07 01:27:04,497] {timeout.py:36} ERROR - Process timed out, PID: 748627
[2022-06-07 01:27:04,498] {logging_mixin.py:109} INFO - [2022-06-07 01:27:04,498] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 748627
[2022-06-07 01:27:04,498] {logging_mixin.py:109} INFO - [2022-06-07 01:27:04,498] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:27:04,499] {logging_mixin.py:109} INFO - [2022-06-07 01:27:04,498] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 748627

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:27:04,499] {logging_mixin.py:109} INFO - [2022-06-07 01:27:04,499] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:27:04,499] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:27:04,511] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 01:27:34,800] {processor.py:163} INFO - Started process (PID=749720) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:27:34,801] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:27:34,801] {logging_mixin.py:109} INFO - [2022-06-07 01:27:34,801] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:28:04,804] {logging_mixin.py:109} INFO - [2022-06-07 01:28:04,803] {timeout.py:36} ERROR - Process timed out, PID: 749720
[2022-06-07 01:28:04,804] {logging_mixin.py:109} INFO - [2022-06-07 01:28:04,804] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 749720
[2022-06-07 01:28:04,804] {logging_mixin.py:109} INFO - [2022-06-07 01:28:04,804] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:28:04,805] {logging_mixin.py:109} INFO - [2022-06-07 01:28:04,804] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 749720

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:28:04,805] {logging_mixin.py:109} INFO - [2022-06-07 01:28:04,805] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:28:04,805] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:28:04,818] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:28:35,110] {processor.py:163} INFO - Started process (PID=750814) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:28:35,110] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:28:35,110] {logging_mixin.py:109} INFO - [2022-06-07 01:28:35,110] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:29:05,112] {logging_mixin.py:109} INFO - [2022-06-07 01:29:05,112] {timeout.py:36} ERROR - Process timed out, PID: 750814
[2022-06-07 01:29:05,113] {logging_mixin.py:109} INFO - [2022-06-07 01:29:05,112] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 750814
[2022-06-07 01:29:05,113] {logging_mixin.py:109} INFO - [2022-06-07 01:29:05,113] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:29:05,114] {logging_mixin.py:109} INFO - [2022-06-07 01:29:05,113] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 750814

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:29:05,114] {logging_mixin.py:109} INFO - [2022-06-07 01:29:05,114] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:29:05,114] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:29:05,126] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:29:35,337] {processor.py:163} INFO - Started process (PID=751896) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:29:35,338] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:29:35,338] {logging_mixin.py:109} INFO - [2022-06-07 01:29:35,338] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:30:05,362] {logging_mixin.py:109} INFO - [2022-06-07 01:30:05,362] {timeout.py:36} ERROR - Process timed out, PID: 751896
[2022-06-07 01:30:05,363] {logging_mixin.py:109} INFO - [2022-06-07 01:30:05,363] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 751896
[2022-06-07 01:30:05,363] {logging_mixin.py:109} INFO - [2022-06-07 01:30:05,363] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:30:05,364] {logging_mixin.py:109} INFO - [2022-06-07 01:30:05,364] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 751896

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:30:05,365] {logging_mixin.py:109} INFO - [2022-06-07 01:30:05,364] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:30:05,365] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:30:05,377] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.041 seconds
[2022-06-07 01:30:35,693] {processor.py:163} INFO - Started process (PID=752990) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:30:35,693] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:30:35,694] {logging_mixin.py:109} INFO - [2022-06-07 01:30:35,694] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:31:05,695] {logging_mixin.py:109} INFO - [2022-06-07 01:31:05,694] {timeout.py:36} ERROR - Process timed out, PID: 752990
[2022-06-07 01:31:05,695] {logging_mixin.py:109} INFO - [2022-06-07 01:31:05,695] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 752990
[2022-06-07 01:31:05,696] {logging_mixin.py:109} INFO - [2022-06-07 01:31:05,695] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:31:05,696] {logging_mixin.py:109} INFO - [2022-06-07 01:31:05,696] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 752990

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:31:05,696] {logging_mixin.py:109} INFO - [2022-06-07 01:31:05,696] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:31:05,697] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:31:05,707] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.015 seconds
[2022-06-07 01:31:35,957] {processor.py:163} INFO - Started process (PID=754083) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:31:35,957] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:31:35,958] {logging_mixin.py:109} INFO - [2022-06-07 01:31:35,958] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:32:05,963] {logging_mixin.py:109} INFO - [2022-06-07 01:32:05,963] {timeout.py:36} ERROR - Process timed out, PID: 754083
[2022-06-07 01:32:05,964] {logging_mixin.py:109} INFO - [2022-06-07 01:32:05,964] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 754083
[2022-06-07 01:32:05,964] {logging_mixin.py:109} INFO - [2022-06-07 01:32:05,964] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:32:05,965] {logging_mixin.py:109} INFO - [2022-06-07 01:32:05,964] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 754083

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:32:05,965] {logging_mixin.py:109} INFO - [2022-06-07 01:32:05,965] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:32:05,965] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:32:05,977] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 01:32:36,199] {processor.py:163} INFO - Started process (PID=755152) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:32:36,200] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:32:36,200] {logging_mixin.py:109} INFO - [2022-06-07 01:32:36,200] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:33:06,203] {logging_mixin.py:109} INFO - [2022-06-07 01:33:06,202] {timeout.py:36} ERROR - Process timed out, PID: 755152
[2022-06-07 01:33:06,203] {logging_mixin.py:109} INFO - [2022-06-07 01:33:06,203] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 755152
[2022-06-07 01:33:06,203] {logging_mixin.py:109} INFO - [2022-06-07 01:33:06,203] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:33:06,204] {logging_mixin.py:109} INFO - [2022-06-07 01:33:06,203] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 755152

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:33:06,204] {logging_mixin.py:109} INFO - [2022-06-07 01:33:06,204] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:33:06,204] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:33:06,216] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:33:36,486] {processor.py:163} INFO - Started process (PID=756241) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:33:36,486] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:33:36,487] {logging_mixin.py:109} INFO - [2022-06-07 01:33:36,486] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:34:06,492] {logging_mixin.py:109} INFO - [2022-06-07 01:34:06,492] {timeout.py:36} ERROR - Process timed out, PID: 756241
[2022-06-07 01:34:06,493] {logging_mixin.py:109} INFO - [2022-06-07 01:34:06,492] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 756241
[2022-06-07 01:34:06,493] {logging_mixin.py:109} INFO - [2022-06-07 01:34:06,493] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:34:06,494] {logging_mixin.py:109} INFO - [2022-06-07 01:34:06,493] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 756241

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:34:06,494] {logging_mixin.py:109} INFO - [2022-06-07 01:34:06,494] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:34:06,494] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:34:06,505] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 01:34:36,885] {processor.py:163} INFO - Started process (PID=757330) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:34:36,886] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:34:36,886] {logging_mixin.py:109} INFO - [2022-06-07 01:34:36,886] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:35:06,888] {logging_mixin.py:109} INFO - [2022-06-07 01:35:06,887] {timeout.py:36} ERROR - Process timed out, PID: 757330
[2022-06-07 01:35:06,888] {logging_mixin.py:109} INFO - [2022-06-07 01:35:06,888] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 757330
[2022-06-07 01:35:06,888] {logging_mixin.py:109} INFO - [2022-06-07 01:35:06,888] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:35:06,889] {logging_mixin.py:109} INFO - [2022-06-07 01:35:06,888] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 757330

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:35:06,889] {logging_mixin.py:109} INFO - [2022-06-07 01:35:06,889] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:35:06,889] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:35:06,901] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 01:35:37,130] {processor.py:163} INFO - Started process (PID=758424) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:35:37,131] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:35:37,131] {logging_mixin.py:109} INFO - [2022-06-07 01:35:37,131] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:36:07,134] {logging_mixin.py:109} INFO - [2022-06-07 01:36:07,133] {timeout.py:36} ERROR - Process timed out, PID: 758424
[2022-06-07 01:36:07,134] {logging_mixin.py:109} INFO - [2022-06-07 01:36:07,134] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 758424
[2022-06-07 01:36:07,134] {logging_mixin.py:109} INFO - [2022-06-07 01:36:07,134] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:36:07,135] {logging_mixin.py:109} INFO - [2022-06-07 01:36:07,134] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 758424

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:36:07,135] {logging_mixin.py:109} INFO - [2022-06-07 01:36:07,135] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:36:07,135] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:36:07,148] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:36:37,386] {processor.py:163} INFO - Started process (PID=759517) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:36:37,386] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:36:37,387] {logging_mixin.py:109} INFO - [2022-06-07 01:36:37,387] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:37:07,388] {logging_mixin.py:109} INFO - [2022-06-07 01:37:07,387] {timeout.py:36} ERROR - Process timed out, PID: 759517
[2022-06-07 01:37:07,388] {logging_mixin.py:109} INFO - [2022-06-07 01:37:07,388] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 759517
[2022-06-07 01:37:07,388] {logging_mixin.py:109} INFO - [2022-06-07 01:37:07,388] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:37:07,389] {logging_mixin.py:109} INFO - [2022-06-07 01:37:07,388] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 759517

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:37:07,389] {logging_mixin.py:109} INFO - [2022-06-07 01:37:07,389] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:37:07,389] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:37:07,401] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 01:37:37,717] {processor.py:163} INFO - Started process (PID=760610) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:37:37,718] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:37:37,718] {logging_mixin.py:109} INFO - [2022-06-07 01:37:37,718] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:38:07,720] {logging_mixin.py:109} INFO - [2022-06-07 01:38:07,719] {timeout.py:36} ERROR - Process timed out, PID: 760610
[2022-06-07 01:38:07,720] {logging_mixin.py:109} INFO - [2022-06-07 01:38:07,720] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 760610
[2022-06-07 01:38:07,721] {logging_mixin.py:109} INFO - [2022-06-07 01:38:07,721] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:38:07,721] {logging_mixin.py:109} INFO - [2022-06-07 01:38:07,721] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 760610

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:38:07,722] {logging_mixin.py:109} INFO - [2022-06-07 01:38:07,721] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:38:07,722] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:38:07,733] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 01:38:37,801] {processor.py:163} INFO - Started process (PID=761670) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:38:37,802] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:38:37,802] {logging_mixin.py:109} INFO - [2022-06-07 01:38:37,802] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:39:07,806] {logging_mixin.py:109} INFO - [2022-06-07 01:39:07,805] {timeout.py:36} ERROR - Process timed out, PID: 761670
[2022-06-07 01:39:07,806] {logging_mixin.py:109} INFO - [2022-06-07 01:39:07,806] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 761670
[2022-06-07 01:39:07,806] {logging_mixin.py:109} INFO - [2022-06-07 01:39:07,806] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:39:07,807] {logging_mixin.py:109} INFO - [2022-06-07 01:39:07,806] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 761670

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:39:07,807] {logging_mixin.py:109} INFO - [2022-06-07 01:39:07,807] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:39:07,808] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:39:07,819] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:39:38,038] {processor.py:163} INFO - Started process (PID=762766) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:39:38,039] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:39:38,039] {logging_mixin.py:109} INFO - [2022-06-07 01:39:38,039] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:40:08,042] {logging_mixin.py:109} INFO - [2022-06-07 01:40:08,041] {timeout.py:36} ERROR - Process timed out, PID: 762766
[2022-06-07 01:40:08,042] {logging_mixin.py:109} INFO - [2022-06-07 01:40:08,042] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 762766
[2022-06-07 01:40:08,043] {logging_mixin.py:109} INFO - [2022-06-07 01:40:08,042] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:40:08,043] {logging_mixin.py:109} INFO - [2022-06-07 01:40:08,043] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 762766

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:40:08,043] {logging_mixin.py:109} INFO - [2022-06-07 01:40:08,043] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:40:08,044] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:40:08,056] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:40:38,394] {processor.py:163} INFO - Started process (PID=763860) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:40:38,395] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:40:38,395] {logging_mixin.py:109} INFO - [2022-06-07 01:40:38,395] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:41:08,396] {logging_mixin.py:109} INFO - [2022-06-07 01:41:08,395] {timeout.py:36} ERROR - Process timed out, PID: 763860
[2022-06-07 01:41:08,396] {logging_mixin.py:109} INFO - [2022-06-07 01:41:08,396] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 763860
[2022-06-07 01:41:08,396] {logging_mixin.py:109} INFO - [2022-06-07 01:41:08,396] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:41:08,397] {logging_mixin.py:109} INFO - [2022-06-07 01:41:08,397] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 763860

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:41:08,397] {logging_mixin.py:109} INFO - [2022-06-07 01:41:08,397] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:41:08,398] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:41:08,409] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 01:41:38,516] {processor.py:163} INFO - Started process (PID=764945) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:41:38,516] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:41:38,517] {logging_mixin.py:109} INFO - [2022-06-07 01:41:38,517] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:42:08,519] {logging_mixin.py:109} INFO - [2022-06-07 01:42:08,519] {timeout.py:36} ERROR - Process timed out, PID: 764945
[2022-06-07 01:42:08,520] {logging_mixin.py:109} INFO - [2022-06-07 01:42:08,519] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 764945
[2022-06-07 01:42:08,520] {logging_mixin.py:109} INFO - [2022-06-07 01:42:08,520] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:42:08,520] {logging_mixin.py:109} INFO - [2022-06-07 01:42:08,520] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 764945

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:42:08,521] {logging_mixin.py:109} INFO - [2022-06-07 01:42:08,520] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:42:08,521] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:42:08,533] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:42:38,777] {processor.py:163} INFO - Started process (PID=766028) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:42:38,778] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:42:38,778] {logging_mixin.py:109} INFO - [2022-06-07 01:42:38,778] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:43:08,780] {logging_mixin.py:109} INFO - [2022-06-07 01:43:08,779] {timeout.py:36} ERROR - Process timed out, PID: 766028
[2022-06-07 01:43:08,780] {logging_mixin.py:109} INFO - [2022-06-07 01:43:08,780] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 766028
[2022-06-07 01:43:08,780] {logging_mixin.py:109} INFO - [2022-06-07 01:43:08,780] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:43:08,781] {logging_mixin.py:109} INFO - [2022-06-07 01:43:08,781] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 766028

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:43:08,781] {logging_mixin.py:109} INFO - [2022-06-07 01:43:08,781] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:43:08,782] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:43:08,793] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:43:39,014] {processor.py:163} INFO - Started process (PID=767112) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:43:39,015] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:43:39,015] {logging_mixin.py:109} INFO - [2022-06-07 01:43:39,015] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:44:09,019] {logging_mixin.py:109} INFO - [2022-06-07 01:44:09,018] {timeout.py:36} ERROR - Process timed out, PID: 767112
[2022-06-07 01:44:09,019] {logging_mixin.py:109} INFO - [2022-06-07 01:44:09,019] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 767112
[2022-06-07 01:44:09,020] {logging_mixin.py:109} INFO - [2022-06-07 01:44:09,020] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:44:09,020] {logging_mixin.py:109} INFO - [2022-06-07 01:44:09,020] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 767112

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:44:09,020] {logging_mixin.py:109} INFO - [2022-06-07 01:44:09,020] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:44:09,021] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:44:09,032] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 01:44:39,161] {processor.py:163} INFO - Started process (PID=768204) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:44:39,161] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:44:39,161] {logging_mixin.py:109} INFO - [2022-06-07 01:44:39,161] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:45:09,164] {logging_mixin.py:109} INFO - [2022-06-07 01:45:09,163] {timeout.py:36} ERROR - Process timed out, PID: 768204
[2022-06-07 01:45:09,164] {logging_mixin.py:109} INFO - [2022-06-07 01:45:09,164] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 768204
[2022-06-07 01:45:09,165] {logging_mixin.py:109} INFO - [2022-06-07 01:45:09,165] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:45:09,165] {logging_mixin.py:109} INFO - [2022-06-07 01:45:09,165] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 768204

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:45:09,166] {logging_mixin.py:109} INFO - [2022-06-07 01:45:09,165] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:45:09,166] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:45:09,177] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:45:39,461] {processor.py:163} INFO - Started process (PID=769299) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:45:39,462] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:45:39,462] {logging_mixin.py:109} INFO - [2022-06-07 01:45:39,462] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:46:09,463] {logging_mixin.py:109} INFO - [2022-06-07 01:46:09,462] {timeout.py:36} ERROR - Process timed out, PID: 769299
[2022-06-07 01:46:09,463] {logging_mixin.py:109} INFO - [2022-06-07 01:46:09,463] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 769299
[2022-06-07 01:46:09,464] {logging_mixin.py:109} INFO - [2022-06-07 01:46:09,464] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:46:09,464] {logging_mixin.py:109} INFO - [2022-06-07 01:46:09,464] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 769299

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:46:09,465] {logging_mixin.py:109} INFO - [2022-06-07 01:46:09,465] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:46:09,465] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:46:09,478] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:46:39,752] {processor.py:163} INFO - Started process (PID=770392) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:46:39,752] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:46:39,752] {logging_mixin.py:109} INFO - [2022-06-07 01:46:39,752] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:47:09,762] {logging_mixin.py:109} INFO - [2022-06-07 01:47:09,762] {timeout.py:36} ERROR - Process timed out, PID: 770392
[2022-06-07 01:47:09,763] {logging_mixin.py:109} INFO - [2022-06-07 01:47:09,763] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 770392
[2022-06-07 01:47:09,763] {logging_mixin.py:109} INFO - [2022-06-07 01:47:09,763] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:47:09,764] {logging_mixin.py:109} INFO - [2022-06-07 01:47:09,763] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 770392

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:47:09,764] {logging_mixin.py:109} INFO - [2022-06-07 01:47:09,764] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:47:09,764] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:47:09,776] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 01:47:39,992] {processor.py:163} INFO - Started process (PID=771486) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:47:39,993] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:47:39,993] {logging_mixin.py:109} INFO - [2022-06-07 01:47:39,993] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:48:09,995] {logging_mixin.py:109} INFO - [2022-06-07 01:48:09,994] {timeout.py:36} ERROR - Process timed out, PID: 771486
[2022-06-07 01:48:09,995] {logging_mixin.py:109} INFO - [2022-06-07 01:48:09,995] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 771486
[2022-06-07 01:48:09,995] {logging_mixin.py:109} INFO - [2022-06-07 01:48:09,995] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:48:09,996] {logging_mixin.py:109} INFO - [2022-06-07 01:48:09,995] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 771486

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:48:09,996] {logging_mixin.py:109} INFO - [2022-06-07 01:48:09,996] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:48:09,996] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:48:10,008] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 01:48:40,213] {processor.py:163} INFO - Started process (PID=772581) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:48:40,213] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:48:40,213] {logging_mixin.py:109} INFO - [2022-06-07 01:48:40,213] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:49:10,232] {logging_mixin.py:109} INFO - [2022-06-07 01:49:10,232] {timeout.py:36} ERROR - Process timed out, PID: 772581
[2022-06-07 01:49:10,233] {logging_mixin.py:109} INFO - [2022-06-07 01:49:10,232] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 772581
[2022-06-07 01:49:10,233] {logging_mixin.py:109} INFO - [2022-06-07 01:49:10,233] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:49:10,234] {logging_mixin.py:109} INFO - [2022-06-07 01:49:10,233] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 772581

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:49:10,234] {logging_mixin.py:109} INFO - [2022-06-07 01:49:10,234] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:49:10,234] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:49:10,246] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.034 seconds
[2022-06-07 01:49:40,422] {processor.py:163} INFO - Started process (PID=773675) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:49:40,422] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:49:40,423] {logging_mixin.py:109} INFO - [2022-06-07 01:49:40,423] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:50:10,425] {logging_mixin.py:109} INFO - [2022-06-07 01:50:10,424] {timeout.py:36} ERROR - Process timed out, PID: 773675
[2022-06-07 01:50:10,425] {logging_mixin.py:109} INFO - [2022-06-07 01:50:10,425] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 773675
[2022-06-07 01:50:10,426] {logging_mixin.py:109} INFO - [2022-06-07 01:50:10,426] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:50:10,426] {logging_mixin.py:109} INFO - [2022-06-07 01:50:10,426] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 773675

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:50:10,426] {logging_mixin.py:109} INFO - [2022-06-07 01:50:10,426] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:50:10,427] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:50:10,438] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:50:40,614] {processor.py:163} INFO - Started process (PID=774770) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:50:40,614] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:50:40,615] {logging_mixin.py:109} INFO - [2022-06-07 01:50:40,614] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:51:10,617] {logging_mixin.py:109} INFO - [2022-06-07 01:51:10,617] {timeout.py:36} ERROR - Process timed out, PID: 774770
[2022-06-07 01:51:10,618] {logging_mixin.py:109} INFO - [2022-06-07 01:51:10,618] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 774770
[2022-06-07 01:51:10,618] {logging_mixin.py:109} INFO - [2022-06-07 01:51:10,618] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:51:10,619] {logging_mixin.py:109} INFO - [2022-06-07 01:51:10,618] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 774770

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:51:10,619] {logging_mixin.py:109} INFO - [2022-06-07 01:51:10,619] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:51:10,619] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:51:10,633] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 01:51:40,988] {processor.py:163} INFO - Started process (PID=775865) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:51:40,988] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:51:40,989] {logging_mixin.py:109} INFO - [2022-06-07 01:51:40,989] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:52:10,991] {logging_mixin.py:109} INFO - [2022-06-07 01:52:10,990] {timeout.py:36} ERROR - Process timed out, PID: 775865
[2022-06-07 01:52:10,991] {logging_mixin.py:109} INFO - [2022-06-07 01:52:10,991] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 775865
[2022-06-07 01:52:10,991] {logging_mixin.py:109} INFO - [2022-06-07 01:52:10,991] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:52:10,992] {logging_mixin.py:109} INFO - [2022-06-07 01:52:10,992] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 775865

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:52:10,992] {logging_mixin.py:109} INFO - [2022-06-07 01:52:10,992] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:52:10,992] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:52:11,005] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 01:52:41,312] {processor.py:163} INFO - Started process (PID=776958) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:52:41,313] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:52:41,313] {logging_mixin.py:109} INFO - [2022-06-07 01:52:41,313] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:53:11,314] {logging_mixin.py:109} INFO - [2022-06-07 01:53:11,314] {timeout.py:36} ERROR - Process timed out, PID: 776958
[2022-06-07 01:53:11,315] {logging_mixin.py:109} INFO - [2022-06-07 01:53:11,315] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 776958
[2022-06-07 01:53:11,315] {logging_mixin.py:109} INFO - [2022-06-07 01:53:11,315] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:53:11,316] {logging_mixin.py:109} INFO - [2022-06-07 01:53:11,315] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 776958

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:53:11,316] {logging_mixin.py:109} INFO - [2022-06-07 01:53:11,316] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:53:11,316] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:53:11,328] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:53:41,479] {processor.py:163} INFO - Started process (PID=778035) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:53:41,479] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:53:41,479] {logging_mixin.py:109} INFO - [2022-06-07 01:53:41,479] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:54:11,487] {logging_mixin.py:109} INFO - [2022-06-07 01:54:11,487] {timeout.py:36} ERROR - Process timed out, PID: 778035
[2022-06-07 01:54:11,488] {logging_mixin.py:109} INFO - [2022-06-07 01:54:11,487] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 778035
[2022-06-07 01:54:11,488] {logging_mixin.py:109} INFO - [2022-06-07 01:54:11,488] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:54:11,488] {logging_mixin.py:109} INFO - [2022-06-07 01:54:11,488] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 778035

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:54:11,489] {logging_mixin.py:109} INFO - [2022-06-07 01:54:11,488] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:54:11,489] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:54:11,500] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 01:54:41,941] {processor.py:163} INFO - Started process (PID=779089) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:54:41,941] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:54:41,942] {logging_mixin.py:109} INFO - [2022-06-07 01:54:41,942] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:55:11,943] {logging_mixin.py:109} INFO - [2022-06-07 01:55:11,943] {timeout.py:36} ERROR - Process timed out, PID: 779089
[2022-06-07 01:55:11,944] {logging_mixin.py:109} INFO - [2022-06-07 01:55:11,943] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 779089
[2022-06-07 01:55:11,944] {logging_mixin.py:109} INFO - [2022-06-07 01:55:11,944] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:55:11,944] {logging_mixin.py:109} INFO - [2022-06-07 01:55:11,944] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 779089

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:55:11,945] {logging_mixin.py:109} INFO - [2022-06-07 01:55:11,944] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:55:11,945] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:55:11,957] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:55:42,243] {processor.py:163} INFO - Started process (PID=780182) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:55:42,244] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:55:42,244] {logging_mixin.py:109} INFO - [2022-06-07 01:55:42,244] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:56:12,246] {logging_mixin.py:109} INFO - [2022-06-07 01:56:12,245] {timeout.py:36} ERROR - Process timed out, PID: 780182
[2022-06-07 01:56:12,246] {logging_mixin.py:109} INFO - [2022-06-07 01:56:12,246] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 780182
[2022-06-07 01:56:12,246] {logging_mixin.py:109} INFO - [2022-06-07 01:56:12,246] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:56:12,247] {logging_mixin.py:109} INFO - [2022-06-07 01:56:12,246] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 780182

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:56:12,247] {logging_mixin.py:109} INFO - [2022-06-07 01:56:12,247] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:56:12,247] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:56:12,260] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:56:42,551] {processor.py:163} INFO - Started process (PID=781276) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:56:42,552] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:56:42,552] {logging_mixin.py:109} INFO - [2022-06-07 01:56:42,552] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:57:12,561] {logging_mixin.py:109} INFO - [2022-06-07 01:57:12,561] {timeout.py:36} ERROR - Process timed out, PID: 781276
[2022-06-07 01:57:12,562] {logging_mixin.py:109} INFO - [2022-06-07 01:57:12,561] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 781276
[2022-06-07 01:57:12,562] {logging_mixin.py:109} INFO - [2022-06-07 01:57:12,562] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:57:12,562] {logging_mixin.py:109} INFO - [2022-06-07 01:57:12,562] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 781276

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:57:12,563] {logging_mixin.py:109} INFO - [2022-06-07 01:57:12,562] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:57:12,563] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:57:12,575] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 01:57:42,999] {processor.py:163} INFO - Started process (PID=782369) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:57:42,999] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:57:43,000] {logging_mixin.py:109} INFO - [2022-06-07 01:57:43,000] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:58:13,007] {logging_mixin.py:109} INFO - [2022-06-07 01:58:13,007] {timeout.py:36} ERROR - Process timed out, PID: 782369
[2022-06-07 01:58:13,008] {logging_mixin.py:109} INFO - [2022-06-07 01:58:13,007] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 782369
[2022-06-07 01:58:13,008] {logging_mixin.py:109} INFO - [2022-06-07 01:58:13,008] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:58:13,009] {logging_mixin.py:109} INFO - [2022-06-07 01:58:13,008] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 782369

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:58:13,009] {logging_mixin.py:109} INFO - [2022-06-07 01:58:13,009] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:58:13,009] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:58:13,022] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 01:58:43,428] {processor.py:163} INFO - Started process (PID=783463) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:58:43,428] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:58:43,429] {logging_mixin.py:109} INFO - [2022-06-07 01:58:43,429] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:59:13,431] {logging_mixin.py:109} INFO - [2022-06-07 01:59:13,430] {timeout.py:36} ERROR - Process timed out, PID: 783463
[2022-06-07 01:59:13,431] {logging_mixin.py:109} INFO - [2022-06-07 01:59:13,431] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 783463
[2022-06-07 01:59:13,431] {logging_mixin.py:109} INFO - [2022-06-07 01:59:13,431] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 01:59:13,432] {logging_mixin.py:109} INFO - [2022-06-07 01:59:13,431] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 783463

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 01:59:13,432] {logging_mixin.py:109} INFO - [2022-06-07 01:59:13,432] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 01:59:13,432] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 01:59:13,445] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 01:59:43,749] {processor.py:163} INFO - Started process (PID=784557) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 01:59:43,750] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 01:59:43,750] {logging_mixin.py:109} INFO - [2022-06-07 01:59:43,750] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:00:13,752] {logging_mixin.py:109} INFO - [2022-06-07 02:00:13,752] {timeout.py:36} ERROR - Process timed out, PID: 784557
[2022-06-07 02:00:13,753] {logging_mixin.py:109} INFO - [2022-06-07 02:00:13,752] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 784557
[2022-06-07 02:00:13,753] {logging_mixin.py:109} INFO - [2022-06-07 02:00:13,753] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:00:13,753] {logging_mixin.py:109} INFO - [2022-06-07 02:00:13,753] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 784557

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:00:13,754] {logging_mixin.py:109} INFO - [2022-06-07 02:00:13,754] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:00:13,754] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:00:13,765] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:00:44,005] {processor.py:163} INFO - Started process (PID=785650) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:00:44,005] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:00:44,006] {logging_mixin.py:109} INFO - [2022-06-07 02:00:44,006] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:01:14,007] {logging_mixin.py:109} INFO - [2022-06-07 02:01:14,007] {timeout.py:36} ERROR - Process timed out, PID: 785650
[2022-06-07 02:01:14,008] {logging_mixin.py:109} INFO - [2022-06-07 02:01:14,007] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 785650
[2022-06-07 02:01:14,008] {logging_mixin.py:109} INFO - [2022-06-07 02:01:14,008] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:01:14,008] {logging_mixin.py:109} INFO - [2022-06-07 02:01:14,008] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 785650

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:01:14,009] {logging_mixin.py:109} INFO - [2022-06-07 02:01:14,008] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:01:14,009] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:01:14,022] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:01:44,982] {processor.py:163} INFO - Started process (PID=786745) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:01:44,982] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:01:44,982] {logging_mixin.py:109} INFO - [2022-06-07 02:01:44,982] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:02:14,983] {logging_mixin.py:109} INFO - [2022-06-07 02:02:14,983] {timeout.py:36} ERROR - Process timed out, PID: 786745
[2022-06-07 02:02:14,984] {logging_mixin.py:109} INFO - [2022-06-07 02:02:14,983] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 786745
[2022-06-07 02:02:14,984] {logging_mixin.py:109} INFO - [2022-06-07 02:02:14,984] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:02:14,984] {logging_mixin.py:109} INFO - [2022-06-07 02:02:14,984] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 786745

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:02:14,985] {logging_mixin.py:109} INFO - [2022-06-07 02:02:14,984] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:02:14,985] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:02:14,996] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 02:02:45,275] {processor.py:163} INFO - Started process (PID=787842) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:02:45,276] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:02:45,276] {logging_mixin.py:109} INFO - [2022-06-07 02:02:45,276] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:03:15,277] {logging_mixin.py:109} INFO - [2022-06-07 02:03:15,277] {timeout.py:36} ERROR - Process timed out, PID: 787842
[2022-06-07 02:03:15,278] {logging_mixin.py:109} INFO - [2022-06-07 02:03:15,277] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 787842
[2022-06-07 02:03:15,278] {logging_mixin.py:109} INFO - [2022-06-07 02:03:15,278] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:03:15,278] {logging_mixin.py:109} INFO - [2022-06-07 02:03:15,278] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 787842

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:03:15,279] {logging_mixin.py:109} INFO - [2022-06-07 02:03:15,278] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:03:15,279] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:03:15,291] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:03:46,116] {processor.py:163} INFO - Started process (PID=788936) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:03:46,117] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:03:46,117] {logging_mixin.py:109} INFO - [2022-06-07 02:03:46,117] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:04:16,118] {logging_mixin.py:109} INFO - [2022-06-07 02:04:16,118] {timeout.py:36} ERROR - Process timed out, PID: 788936
[2022-06-07 02:04:16,119] {logging_mixin.py:109} INFO - [2022-06-07 02:04:16,118] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 788936
[2022-06-07 02:04:16,119] {logging_mixin.py:109} INFO - [2022-06-07 02:04:16,119] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:04:16,120] {logging_mixin.py:109} INFO - [2022-06-07 02:04:16,119] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 788936

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:04:16,120] {logging_mixin.py:109} INFO - [2022-06-07 02:04:16,120] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:04:16,120] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:04:16,133] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:04:46,170] {processor.py:163} INFO - Started process (PID=789996) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:04:46,171] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:04:46,171] {logging_mixin.py:109} INFO - [2022-06-07 02:04:46,171] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:05:16,174] {logging_mixin.py:109} INFO - [2022-06-07 02:05:16,173] {timeout.py:36} ERROR - Process timed out, PID: 789996
[2022-06-07 02:05:16,174] {logging_mixin.py:109} INFO - [2022-06-07 02:05:16,174] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 789996
[2022-06-07 02:05:16,174] {logging_mixin.py:109} INFO - [2022-06-07 02:05:16,174] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:05:16,175] {logging_mixin.py:109} INFO - [2022-06-07 02:05:16,174] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 789996

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:05:16,175] {logging_mixin.py:109} INFO - [2022-06-07 02:05:16,175] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:05:16,175] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:05:16,187] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:05:46,630] {processor.py:163} INFO - Started process (PID=791090) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:05:46,631] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:05:46,631] {logging_mixin.py:109} INFO - [2022-06-07 02:05:46,631] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:06:16,634] {logging_mixin.py:109} INFO - [2022-06-07 02:06:16,633] {timeout.py:36} ERROR - Process timed out, PID: 791090
[2022-06-07 02:06:16,634] {logging_mixin.py:109} INFO - [2022-06-07 02:06:16,634] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 791090
[2022-06-07 02:06:16,634] {logging_mixin.py:109} INFO - [2022-06-07 02:06:16,634] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:06:16,635] {logging_mixin.py:109} INFO - [2022-06-07 02:06:16,634] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 791090

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:06:16,635] {logging_mixin.py:109} INFO - [2022-06-07 02:06:16,635] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:06:16,635] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:06:16,648] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 02:06:47,088] {processor.py:163} INFO - Started process (PID=792184) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:06:47,088] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:06:47,089] {logging_mixin.py:109} INFO - [2022-06-07 02:06:47,089] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:07:17,095] {logging_mixin.py:109} INFO - [2022-06-07 02:07:17,095] {timeout.py:36} ERROR - Process timed out, PID: 792184
[2022-06-07 02:07:17,096] {logging_mixin.py:109} INFO - [2022-06-07 02:07:17,096] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 792184
[2022-06-07 02:07:17,096] {logging_mixin.py:109} INFO - [2022-06-07 02:07:17,096] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:07:17,097] {logging_mixin.py:109} INFO - [2022-06-07 02:07:17,096] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 792184

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:07:17,097] {logging_mixin.py:109} INFO - [2022-06-07 02:07:17,097] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:07:17,097] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:07:17,109] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 02:07:47,394] {processor.py:163} INFO - Started process (PID=793278) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:07:47,395] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:07:47,395] {logging_mixin.py:109} INFO - [2022-06-07 02:07:47,395] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:08:17,397] {logging_mixin.py:109} INFO - [2022-06-07 02:08:17,396] {timeout.py:36} ERROR - Process timed out, PID: 793278
[2022-06-07 02:08:17,398] {logging_mixin.py:109} INFO - [2022-06-07 02:08:17,397] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 793278
[2022-06-07 02:08:17,398] {logging_mixin.py:109} INFO - [2022-06-07 02:08:17,398] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:08:17,398] {logging_mixin.py:109} INFO - [2022-06-07 02:08:17,398] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 793278

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:08:17,398] {logging_mixin.py:109} INFO - [2022-06-07 02:08:17,398] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:08:17,399] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:08:17,411] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:08:47,972] {processor.py:163} INFO - Started process (PID=794373) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:08:47,972] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:08:47,973] {logging_mixin.py:109} INFO - [2022-06-07 02:08:47,973] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:09:17,974] {logging_mixin.py:109} INFO - [2022-06-07 02:09:17,973] {timeout.py:36} ERROR - Process timed out, PID: 794373
[2022-06-07 02:09:17,974] {logging_mixin.py:109} INFO - [2022-06-07 02:09:17,974] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 794373
[2022-06-07 02:09:17,975] {logging_mixin.py:109} INFO - [2022-06-07 02:09:17,974] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:09:17,975] {logging_mixin.py:109} INFO - [2022-06-07 02:09:17,975] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 794373

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:09:17,975] {logging_mixin.py:109} INFO - [2022-06-07 02:09:17,975] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:09:17,976] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:09:17,987] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:09:48,215] {processor.py:163} INFO - Started process (PID=795456) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:09:48,215] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:09:48,215] {logging_mixin.py:109} INFO - [2022-06-07 02:09:48,215] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:10:18,217] {logging_mixin.py:109} INFO - [2022-06-07 02:10:18,216] {timeout.py:36} ERROR - Process timed out, PID: 795456
[2022-06-07 02:10:18,217] {logging_mixin.py:109} INFO - [2022-06-07 02:10:18,217] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 795456
[2022-06-07 02:10:18,217] {logging_mixin.py:109} INFO - [2022-06-07 02:10:18,217] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:10:18,218] {logging_mixin.py:109} INFO - [2022-06-07 02:10:18,217] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 795456

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:10:18,218] {logging_mixin.py:109} INFO - [2022-06-07 02:10:18,218] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:10:18,218] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:10:18,229] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 02:10:48,412] {processor.py:163} INFO - Started process (PID=796543) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:10:48,413] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:10:48,413] {logging_mixin.py:109} INFO - [2022-06-07 02:10:48,413] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:11:18,416] {logging_mixin.py:109} INFO - [2022-06-07 02:11:18,415] {timeout.py:36} ERROR - Process timed out, PID: 796543
[2022-06-07 02:11:18,417] {logging_mixin.py:109} INFO - [2022-06-07 02:11:18,416] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 796543
[2022-06-07 02:11:18,417] {logging_mixin.py:109} INFO - [2022-06-07 02:11:18,417] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:11:18,417] {logging_mixin.py:109} INFO - [2022-06-07 02:11:18,417] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 796543

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:11:18,418] {logging_mixin.py:109} INFO - [2022-06-07 02:11:18,417] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:11:18,418] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:11:18,430] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 02:11:49,072] {processor.py:163} INFO - Started process (PID=797609) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:11:49,072] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:11:49,072] {logging_mixin.py:109} INFO - [2022-06-07 02:11:49,072] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:12:19,075] {logging_mixin.py:109} INFO - [2022-06-07 02:12:19,075] {timeout.py:36} ERROR - Process timed out, PID: 797609
[2022-06-07 02:12:19,076] {logging_mixin.py:109} INFO - [2022-06-07 02:12:19,075] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 797609
[2022-06-07 02:12:19,076] {logging_mixin.py:109} INFO - [2022-06-07 02:12:19,076] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:12:19,076] {logging_mixin.py:109} INFO - [2022-06-07 02:12:19,076] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 797609

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:12:19,077] {logging_mixin.py:109} INFO - [2022-06-07 02:12:19,077] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:12:19,077] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:12:19,089] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 02:12:49,310] {processor.py:163} INFO - Started process (PID=798705) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:12:49,310] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:12:49,311] {logging_mixin.py:109} INFO - [2022-06-07 02:12:49,311] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:13:19,312] {logging_mixin.py:109} INFO - [2022-06-07 02:13:19,312] {timeout.py:36} ERROR - Process timed out, PID: 798705
[2022-06-07 02:13:19,318] {logging_mixin.py:109} INFO - [2022-06-07 02:13:19,312] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 798705
[2022-06-07 02:13:19,318] {logging_mixin.py:109} INFO - [2022-06-07 02:13:19,318] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:13:19,318] {logging_mixin.py:109} INFO - [2022-06-07 02:13:19,318] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 798705

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:13:19,319] {logging_mixin.py:109} INFO - [2022-06-07 02:13:19,319] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:13:19,319] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:13:19,331] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 02:13:49,586] {processor.py:163} INFO - Started process (PID=799798) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:13:49,587] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:13:49,587] {logging_mixin.py:109} INFO - [2022-06-07 02:13:49,587] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:14:19,602] {logging_mixin.py:109} INFO - [2022-06-07 02:14:19,602] {timeout.py:36} ERROR - Process timed out, PID: 799798
[2022-06-07 02:14:19,603] {logging_mixin.py:109} INFO - [2022-06-07 02:14:19,602] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 799798
[2022-06-07 02:14:19,603] {logging_mixin.py:109} INFO - [2022-06-07 02:14:19,603] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:14:19,603] {logging_mixin.py:109} INFO - [2022-06-07 02:14:19,603] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 799798

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:14:19,604] {logging_mixin.py:109} INFO - [2022-06-07 02:14:19,603] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:14:19,604] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:14:19,616] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.031 seconds
[2022-06-07 02:14:50,103] {processor.py:163} INFO - Started process (PID=800894) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:14:50,103] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:14:50,103] {logging_mixin.py:109} INFO - [2022-06-07 02:14:50,103] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:15:20,106] {logging_mixin.py:109} INFO - [2022-06-07 02:15:20,106] {timeout.py:36} ERROR - Process timed out, PID: 800894
[2022-06-07 02:15:20,107] {logging_mixin.py:109} INFO - [2022-06-07 02:15:20,106] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 800894
[2022-06-07 02:15:20,107] {logging_mixin.py:109} INFO - [2022-06-07 02:15:20,107] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:15:20,107] {logging_mixin.py:109} INFO - [2022-06-07 02:15:20,107] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 800894

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:15:20,108] {logging_mixin.py:109} INFO - [2022-06-07 02:15:20,108] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:15:20,108] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:15:20,120] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 02:15:50,613] {processor.py:163} INFO - Started process (PID=801987) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:15:50,613] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:15:50,613] {logging_mixin.py:109} INFO - [2022-06-07 02:15:50,613] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:16:20,615] {logging_mixin.py:109} INFO - [2022-06-07 02:16:20,614] {timeout.py:36} ERROR - Process timed out, PID: 801987
[2022-06-07 02:16:20,615] {logging_mixin.py:109} INFO - [2022-06-07 02:16:20,615] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 801987
[2022-06-07 02:16:20,615] {logging_mixin.py:109} INFO - [2022-06-07 02:16:20,615] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:16:20,616] {logging_mixin.py:109} INFO - [2022-06-07 02:16:20,616] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 801987

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:16:20,616] {logging_mixin.py:109} INFO - [2022-06-07 02:16:20,616] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:16:20,617] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:16:20,628] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:16:50,873] {processor.py:163} INFO - Started process (PID=803081) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:16:50,874] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:16:50,874] {logging_mixin.py:109} INFO - [2022-06-07 02:16:50,874] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:17:20,876] {logging_mixin.py:109} INFO - [2022-06-07 02:17:20,875] {timeout.py:36} ERROR - Process timed out, PID: 803081
[2022-06-07 02:17:20,876] {logging_mixin.py:109} INFO - [2022-06-07 02:17:20,876] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 803081
[2022-06-07 02:17:20,876] {logging_mixin.py:109} INFO - [2022-06-07 02:17:20,876] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:17:20,877] {logging_mixin.py:109} INFO - [2022-06-07 02:17:20,876] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 803081

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:17:20,877] {logging_mixin.py:109} INFO - [2022-06-07 02:17:20,877] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:17:20,877] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:17:20,889] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:17:51,136] {processor.py:163} INFO - Started process (PID=804175) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:17:51,136] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:17:51,137] {logging_mixin.py:109} INFO - [2022-06-07 02:17:51,137] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:18:21,143] {logging_mixin.py:109} INFO - [2022-06-07 02:18:21,143] {timeout.py:36} ERROR - Process timed out, PID: 804175
[2022-06-07 02:18:21,144] {logging_mixin.py:109} INFO - [2022-06-07 02:18:21,143] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 804175
[2022-06-07 02:18:21,144] {logging_mixin.py:109} INFO - [2022-06-07 02:18:21,144] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:18:21,145] {logging_mixin.py:109} INFO - [2022-06-07 02:18:21,144] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 804175

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:18:21,145] {logging_mixin.py:109} INFO - [2022-06-07 02:18:21,145] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:18:21,145] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:18:21,157] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 02:18:51,623] {processor.py:163} INFO - Started process (PID=805269) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:18:51,624] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:18:51,624] {logging_mixin.py:109} INFO - [2022-06-07 02:18:51,624] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:19:21,626] {logging_mixin.py:109} INFO - [2022-06-07 02:19:21,626] {timeout.py:36} ERROR - Process timed out, PID: 805269
[2022-06-07 02:19:21,627] {logging_mixin.py:109} INFO - [2022-06-07 02:19:21,626] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 805269
[2022-06-07 02:19:21,627] {logging_mixin.py:109} INFO - [2022-06-07 02:19:21,627] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:19:21,627] {logging_mixin.py:109} INFO - [2022-06-07 02:19:21,627] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 805269

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:19:21,628] {logging_mixin.py:109} INFO - [2022-06-07 02:19:21,627] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:19:21,628] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:19:21,640] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:19:51,878] {processor.py:163} INFO - Started process (PID=806364) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:19:51,878] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:19:51,878] {logging_mixin.py:109} INFO - [2022-06-07 02:19:51,878] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:20:21,887] {logging_mixin.py:109} INFO - [2022-06-07 02:20:21,886] {timeout.py:36} ERROR - Process timed out, PID: 806364
[2022-06-07 02:20:21,887] {logging_mixin.py:109} INFO - [2022-06-07 02:20:21,887] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 806364
[2022-06-07 02:20:21,888] {logging_mixin.py:109} INFO - [2022-06-07 02:20:21,888] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:20:21,888] {logging_mixin.py:109} INFO - [2022-06-07 02:20:21,888] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 806364

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:20:21,888] {logging_mixin.py:109} INFO - [2022-06-07 02:20:21,888] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:20:21,889] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:20:21,901] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 02:20:52,462] {processor.py:163} INFO - Started process (PID=807457) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:20:52,463] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:20:52,463] {logging_mixin.py:109} INFO - [2022-06-07 02:20:52,463] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:21:22,479] {logging_mixin.py:109} INFO - [2022-06-07 02:21:22,479] {timeout.py:36} ERROR - Process timed out, PID: 807457
[2022-06-07 02:21:22,480] {logging_mixin.py:109} INFO - [2022-06-07 02:21:22,479] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 807457
[2022-06-07 02:21:22,480] {logging_mixin.py:109} INFO - [2022-06-07 02:21:22,480] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:21:22,481] {logging_mixin.py:109} INFO - [2022-06-07 02:21:22,480] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 807457

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:21:22,481] {logging_mixin.py:109} INFO - [2022-06-07 02:21:22,481] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:21:22,481] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:21:22,494] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.033 seconds
[2022-06-07 02:21:52,762] {processor.py:163} INFO - Started process (PID=808551) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:21:52,763] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:21:52,763] {logging_mixin.py:109} INFO - [2022-06-07 02:21:52,763] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:22:22,765] {logging_mixin.py:109} INFO - [2022-06-07 02:22:22,764] {timeout.py:36} ERROR - Process timed out, PID: 808551
[2022-06-07 02:22:22,765] {logging_mixin.py:109} INFO - [2022-06-07 02:22:22,765] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 808551
[2022-06-07 02:22:22,766] {logging_mixin.py:109} INFO - [2022-06-07 02:22:22,766] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:22:22,766] {logging_mixin.py:109} INFO - [2022-06-07 02:22:22,766] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 808551

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:22:22,766] {logging_mixin.py:109} INFO - [2022-06-07 02:22:22,766] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:22:22,767] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:22:22,778] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:22:52,969] {processor.py:163} INFO - Started process (PID=809645) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:22:52,969] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:22:52,970] {logging_mixin.py:109} INFO - [2022-06-07 02:22:52,970] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:23:22,971] {logging_mixin.py:109} INFO - [2022-06-07 02:23:22,970] {timeout.py:36} ERROR - Process timed out, PID: 809645
[2022-06-07 02:23:22,971] {logging_mixin.py:109} INFO - [2022-06-07 02:23:22,971] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 809645
[2022-06-07 02:23:22,971] {logging_mixin.py:109} INFO - [2022-06-07 02:23:22,971] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:23:22,972] {logging_mixin.py:109} INFO - [2022-06-07 02:23:22,972] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 809645

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:23:22,972] {logging_mixin.py:109} INFO - [2022-06-07 02:23:22,972] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:23:22,973] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:23:22,985] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:23:53,174] {processor.py:163} INFO - Started process (PID=810718) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:23:53,175] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:23:53,175] {logging_mixin.py:109} INFO - [2022-06-07 02:23:53,175] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:24:23,177] {logging_mixin.py:109} INFO - [2022-06-07 02:24:23,176] {timeout.py:36} ERROR - Process timed out, PID: 810718
[2022-06-07 02:24:23,177] {logging_mixin.py:109} INFO - [2022-06-07 02:24:23,177] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 810718
[2022-06-07 02:24:23,178] {logging_mixin.py:109} INFO - [2022-06-07 02:24:23,177] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:24:23,178] {logging_mixin.py:109} INFO - [2022-06-07 02:24:23,178] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 810718

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:24:23,178] {logging_mixin.py:109} INFO - [2022-06-07 02:24:23,178] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:24:23,179] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:24:23,191] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:24:53,391] {processor.py:163} INFO - Started process (PID=811789) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:24:53,391] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:24:53,392] {logging_mixin.py:109} INFO - [2022-06-07 02:24:53,392] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:25:23,393] {logging_mixin.py:109} INFO - [2022-06-07 02:25:23,393] {timeout.py:36} ERROR - Process timed out, PID: 811789
[2022-06-07 02:25:23,394] {logging_mixin.py:109} INFO - [2022-06-07 02:25:23,394] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 811789
[2022-06-07 02:25:23,394] {logging_mixin.py:109} INFO - [2022-06-07 02:25:23,394] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:25:23,395] {logging_mixin.py:109} INFO - [2022-06-07 02:25:23,394] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 811789

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:25:23,395] {logging_mixin.py:109} INFO - [2022-06-07 02:25:23,395] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:25:23,395] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:25:23,407] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:25:53,727] {processor.py:163} INFO - Started process (PID=812840) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:25:53,728] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:25:53,728] {logging_mixin.py:109} INFO - [2022-06-07 02:25:53,728] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:26:23,733] {logging_mixin.py:109} INFO - [2022-06-07 02:26:23,732] {timeout.py:36} ERROR - Process timed out, PID: 812840
[2022-06-07 02:26:23,734] {logging_mixin.py:109} INFO - [2022-06-07 02:26:23,733] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 812840
[2022-06-07 02:26:23,734] {logging_mixin.py:109} INFO - [2022-06-07 02:26:23,734] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:26:23,734] {logging_mixin.py:109} INFO - [2022-06-07 02:26:23,734] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 812840

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:26:23,735] {logging_mixin.py:109} INFO - [2022-06-07 02:26:23,734] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:26:23,735] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:26:23,748] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 02:26:53,945] {processor.py:163} INFO - Started process (PID=813932) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:26:53,945] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:26:53,946] {logging_mixin.py:109} INFO - [2022-06-07 02:26:53,946] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:27:23,947] {logging_mixin.py:109} INFO - [2022-06-07 02:27:23,947] {timeout.py:36} ERROR - Process timed out, PID: 813932
[2022-06-07 02:27:23,948] {logging_mixin.py:109} INFO - [2022-06-07 02:27:23,947] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 813932
[2022-06-07 02:27:23,948] {logging_mixin.py:109} INFO - [2022-06-07 02:27:23,948] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:27:23,948] {logging_mixin.py:109} INFO - [2022-06-07 02:27:23,948] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 813932

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:27:23,949] {logging_mixin.py:109} INFO - [2022-06-07 02:27:23,948] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:27:23,949] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:27:23,960] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:27:54,331] {processor.py:163} INFO - Started process (PID=815025) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:27:54,332] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:27:54,332] {logging_mixin.py:109} INFO - [2022-06-07 02:27:54,332] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:28:24,333] {logging_mixin.py:109} INFO - [2022-06-07 02:28:24,333] {timeout.py:36} ERROR - Process timed out, PID: 815025
[2022-06-07 02:28:24,334] {logging_mixin.py:109} INFO - [2022-06-07 02:28:24,333] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 815025
[2022-06-07 02:28:24,334] {logging_mixin.py:109} INFO - [2022-06-07 02:28:24,334] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:28:24,334] {logging_mixin.py:109} INFO - [2022-06-07 02:28:24,334] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 815025

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:28:24,335] {logging_mixin.py:109} INFO - [2022-06-07 02:28:24,334] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:28:24,335] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:28:24,347] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:28:54,711] {processor.py:163} INFO - Started process (PID=816119) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:28:54,712] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:28:54,712] {logging_mixin.py:109} INFO - [2022-06-07 02:28:54,712] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:29:24,715] {logging_mixin.py:109} INFO - [2022-06-07 02:29:24,714] {timeout.py:36} ERROR - Process timed out, PID: 816119
[2022-06-07 02:29:24,715] {logging_mixin.py:109} INFO - [2022-06-07 02:29:24,715] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 816119
[2022-06-07 02:29:24,715] {logging_mixin.py:109} INFO - [2022-06-07 02:29:24,715] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:29:24,716] {logging_mixin.py:109} INFO - [2022-06-07 02:29:24,715] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 816119

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:29:24,717] {logging_mixin.py:109} INFO - [2022-06-07 02:29:24,716] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:29:24,717] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:29:24,730] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 02:29:55,056] {processor.py:163} INFO - Started process (PID=817212) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:29:55,056] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:29:55,057] {logging_mixin.py:109} INFO - [2022-06-07 02:29:55,057] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:30:25,071] {logging_mixin.py:109} INFO - [2022-06-07 02:30:25,071] {timeout.py:36} ERROR - Process timed out, PID: 817212
[2022-06-07 02:30:25,072] {logging_mixin.py:109} INFO - [2022-06-07 02:30:25,072] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 817212
[2022-06-07 02:30:25,072] {logging_mixin.py:109} INFO - [2022-06-07 02:30:25,072] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:30:25,073] {logging_mixin.py:109} INFO - [2022-06-07 02:30:25,072] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 817212

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:30:25,073] {logging_mixin.py:109} INFO - [2022-06-07 02:30:25,073] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:30:25,073] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:30:25,086] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.031 seconds
[2022-06-07 02:30:55,351] {processor.py:163} INFO - Started process (PID=818306) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:30:55,352] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:30:55,352] {logging_mixin.py:109} INFO - [2022-06-07 02:30:55,352] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:31:25,366] {logging_mixin.py:109} INFO - [2022-06-07 02:31:25,365] {timeout.py:36} ERROR - Process timed out, PID: 818306
[2022-06-07 02:31:25,366] {logging_mixin.py:109} INFO - [2022-06-07 02:31:25,366] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 818306
[2022-06-07 02:31:25,367] {logging_mixin.py:109} INFO - [2022-06-07 02:31:25,367] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:31:25,367] {logging_mixin.py:109} INFO - [2022-06-07 02:31:25,367] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 818306

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:31:25,368] {logging_mixin.py:109} INFO - [2022-06-07 02:31:25,367] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:31:25,368] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:31:25,380] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.029 seconds
[2022-06-07 02:31:55,854] {processor.py:163} INFO - Started process (PID=819400) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:31:55,854] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:31:55,855] {logging_mixin.py:109} INFO - [2022-06-07 02:31:55,855] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:32:25,861] {logging_mixin.py:109} INFO - [2022-06-07 02:32:25,860] {timeout.py:36} ERROR - Process timed out, PID: 819400
[2022-06-07 02:32:25,861] {logging_mixin.py:109} INFO - [2022-06-07 02:32:25,861] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 819400
[2022-06-07 02:32:25,861] {logging_mixin.py:109} INFO - [2022-06-07 02:32:25,861] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:32:25,862] {logging_mixin.py:109} INFO - [2022-06-07 02:32:25,861] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 819400

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:32:25,862] {logging_mixin.py:109} INFO - [2022-06-07 02:32:25,862] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:32:25,862] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:32:25,874] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 02:32:56,178] {processor.py:163} INFO - Started process (PID=820493) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:32:56,178] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:32:56,179] {logging_mixin.py:109} INFO - [2022-06-07 02:32:56,179] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:33:26,180] {logging_mixin.py:109} INFO - [2022-06-07 02:33:26,180] {timeout.py:36} ERROR - Process timed out, PID: 820493
[2022-06-07 02:33:26,181] {logging_mixin.py:109} INFO - [2022-06-07 02:33:26,181] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 820493
[2022-06-07 02:33:26,181] {logging_mixin.py:109} INFO - [2022-06-07 02:33:26,181] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:33:26,182] {logging_mixin.py:109} INFO - [2022-06-07 02:33:26,181] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 820493

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:33:26,182] {logging_mixin.py:109} INFO - [2022-06-07 02:33:26,182] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:33:26,182] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:33:26,194] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:33:56,429] {processor.py:163} INFO - Started process (PID=821587) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:33:56,430] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:33:56,430] {logging_mixin.py:109} INFO - [2022-06-07 02:33:56,430] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:34:26,432] {logging_mixin.py:109} INFO - [2022-06-07 02:34:26,431] {timeout.py:36} ERROR - Process timed out, PID: 821587
[2022-06-07 02:34:26,432] {logging_mixin.py:109} INFO - [2022-06-07 02:34:26,432] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 821587
[2022-06-07 02:34:26,432] {logging_mixin.py:109} INFO - [2022-06-07 02:34:26,432] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:34:26,433] {logging_mixin.py:109} INFO - [2022-06-07 02:34:26,432] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 821587

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:34:26,433] {logging_mixin.py:109} INFO - [2022-06-07 02:34:26,433] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:34:26,433] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:34:26,445] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:34:56,805] {processor.py:163} INFO - Started process (PID=822681) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:34:56,806] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:34:56,806] {logging_mixin.py:109} INFO - [2022-06-07 02:34:56,806] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:35:26,807] {logging_mixin.py:109} INFO - [2022-06-07 02:35:26,807] {timeout.py:36} ERROR - Process timed out, PID: 822681
[2022-06-07 02:35:26,808] {logging_mixin.py:109} INFO - [2022-06-07 02:35:26,807] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 822681
[2022-06-07 02:35:26,808] {logging_mixin.py:109} INFO - [2022-06-07 02:35:26,808] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:35:26,808] {logging_mixin.py:109} INFO - [2022-06-07 02:35:26,808] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 822681

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:35:26,809] {logging_mixin.py:109} INFO - [2022-06-07 02:35:26,808] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:35:26,809] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:35:26,821] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:35:56,883] {processor.py:163} INFO - Started process (PID=823739) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:35:56,884] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:35:56,884] {logging_mixin.py:109} INFO - [2022-06-07 02:35:56,884] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:36:26,887] {logging_mixin.py:109} INFO - [2022-06-07 02:36:26,887] {timeout.py:36} ERROR - Process timed out, PID: 823739
[2022-06-07 02:36:26,888] {logging_mixin.py:109} INFO - [2022-06-07 02:36:26,888] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 823739
[2022-06-07 02:36:26,888] {logging_mixin.py:109} INFO - [2022-06-07 02:36:26,888] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:36:26,889] {logging_mixin.py:109} INFO - [2022-06-07 02:36:26,888] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 823739

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:36:26,889] {logging_mixin.py:109} INFO - [2022-06-07 02:36:26,889] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:36:26,889] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:36:26,900] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 02:36:57,276] {processor.py:163} INFO - Started process (PID=824834) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:36:57,276] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:36:57,276] {logging_mixin.py:109} INFO - [2022-06-07 02:36:57,276] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:37:27,281] {logging_mixin.py:109} INFO - [2022-06-07 02:37:27,281] {timeout.py:36} ERROR - Process timed out, PID: 824834
[2022-06-07 02:37:27,282] {logging_mixin.py:109} INFO - [2022-06-07 02:37:27,281] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 824834
[2022-06-07 02:37:27,282] {logging_mixin.py:109} INFO - [2022-06-07 02:37:27,282] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:37:27,282] {logging_mixin.py:109} INFO - [2022-06-07 02:37:27,282] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 824834

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:37:27,283] {logging_mixin.py:109} INFO - [2022-06-07 02:37:27,282] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:37:27,283] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:37:27,294] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 02:37:57,663] {processor.py:163} INFO - Started process (PID=825928) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:37:57,663] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:37:57,663] {logging_mixin.py:109} INFO - [2022-06-07 02:37:57,663] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:38:27,666] {logging_mixin.py:109} INFO - [2022-06-07 02:38:27,665] {timeout.py:36} ERROR - Process timed out, PID: 825928
[2022-06-07 02:38:27,666] {logging_mixin.py:109} INFO - [2022-06-07 02:38:27,666] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 825928
[2022-06-07 02:38:27,666] {logging_mixin.py:109} INFO - [2022-06-07 02:38:27,666] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:38:27,667] {logging_mixin.py:109} INFO - [2022-06-07 02:38:27,666] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 825928

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:38:27,667] {logging_mixin.py:109} INFO - [2022-06-07 02:38:27,667] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:38:27,667] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:38:27,680] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:38:57,824] {processor.py:163} INFO - Started process (PID=827021) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:38:57,825] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:38:57,825] {logging_mixin.py:109} INFO - [2022-06-07 02:38:57,825] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:39:27,826] {logging_mixin.py:109} INFO - [2022-06-07 02:39:27,826] {timeout.py:36} ERROR - Process timed out, PID: 827021
[2022-06-07 02:39:27,827] {logging_mixin.py:109} INFO - [2022-06-07 02:39:27,826] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 827021
[2022-06-07 02:39:27,827] {logging_mixin.py:109} INFO - [2022-06-07 02:39:27,827] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:39:27,827] {logging_mixin.py:109} INFO - [2022-06-07 02:39:27,827] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 827021

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:39:27,828] {logging_mixin.py:109} INFO - [2022-06-07 02:39:27,828] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:39:27,828] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:39:27,840] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:39:58,040] {processor.py:163} INFO - Started process (PID=828115) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:39:58,040] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:39:58,040] {logging_mixin.py:109} INFO - [2022-06-07 02:39:58,040] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:40:28,045] {logging_mixin.py:109} INFO - [2022-06-07 02:40:28,045] {timeout.py:36} ERROR - Process timed out, PID: 828115
[2022-06-07 02:40:28,046] {logging_mixin.py:109} INFO - [2022-06-07 02:40:28,045] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 828115
[2022-06-07 02:40:28,046] {logging_mixin.py:109} INFO - [2022-06-07 02:40:28,046] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:40:28,046] {logging_mixin.py:109} INFO - [2022-06-07 02:40:28,046] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 828115

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:40:28,047] {logging_mixin.py:109} INFO - [2022-06-07 02:40:28,047] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:40:28,047] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:40:28,060] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 02:40:58,245] {processor.py:163} INFO - Started process (PID=829211) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:40:58,246] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:40:58,246] {logging_mixin.py:109} INFO - [2022-06-07 02:40:58,246] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:41:28,248] {logging_mixin.py:109} INFO - [2022-06-07 02:41:28,248] {timeout.py:36} ERROR - Process timed out, PID: 829211
[2022-06-07 02:41:28,249] {logging_mixin.py:109} INFO - [2022-06-07 02:41:28,248] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 829211
[2022-06-07 02:41:28,249] {logging_mixin.py:109} INFO - [2022-06-07 02:41:28,249] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:41:28,249] {logging_mixin.py:109} INFO - [2022-06-07 02:41:28,249] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 829211

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:41:28,250] {logging_mixin.py:109} INFO - [2022-06-07 02:41:28,249] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:41:28,250] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:41:28,261] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:41:58,543] {processor.py:163} INFO - Started process (PID=830304) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:41:58,544] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:41:58,544] {logging_mixin.py:109} INFO - [2022-06-07 02:41:58,544] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:42:28,556] {logging_mixin.py:109} INFO - [2022-06-07 02:42:28,556] {timeout.py:36} ERROR - Process timed out, PID: 830304
[2022-06-07 02:42:28,557] {logging_mixin.py:109} INFO - [2022-06-07 02:42:28,557] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 830304
[2022-06-07 02:42:28,557] {logging_mixin.py:109} INFO - [2022-06-07 02:42:28,557] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:42:28,558] {logging_mixin.py:109} INFO - [2022-06-07 02:42:28,557] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 830304

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:42:28,558] {logging_mixin.py:109} INFO - [2022-06-07 02:42:28,558] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:42:28,558] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:42:28,569] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.027 seconds
[2022-06-07 02:42:58,914] {processor.py:163} INFO - Started process (PID=831398) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:42:58,914] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:42:58,915] {logging_mixin.py:109} INFO - [2022-06-07 02:42:58,915] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:43:28,929] {logging_mixin.py:109} INFO - [2022-06-07 02:43:28,929] {timeout.py:36} ERROR - Process timed out, PID: 831398
[2022-06-07 02:43:28,930] {logging_mixin.py:109} INFO - [2022-06-07 02:43:28,929] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 831398
[2022-06-07 02:43:28,930] {logging_mixin.py:109} INFO - [2022-06-07 02:43:28,930] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:43:28,930] {logging_mixin.py:109} INFO - [2022-06-07 02:43:28,930] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 831398

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:43:28,931] {logging_mixin.py:109} INFO - [2022-06-07 02:43:28,931] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:43:28,931] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:43:28,941] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.029 seconds
[2022-06-07 02:43:59,253] {processor.py:163} INFO - Started process (PID=832493) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:43:59,254] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:43:59,254] {logging_mixin.py:109} INFO - [2022-06-07 02:43:59,254] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:44:29,256] {logging_mixin.py:109} INFO - [2022-06-07 02:44:29,255] {timeout.py:36} ERROR - Process timed out, PID: 832493
[2022-06-07 02:44:29,256] {logging_mixin.py:109} INFO - [2022-06-07 02:44:29,256] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 832493
[2022-06-07 02:44:29,256] {logging_mixin.py:109} INFO - [2022-06-07 02:44:29,256] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:44:29,257] {logging_mixin.py:109} INFO - [2022-06-07 02:44:29,257] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 832493

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:44:29,257] {logging_mixin.py:109} INFO - [2022-06-07 02:44:29,257] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:44:29,258] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:44:29,270] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:44:59,515] {processor.py:163} INFO - Started process (PID=833587) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:44:59,516] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:44:59,516] {logging_mixin.py:109} INFO - [2022-06-07 02:44:59,516] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:45:29,517] {logging_mixin.py:109} INFO - [2022-06-07 02:45:29,517] {timeout.py:36} ERROR - Process timed out, PID: 833587
[2022-06-07 02:45:29,518] {logging_mixin.py:109} INFO - [2022-06-07 02:45:29,517] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 833587
[2022-06-07 02:45:29,518] {logging_mixin.py:109} INFO - [2022-06-07 02:45:29,518] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:45:29,518] {logging_mixin.py:109} INFO - [2022-06-07 02:45:29,518] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 833587

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:45:29,519] {logging_mixin.py:109} INFO - [2022-06-07 02:45:29,518] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:45:29,519] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:45:29,531] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:45:59,818] {processor.py:163} INFO - Started process (PID=834676) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:45:59,818] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:45:59,818] {logging_mixin.py:109} INFO - [2022-06-07 02:45:59,818] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:46:29,820] {logging_mixin.py:109} INFO - [2022-06-07 02:46:29,820] {timeout.py:36} ERROR - Process timed out, PID: 834676
[2022-06-07 02:46:29,821] {logging_mixin.py:109} INFO - [2022-06-07 02:46:29,821] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 834676
[2022-06-07 02:46:29,821] {logging_mixin.py:109} INFO - [2022-06-07 02:46:29,821] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:46:29,822] {logging_mixin.py:109} INFO - [2022-06-07 02:46:29,821] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 834676

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:46:29,822] {logging_mixin.py:109} INFO - [2022-06-07 02:46:29,822] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:46:29,822] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:46:29,833] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:47:00,252] {processor.py:163} INFO - Started process (PID=835729) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:47:00,252] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:47:00,252] {logging_mixin.py:109} INFO - [2022-06-07 02:47:00,252] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:47:30,259] {logging_mixin.py:109} INFO - [2022-06-07 02:47:30,258] {timeout.py:36} ERROR - Process timed out, PID: 835729
[2022-06-07 02:47:30,259] {logging_mixin.py:109} INFO - [2022-06-07 02:47:30,259] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 835729
[2022-06-07 02:47:30,259] {logging_mixin.py:109} INFO - [2022-06-07 02:47:30,259] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:47:30,260] {logging_mixin.py:109} INFO - [2022-06-07 02:47:30,260] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 835729

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:47:30,260] {logging_mixin.py:109} INFO - [2022-06-07 02:47:30,260] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:47:30,261] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:47:30,272] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 02:48:00,472] {processor.py:163} INFO - Started process (PID=836824) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:48:00,472] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:48:00,472] {logging_mixin.py:109} INFO - [2022-06-07 02:48:00,472] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:48:30,475] {logging_mixin.py:109} INFO - [2022-06-07 02:48:30,475] {timeout.py:36} ERROR - Process timed out, PID: 836824
[2022-06-07 02:48:30,476] {logging_mixin.py:109} INFO - [2022-06-07 02:48:30,475] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 836824
[2022-06-07 02:48:30,476] {logging_mixin.py:109} INFO - [2022-06-07 02:48:30,476] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:48:30,477] {logging_mixin.py:109} INFO - [2022-06-07 02:48:30,476] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 836824

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:48:30,477] {logging_mixin.py:109} INFO - [2022-06-07 02:48:30,477] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:48:30,477] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:48:30,489] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 02:49:00,830] {processor.py:163} INFO - Started process (PID=837917) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:49:00,830] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:49:00,830] {logging_mixin.py:109} INFO - [2022-06-07 02:49:00,830] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:49:30,838] {logging_mixin.py:109} INFO - [2022-06-07 02:49:30,837] {timeout.py:36} ERROR - Process timed out, PID: 837917
[2022-06-07 02:49:30,838] {logging_mixin.py:109} INFO - [2022-06-07 02:49:30,838] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 837917
[2022-06-07 02:49:30,838] {logging_mixin.py:109} INFO - [2022-06-07 02:49:30,838] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:49:30,839] {logging_mixin.py:109} INFO - [2022-06-07 02:49:30,838] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 837917

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:49:30,839] {logging_mixin.py:109} INFO - [2022-06-07 02:49:30,839] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:49:30,839] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:49:30,851] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 02:50:01,267] {processor.py:163} INFO - Started process (PID=839011) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:50:01,267] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:50:01,267] {logging_mixin.py:109} INFO - [2022-06-07 02:50:01,267] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:50:31,279] {logging_mixin.py:109} INFO - [2022-06-07 02:50:31,279] {timeout.py:36} ERROR - Process timed out, PID: 839011
[2022-06-07 02:50:31,280] {logging_mixin.py:109} INFO - [2022-06-07 02:50:31,280] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 839011
[2022-06-07 02:50:31,280] {logging_mixin.py:109} INFO - [2022-06-07 02:50:31,280] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:50:31,281] {logging_mixin.py:109} INFO - [2022-06-07 02:50:31,280] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 839011

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:50:31,281] {logging_mixin.py:109} INFO - [2022-06-07 02:50:31,281] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:50:31,281] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:50:31,294] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.029 seconds
[2022-06-07 02:51:01,664] {processor.py:163} INFO - Started process (PID=840106) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:51:01,665] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:51:01,665] {logging_mixin.py:109} INFO - [2022-06-07 02:51:01,665] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:51:31,670] {logging_mixin.py:109} INFO - [2022-06-07 02:51:31,670] {timeout.py:36} ERROR - Process timed out, PID: 840106
[2022-06-07 02:51:31,671] {logging_mixin.py:109} INFO - [2022-06-07 02:51:31,670] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 840106
[2022-06-07 02:51:31,671] {logging_mixin.py:109} INFO - [2022-06-07 02:51:31,671] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:51:31,671] {logging_mixin.py:109} INFO - [2022-06-07 02:51:31,671] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 840106

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:51:31,672] {logging_mixin.py:109} INFO - [2022-06-07 02:51:31,671] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:51:31,672] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:51:31,683] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 02:52:01,894] {processor.py:163} INFO - Started process (PID=841200) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:52:01,894] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:52:01,895] {logging_mixin.py:109} INFO - [2022-06-07 02:52:01,895] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:52:31,898] {logging_mixin.py:109} INFO - [2022-06-07 02:52:31,898] {timeout.py:36} ERROR - Process timed out, PID: 841200
[2022-06-07 02:52:31,898] {logging_mixin.py:109} INFO - [2022-06-07 02:52:31,898] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 841200
[2022-06-07 02:52:31,899] {logging_mixin.py:109} INFO - [2022-06-07 02:52:31,898] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:52:31,899] {logging_mixin.py:109} INFO - [2022-06-07 02:52:31,899] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 841200

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:52:31,899] {logging_mixin.py:109} INFO - [2022-06-07 02:52:31,899] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:52:31,900] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:52:31,911] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:53:02,190] {processor.py:163} INFO - Started process (PID=842294) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:53:02,190] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:53:02,191] {logging_mixin.py:109} INFO - [2022-06-07 02:53:02,191] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:53:32,193] {logging_mixin.py:109} INFO - [2022-06-07 02:53:32,193] {timeout.py:36} ERROR - Process timed out, PID: 842294
[2022-06-07 02:53:32,194] {logging_mixin.py:109} INFO - [2022-06-07 02:53:32,193] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 842294
[2022-06-07 02:53:32,194] {logging_mixin.py:109} INFO - [2022-06-07 02:53:32,194] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:53:32,194] {logging_mixin.py:109} INFO - [2022-06-07 02:53:32,194] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 842294

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:53:32,195] {logging_mixin.py:109} INFO - [2022-06-07 02:53:32,194] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:53:32,195] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:53:32,206] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:54:02,336] {processor.py:163} INFO - Started process (PID=843369) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:54:02,336] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:54:02,337] {logging_mixin.py:109} INFO - [2022-06-07 02:54:02,337] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:54:32,349] {logging_mixin.py:109} INFO - [2022-06-07 02:54:32,349] {timeout.py:36} ERROR - Process timed out, PID: 843369
[2022-06-07 02:54:32,350] {logging_mixin.py:109} INFO - [2022-06-07 02:54:32,349] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 843369
[2022-06-07 02:54:32,350] {logging_mixin.py:109} INFO - [2022-06-07 02:54:32,350] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:54:32,350] {logging_mixin.py:109} INFO - [2022-06-07 02:54:32,350] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 843369

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:54:32,351] {logging_mixin.py:109} INFO - [2022-06-07 02:54:32,350] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:54:32,351] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:54:32,363] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 02:55:02,639] {processor.py:163} INFO - Started process (PID=844459) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:55:02,639] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:55:02,640] {logging_mixin.py:109} INFO - [2022-06-07 02:55:02,640] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:55:32,642] {logging_mixin.py:109} INFO - [2022-06-07 02:55:32,641] {timeout.py:36} ERROR - Process timed out, PID: 844459
[2022-06-07 02:55:32,642] {logging_mixin.py:109} INFO - [2022-06-07 02:55:32,642] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 844459
[2022-06-07 02:55:32,642] {logging_mixin.py:109} INFO - [2022-06-07 02:55:32,642] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:55:32,643] {logging_mixin.py:109} INFO - [2022-06-07 02:55:32,642] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 844459

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:55:32,643] {logging_mixin.py:109} INFO - [2022-06-07 02:55:32,643] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:55:32,643] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:55:32,655] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:56:02,894] {processor.py:163} INFO - Started process (PID=845542) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:56:02,894] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:56:02,895] {logging_mixin.py:109} INFO - [2022-06-07 02:56:02,894] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:56:32,899] {logging_mixin.py:109} INFO - [2022-06-07 02:56:32,899] {timeout.py:36} ERROR - Process timed out, PID: 845542
[2022-06-07 02:56:32,900] {logging_mixin.py:109} INFO - [2022-06-07 02:56:32,899] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 845542
[2022-06-07 02:56:32,900] {logging_mixin.py:109} INFO - [2022-06-07 02:56:32,900] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:56:32,900] {logging_mixin.py:109} INFO - [2022-06-07 02:56:32,900] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 845542

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:56:32,901] {logging_mixin.py:109} INFO - [2022-06-07 02:56:32,900] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:56:32,901] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:56:32,914] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 02:57:03,302] {processor.py:163} INFO - Started process (PID=846590) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:57:03,302] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:57:03,303] {logging_mixin.py:109} INFO - [2022-06-07 02:57:03,303] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:57:33,304] {logging_mixin.py:109} INFO - [2022-06-07 02:57:33,303] {timeout.py:36} ERROR - Process timed out, PID: 846590
[2022-06-07 02:57:33,304] {logging_mixin.py:109} INFO - [2022-06-07 02:57:33,304] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 846590
[2022-06-07 02:57:33,305] {logging_mixin.py:109} INFO - [2022-06-07 02:57:33,305] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:57:33,305] {logging_mixin.py:109} INFO - [2022-06-07 02:57:33,305] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 846590

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:57:33,306] {logging_mixin.py:109} INFO - [2022-06-07 02:57:33,305] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:57:33,306] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:57:33,318] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 02:58:03,712] {processor.py:163} INFO - Started process (PID=847684) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:58:03,713] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:58:03,713] {logging_mixin.py:109} INFO - [2022-06-07 02:58:03,713] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:58:33,714] {logging_mixin.py:109} INFO - [2022-06-07 02:58:33,714] {timeout.py:36} ERROR - Process timed out, PID: 847684
[2022-06-07 02:58:33,715] {logging_mixin.py:109} INFO - [2022-06-07 02:58:33,714] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 847684
[2022-06-07 02:58:33,715] {logging_mixin.py:109} INFO - [2022-06-07 02:58:33,715] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:58:33,715] {logging_mixin.py:109} INFO - [2022-06-07 02:58:33,715] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 847684

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:58:33,716] {logging_mixin.py:109} INFO - [2022-06-07 02:58:33,716] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:58:33,716] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:58:33,728] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 02:59:04,016] {processor.py:163} INFO - Started process (PID=848777) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 02:59:04,017] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 02:59:04,017] {logging_mixin.py:109} INFO - [2022-06-07 02:59:04,017] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:59:34,018] {logging_mixin.py:109} INFO - [2022-06-07 02:59:34,018] {timeout.py:36} ERROR - Process timed out, PID: 848777
[2022-06-07 02:59:34,019] {logging_mixin.py:109} INFO - [2022-06-07 02:59:34,018] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 848777
[2022-06-07 02:59:34,019] {logging_mixin.py:109} INFO - [2022-06-07 02:59:34,019] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 02:59:34,020] {logging_mixin.py:109} INFO - [2022-06-07 02:59:34,019] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 848777

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 02:59:34,020] {logging_mixin.py:109} INFO - [2022-06-07 02:59:34,020] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 02:59:34,020] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 02:59:34,031] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 03:00:04,173] {processor.py:163} INFO - Started process (PID=849871) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:00:04,174] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:00:04,174] {logging_mixin.py:109} INFO - [2022-06-07 03:00:04,174] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:00:34,184] {logging_mixin.py:109} INFO - [2022-06-07 03:00:34,183] {timeout.py:36} ERROR - Process timed out, PID: 849871
[2022-06-07 03:00:34,184] {logging_mixin.py:109} INFO - [2022-06-07 03:00:34,184] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 849871
[2022-06-07 03:00:34,184] {logging_mixin.py:109} INFO - [2022-06-07 03:00:34,184] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:00:34,185] {logging_mixin.py:109} INFO - [2022-06-07 03:00:34,185] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 849871

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:00:34,185] {logging_mixin.py:109} INFO - [2022-06-07 03:00:34,185] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:00:34,186] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:00:34,197] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 03:01:04,546] {processor.py:163} INFO - Started process (PID=850965) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:01:04,546] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:01:04,546] {logging_mixin.py:109} INFO - [2022-06-07 03:01:04,546] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:01:34,550] {logging_mixin.py:109} INFO - [2022-06-07 03:01:34,550] {timeout.py:36} ERROR - Process timed out, PID: 850965
[2022-06-07 03:01:34,551] {logging_mixin.py:109} INFO - [2022-06-07 03:01:34,550] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 850965
[2022-06-07 03:01:34,551] {logging_mixin.py:109} INFO - [2022-06-07 03:01:34,551] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:01:34,551] {logging_mixin.py:109} INFO - [2022-06-07 03:01:34,551] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 850965

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:01:34,552] {logging_mixin.py:109} INFO - [2022-06-07 03:01:34,551] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:01:34,552] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:01:34,565] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 03:02:04,744] {processor.py:163} INFO - Started process (PID=852059) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:02:04,744] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:02:04,744] {logging_mixin.py:109} INFO - [2022-06-07 03:02:04,744] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:02:34,746] {logging_mixin.py:109} INFO - [2022-06-07 03:02:34,746] {timeout.py:36} ERROR - Process timed out, PID: 852059
[2022-06-07 03:02:34,747] {logging_mixin.py:109} INFO - [2022-06-07 03:02:34,746] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 852059
[2022-06-07 03:02:34,747] {logging_mixin.py:109} INFO - [2022-06-07 03:02:34,747] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:02:34,747] {logging_mixin.py:109} INFO - [2022-06-07 03:02:34,747] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 852059

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:02:34,748] {logging_mixin.py:109} INFO - [2022-06-07 03:02:34,748] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:02:34,748] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:02:34,762] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 03:03:04,977] {processor.py:163} INFO - Started process (PID=853154) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:03:04,978] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:03:04,978] {logging_mixin.py:109} INFO - [2022-06-07 03:03:04,978] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:03:34,979] {logging_mixin.py:109} INFO - [2022-06-07 03:03:34,979] {timeout.py:36} ERROR - Process timed out, PID: 853154
[2022-06-07 03:03:34,980] {logging_mixin.py:109} INFO - [2022-06-07 03:03:34,979] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 853154
[2022-06-07 03:03:34,980] {logging_mixin.py:109} INFO - [2022-06-07 03:03:34,980] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:03:34,980] {logging_mixin.py:109} INFO - [2022-06-07 03:03:34,980] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 853154

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:03:34,981] {logging_mixin.py:109} INFO - [2022-06-07 03:03:34,980] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:03:34,981] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:03:34,992] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:04:05,383] {processor.py:163} INFO - Started process (PID=854241) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:04:05,383] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:04:05,384] {logging_mixin.py:109} INFO - [2022-06-07 03:04:05,384] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:04:35,385] {logging_mixin.py:109} INFO - [2022-06-07 03:04:35,385] {timeout.py:36} ERROR - Process timed out, PID: 854241
[2022-06-07 03:04:35,386] {logging_mixin.py:109} INFO - [2022-06-07 03:04:35,385] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 854241
[2022-06-07 03:04:35,386] {logging_mixin.py:109} INFO - [2022-06-07 03:04:35,386] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:04:35,386] {logging_mixin.py:109} INFO - [2022-06-07 03:04:35,386] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 854241

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:04:35,387] {logging_mixin.py:109} INFO - [2022-06-07 03:04:35,386] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:04:35,387] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:04:35,399] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:05:05,860] {processor.py:163} INFO - Started process (PID=855334) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:05:05,861] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:05:05,861] {logging_mixin.py:109} INFO - [2022-06-07 03:05:05,861] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:05:35,862] {logging_mixin.py:109} INFO - [2022-06-07 03:05:35,862] {timeout.py:36} ERROR - Process timed out, PID: 855334
[2022-06-07 03:05:35,863] {logging_mixin.py:109} INFO - [2022-06-07 03:05:35,862] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 855334
[2022-06-07 03:05:35,863] {logging_mixin.py:109} INFO - [2022-06-07 03:05:35,863] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:05:35,863] {logging_mixin.py:109} INFO - [2022-06-07 03:05:35,863] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 855334

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:05:35,864] {logging_mixin.py:109} INFO - [2022-06-07 03:05:35,863] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:05:35,864] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:05:35,875] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 03:06:05,992] {processor.py:163} INFO - Started process (PID=856396) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:06:05,993] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:06:05,993] {logging_mixin.py:109} INFO - [2022-06-07 03:06:05,993] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:06:35,996] {logging_mixin.py:109} INFO - [2022-06-07 03:06:35,995] {timeout.py:36} ERROR - Process timed out, PID: 856396
[2022-06-07 03:06:35,996] {logging_mixin.py:109} INFO - [2022-06-07 03:06:35,996] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 856396
[2022-06-07 03:06:35,996] {logging_mixin.py:109} INFO - [2022-06-07 03:06:35,996] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:06:35,997] {logging_mixin.py:109} INFO - [2022-06-07 03:06:35,996] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 856396

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:06:35,997] {logging_mixin.py:109} INFO - [2022-06-07 03:06:35,997] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:06:35,997] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:06:36,008] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:07:06,895] {processor.py:163} INFO - Started process (PID=857491) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:07:06,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:07:06,896] {logging_mixin.py:109} INFO - [2022-06-07 03:07:06,896] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:07:36,898] {logging_mixin.py:109} INFO - [2022-06-07 03:07:36,898] {timeout.py:36} ERROR - Process timed out, PID: 857491
[2022-06-07 03:07:36,899] {logging_mixin.py:109} INFO - [2022-06-07 03:07:36,898] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 857491
[2022-06-07 03:07:36,899] {logging_mixin.py:109} INFO - [2022-06-07 03:07:36,899] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:07:36,899] {logging_mixin.py:109} INFO - [2022-06-07 03:07:36,899] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 857491

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:07:36,900] {logging_mixin.py:109} INFO - [2022-06-07 03:07:36,899] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:07:36,900] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:07:36,912] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:08:07,351] {processor.py:163} INFO - Started process (PID=858585) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:08:07,352] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:08:07,352] {logging_mixin.py:109} INFO - [2022-06-07 03:08:07,352] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:08:37,353] {logging_mixin.py:109} INFO - [2022-06-07 03:08:37,352] {timeout.py:36} ERROR - Process timed out, PID: 858585
[2022-06-07 03:08:37,353] {logging_mixin.py:109} INFO - [2022-06-07 03:08:37,353] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 858585
[2022-06-07 03:08:37,354] {logging_mixin.py:109} INFO - [2022-06-07 03:08:37,354] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:08:37,354] {logging_mixin.py:109} INFO - [2022-06-07 03:08:37,354] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 858585

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:08:37,354] {logging_mixin.py:109} INFO - [2022-06-07 03:08:37,354] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:08:37,355] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:08:37,366] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 03:09:07,631] {processor.py:163} INFO - Started process (PID=859674) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:09:07,631] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:09:07,632] {logging_mixin.py:109} INFO - [2022-06-07 03:09:07,632] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:09:37,635] {logging_mixin.py:109} INFO - [2022-06-07 03:09:37,635] {timeout.py:36} ERROR - Process timed out, PID: 859674
[2022-06-07 03:09:37,636] {logging_mixin.py:109} INFO - [2022-06-07 03:09:37,635] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 859674
[2022-06-07 03:09:37,636] {logging_mixin.py:109} INFO - [2022-06-07 03:09:37,636] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:09:37,636] {logging_mixin.py:109} INFO - [2022-06-07 03:09:37,636] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 859674

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:09:37,637] {logging_mixin.py:109} INFO - [2022-06-07 03:09:37,636] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:09:37,637] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:09:37,649] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 03:10:07,774] {processor.py:163} INFO - Started process (PID=860766) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:10:07,774] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:10:07,775] {logging_mixin.py:109} INFO - [2022-06-07 03:10:07,775] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:10:37,784] {logging_mixin.py:109} INFO - [2022-06-07 03:10:37,783] {timeout.py:36} ERROR - Process timed out, PID: 860766
[2022-06-07 03:10:37,784] {logging_mixin.py:109} INFO - [2022-06-07 03:10:37,784] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 860766
[2022-06-07 03:10:37,785] {logging_mixin.py:109} INFO - [2022-06-07 03:10:37,784] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:10:37,785] {logging_mixin.py:109} INFO - [2022-06-07 03:10:37,785] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 860766

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:10:37,785] {logging_mixin.py:109} INFO - [2022-06-07 03:10:37,785] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:10:37,786] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:10:37,797] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 03:11:08,007] {processor.py:163} INFO - Started process (PID=861862) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:11:08,008] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:11:08,008] {logging_mixin.py:109} INFO - [2022-06-07 03:11:08,008] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:11:38,014] {logging_mixin.py:109} INFO - [2022-06-07 03:11:38,013] {timeout.py:36} ERROR - Process timed out, PID: 861862
[2022-06-07 03:11:38,014] {logging_mixin.py:109} INFO - [2022-06-07 03:11:38,014] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 861862
[2022-06-07 03:11:38,014] {logging_mixin.py:109} INFO - [2022-06-07 03:11:38,014] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:11:38,015] {logging_mixin.py:109} INFO - [2022-06-07 03:11:38,014] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 861862

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:11:38,015] {logging_mixin.py:109} INFO - [2022-06-07 03:11:38,015] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:11:38,015] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:11:38,027] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 03:12:08,203] {processor.py:163} INFO - Started process (PID=862955) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:12:08,204] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:12:08,204] {logging_mixin.py:109} INFO - [2022-06-07 03:12:08,204] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:12:38,206] {logging_mixin.py:109} INFO - [2022-06-07 03:12:38,205] {timeout.py:36} ERROR - Process timed out, PID: 862955
[2022-06-07 03:12:38,206] {logging_mixin.py:109} INFO - [2022-06-07 03:12:38,206] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 862955
[2022-06-07 03:12:38,206] {logging_mixin.py:109} INFO - [2022-06-07 03:12:38,206] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:12:38,207] {logging_mixin.py:109} INFO - [2022-06-07 03:12:38,207] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 862955

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:12:38,207] {logging_mixin.py:109} INFO - [2022-06-07 03:12:38,207] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:12:38,207] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:12:38,219] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:13:08,474] {processor.py:163} INFO - Started process (PID=864050) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:13:08,474] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:13:08,474] {logging_mixin.py:109} INFO - [2022-06-07 03:13:08,474] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:13:38,490] {logging_mixin.py:109} INFO - [2022-06-07 03:13:38,490] {timeout.py:36} ERROR - Process timed out, PID: 864050
[2022-06-07 03:13:38,491] {logging_mixin.py:109} INFO - [2022-06-07 03:13:38,491] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 864050
[2022-06-07 03:13:38,491] {logging_mixin.py:109} INFO - [2022-06-07 03:13:38,491] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:13:38,492] {logging_mixin.py:109} INFO - [2022-06-07 03:13:38,491] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 864050

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:13:38,492] {logging_mixin.py:109} INFO - [2022-06-07 03:13:38,492] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:13:38,492] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:13:38,505] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.033 seconds
[2022-06-07 03:14:08,789] {processor.py:163} INFO - Started process (PID=865144) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:14:08,789] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:14:08,790] {logging_mixin.py:109} INFO - [2022-06-07 03:14:08,790] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:14:38,791] {logging_mixin.py:109} INFO - [2022-06-07 03:14:38,790] {timeout.py:36} ERROR - Process timed out, PID: 865144
[2022-06-07 03:14:38,791] {logging_mixin.py:109} INFO - [2022-06-07 03:14:38,791] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 865144
[2022-06-07 03:14:38,791] {logging_mixin.py:109} INFO - [2022-06-07 03:14:38,791] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:14:38,792] {logging_mixin.py:109} INFO - [2022-06-07 03:14:38,792] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 865144

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:14:38,792] {logging_mixin.py:109} INFO - [2022-06-07 03:14:38,792] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:14:38,793] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:14:38,804] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:15:09,044] {processor.py:163} INFO - Started process (PID=866240) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:15:09,044] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:15:09,045] {logging_mixin.py:109} INFO - [2022-06-07 03:15:09,045] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:15:39,055] {logging_mixin.py:109} INFO - [2022-06-07 03:15:39,055] {timeout.py:36} ERROR - Process timed out, PID: 866240
[2022-06-07 03:15:39,056] {logging_mixin.py:109} INFO - [2022-06-07 03:15:39,055] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 866240
[2022-06-07 03:15:39,056] {logging_mixin.py:109} INFO - [2022-06-07 03:15:39,056] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:15:39,057] {logging_mixin.py:109} INFO - [2022-06-07 03:15:39,056] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 866240

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:15:39,057] {logging_mixin.py:109} INFO - [2022-06-07 03:15:39,057] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:15:39,058] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:15:39,071] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.029 seconds
[2022-06-07 03:16:09,388] {processor.py:163} INFO - Started process (PID=867335) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:16:09,388] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:16:09,388] {logging_mixin.py:109} INFO - [2022-06-07 03:16:09,388] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:16:39,395] {logging_mixin.py:109} INFO - [2022-06-07 03:16:39,395] {timeout.py:36} ERROR - Process timed out, PID: 867335
[2022-06-07 03:16:39,395] {logging_mixin.py:109} INFO - [2022-06-07 03:16:39,395] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 867335
[2022-06-07 03:16:39,396] {logging_mixin.py:109} INFO - [2022-06-07 03:16:39,395] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:16:39,396] {logging_mixin.py:109} INFO - [2022-06-07 03:16:39,396] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 867335

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:16:39,396] {logging_mixin.py:109} INFO - [2022-06-07 03:16:39,396] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:16:39,397] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:16:39,408] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 03:17:09,543] {processor.py:163} INFO - Started process (PID=868422) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:17:09,543] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:17:09,544] {logging_mixin.py:109} INFO - [2022-06-07 03:17:09,544] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:17:39,545] {logging_mixin.py:109} INFO - [2022-06-07 03:17:39,544] {timeout.py:36} ERROR - Process timed out, PID: 868422
[2022-06-07 03:17:39,545] {logging_mixin.py:109} INFO - [2022-06-07 03:17:39,545] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 868422
[2022-06-07 03:17:39,545] {logging_mixin.py:109} INFO - [2022-06-07 03:17:39,545] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:17:39,546] {logging_mixin.py:109} INFO - [2022-06-07 03:17:39,545] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 868422

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:17:39,546] {logging_mixin.py:109} INFO - [2022-06-07 03:17:39,546] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:17:39,546] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:17:39,557] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 03:18:09,692] {processor.py:163} INFO - Started process (PID=869476) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:18:09,693] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:18:09,693] {logging_mixin.py:109} INFO - [2022-06-07 03:18:09,693] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:18:39,694] {logging_mixin.py:109} INFO - [2022-06-07 03:18:39,693] {timeout.py:36} ERROR - Process timed out, PID: 869476
[2022-06-07 03:18:39,694] {logging_mixin.py:109} INFO - [2022-06-07 03:18:39,694] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 869476
[2022-06-07 03:18:39,694] {logging_mixin.py:109} INFO - [2022-06-07 03:18:39,694] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:18:39,695] {logging_mixin.py:109} INFO - [2022-06-07 03:18:39,695] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 869476

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:18:39,695] {logging_mixin.py:109} INFO - [2022-06-07 03:18:39,695] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:18:39,696] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:18:39,707] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 03:19:09,912] {processor.py:163} INFO - Started process (PID=870569) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:19:09,913] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:19:09,913] {logging_mixin.py:109} INFO - [2022-06-07 03:19:09,913] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:19:39,924] {logging_mixin.py:109} INFO - [2022-06-07 03:19:39,923] {timeout.py:36} ERROR - Process timed out, PID: 870569
[2022-06-07 03:19:39,924] {logging_mixin.py:109} INFO - [2022-06-07 03:19:39,924] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 870569
[2022-06-07 03:19:39,924] {logging_mixin.py:109} INFO - [2022-06-07 03:19:39,924] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:19:39,925] {logging_mixin.py:109} INFO - [2022-06-07 03:19:39,925] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 870569

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:19:39,925] {logging_mixin.py:109} INFO - [2022-06-07 03:19:39,925] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:19:39,925] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:19:39,937] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 03:20:10,464] {processor.py:163} INFO - Started process (PID=871665) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:20:10,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:20:10,465] {logging_mixin.py:109} INFO - [2022-06-07 03:20:10,465] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:20:40,466] {logging_mixin.py:109} INFO - [2022-06-07 03:20:40,466] {timeout.py:36} ERROR - Process timed out, PID: 871665
[2022-06-07 03:20:40,466] {logging_mixin.py:109} INFO - [2022-06-07 03:20:40,466] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 871665
[2022-06-07 03:20:40,467] {logging_mixin.py:109} INFO - [2022-06-07 03:20:40,467] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:20:40,467] {logging_mixin.py:109} INFO - [2022-06-07 03:20:40,467] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 871665

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:20:40,468] {logging_mixin.py:109} INFO - [2022-06-07 03:20:40,467] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:20:40,468] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:20:40,479] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:21:10,990] {processor.py:163} INFO - Started process (PID=872758) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:21:10,991] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:21:10,991] {logging_mixin.py:109} INFO - [2022-06-07 03:21:10,991] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:21:40,993] {logging_mixin.py:109} INFO - [2022-06-07 03:21:40,993] {timeout.py:36} ERROR - Process timed out, PID: 872758
[2022-06-07 03:21:40,994] {logging_mixin.py:109} INFO - [2022-06-07 03:21:40,993] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 872758
[2022-06-07 03:21:40,994] {logging_mixin.py:109} INFO - [2022-06-07 03:21:40,994] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:21:40,994] {logging_mixin.py:109} INFO - [2022-06-07 03:21:40,994] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 872758

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:21:40,995] {logging_mixin.py:109} INFO - [2022-06-07 03:21:40,994] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:21:40,995] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:21:41,007] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 03:22:11,432] {processor.py:163} INFO - Started process (PID=873853) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:22:11,432] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:22:11,432] {logging_mixin.py:109} INFO - [2022-06-07 03:22:11,432] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:22:41,434] {logging_mixin.py:109} INFO - [2022-06-07 03:22:41,434] {timeout.py:36} ERROR - Process timed out, PID: 873853
[2022-06-07 03:22:41,435] {logging_mixin.py:109} INFO - [2022-06-07 03:22:41,434] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 873853
[2022-06-07 03:22:41,435] {logging_mixin.py:109} INFO - [2022-06-07 03:22:41,435] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:22:41,436] {logging_mixin.py:109} INFO - [2022-06-07 03:22:41,435] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 873853

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:22:41,436] {logging_mixin.py:109} INFO - [2022-06-07 03:22:41,436] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:22:41,436] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:22:41,448] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:23:11,927] {processor.py:163} INFO - Started process (PID=874946) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:23:11,928] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:23:11,928] {logging_mixin.py:109} INFO - [2022-06-07 03:23:11,928] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:23:41,929] {logging_mixin.py:109} INFO - [2022-06-07 03:23:41,928] {timeout.py:36} ERROR - Process timed out, PID: 874946
[2022-06-07 03:23:41,929] {logging_mixin.py:109} INFO - [2022-06-07 03:23:41,929] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 874946
[2022-06-07 03:23:41,929] {logging_mixin.py:109} INFO - [2022-06-07 03:23:41,929] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:23:41,930] {logging_mixin.py:109} INFO - [2022-06-07 03:23:41,930] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 874946

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:23:41,930] {logging_mixin.py:109} INFO - [2022-06-07 03:23:41,930] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:23:41,931] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:23:41,942] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 03:24:12,495] {processor.py:163} INFO - Started process (PID=875985) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:24:12,496] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:24:12,496] {logging_mixin.py:109} INFO - [2022-06-07 03:24:12,496] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:24:42,498] {logging_mixin.py:109} INFO - [2022-06-07 03:24:42,497] {timeout.py:36} ERROR - Process timed out, PID: 875985
[2022-06-07 03:24:42,498] {logging_mixin.py:109} INFO - [2022-06-07 03:24:42,498] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 875985
[2022-06-07 03:24:42,498] {logging_mixin.py:109} INFO - [2022-06-07 03:24:42,498] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:24:42,499] {logging_mixin.py:109} INFO - [2022-06-07 03:24:42,498] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 875985

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:24:42,499] {logging_mixin.py:109} INFO - [2022-06-07 03:24:42,499] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:24:42,500] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:24:42,511] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:25:13,036] {processor.py:163} INFO - Started process (PID=877079) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:25:13,036] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:25:13,036] {logging_mixin.py:109} INFO - [2022-06-07 03:25:13,036] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:25:43,044] {logging_mixin.py:109} INFO - [2022-06-07 03:25:43,044] {timeout.py:36} ERROR - Process timed out, PID: 877079
[2022-06-07 03:25:43,045] {logging_mixin.py:109} INFO - [2022-06-07 03:25:43,044] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 877079
[2022-06-07 03:25:43,045] {logging_mixin.py:109} INFO - [2022-06-07 03:25:43,045] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:25:43,046] {logging_mixin.py:109} INFO - [2022-06-07 03:25:43,045] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 877079

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:25:43,046] {logging_mixin.py:109} INFO - [2022-06-07 03:25:43,046] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:25:43,046] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:25:43,058] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 03:26:13,374] {processor.py:163} INFO - Started process (PID=878173) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:26:13,374] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:26:13,375] {logging_mixin.py:109} INFO - [2022-06-07 03:26:13,375] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:26:43,379] {logging_mixin.py:109} INFO - [2022-06-07 03:26:43,379] {timeout.py:36} ERROR - Process timed out, PID: 878173
[2022-06-07 03:26:43,380] {logging_mixin.py:109} INFO - [2022-06-07 03:26:43,379] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 878173
[2022-06-07 03:26:43,380] {logging_mixin.py:109} INFO - [2022-06-07 03:26:43,380] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:26:43,380] {logging_mixin.py:109} INFO - [2022-06-07 03:26:43,380] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 878173

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:26:43,380] {logging_mixin.py:109} INFO - [2022-06-07 03:26:43,380] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:26:43,381] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:26:43,392] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 03:27:13,676] {processor.py:163} INFO - Started process (PID=879267) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:27:13,676] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:27:13,676] {logging_mixin.py:109} INFO - [2022-06-07 03:27:13,676] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:27:43,680] {logging_mixin.py:109} INFO - [2022-06-07 03:27:43,680] {timeout.py:36} ERROR - Process timed out, PID: 879267
[2022-06-07 03:27:43,681] {logging_mixin.py:109} INFO - [2022-06-07 03:27:43,680] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 879267
[2022-06-07 03:27:43,681] {logging_mixin.py:109} INFO - [2022-06-07 03:27:43,681] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:27:43,681] {logging_mixin.py:109} INFO - [2022-06-07 03:27:43,681] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 879267

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:27:43,682] {logging_mixin.py:109} INFO - [2022-06-07 03:27:43,682] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:27:43,682] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:27:43,694] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 03:28:13,991] {processor.py:163} INFO - Started process (PID=880360) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:28:13,991] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:28:13,992] {logging_mixin.py:109} INFO - [2022-06-07 03:28:13,992] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:28:43,993] {logging_mixin.py:109} INFO - [2022-06-07 03:28:43,993] {timeout.py:36} ERROR - Process timed out, PID: 880360
[2022-06-07 03:28:43,994] {logging_mixin.py:109} INFO - [2022-06-07 03:28:43,994] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 880360
[2022-06-07 03:28:43,994] {logging_mixin.py:109} INFO - [2022-06-07 03:28:43,994] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:28:43,995] {logging_mixin.py:109} INFO - [2022-06-07 03:28:43,994] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 880360

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:28:43,995] {logging_mixin.py:109} INFO - [2022-06-07 03:28:43,995] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:28:43,995] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:28:44,007] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:29:14,224] {processor.py:163} INFO - Started process (PID=881455) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:29:14,224] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:29:14,224] {logging_mixin.py:109} INFO - [2022-06-07 03:29:14,224] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:29:44,226] {logging_mixin.py:109} INFO - [2022-06-07 03:29:44,226] {timeout.py:36} ERROR - Process timed out, PID: 881455
[2022-06-07 03:29:44,226] {logging_mixin.py:109} INFO - [2022-06-07 03:29:44,226] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 881455
[2022-06-07 03:29:44,227] {logging_mixin.py:109} INFO - [2022-06-07 03:29:44,227] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:29:44,227] {logging_mixin.py:109} INFO - [2022-06-07 03:29:44,227] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 881455

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:29:44,227] {logging_mixin.py:109} INFO - [2022-06-07 03:29:44,227] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:29:44,228] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:29:44,239] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 03:30:14,482] {processor.py:163} INFO - Started process (PID=882531) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:30:14,483] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:30:14,483] {logging_mixin.py:109} INFO - [2022-06-07 03:30:14,483] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:30:44,496] {logging_mixin.py:109} INFO - [2022-06-07 03:30:44,496] {timeout.py:36} ERROR - Process timed out, PID: 882531
[2022-06-07 03:30:44,497] {logging_mixin.py:109} INFO - [2022-06-07 03:30:44,497] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 882531
[2022-06-07 03:30:44,497] {logging_mixin.py:109} INFO - [2022-06-07 03:30:44,497] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:30:44,498] {logging_mixin.py:109} INFO - [2022-06-07 03:30:44,497] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 882531

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:30:44,498] {logging_mixin.py:109} INFO - [2022-06-07 03:30:44,498] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:30:44,498] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:30:44,511] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.030 seconds
[2022-06-07 03:31:14,666] {processor.py:163} INFO - Started process (PID=883620) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:31:14,666] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:31:14,667] {logging_mixin.py:109} INFO - [2022-06-07 03:31:14,667] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:31:44,670] {logging_mixin.py:109} INFO - [2022-06-07 03:31:44,670] {timeout.py:36} ERROR - Process timed out, PID: 883620
[2022-06-07 03:31:44,671] {logging_mixin.py:109} INFO - [2022-06-07 03:31:44,670] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 883620
[2022-06-07 03:31:44,671] {logging_mixin.py:109} INFO - [2022-06-07 03:31:44,671] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:31:44,672] {logging_mixin.py:109} INFO - [2022-06-07 03:31:44,671] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 883620

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:31:44,672] {logging_mixin.py:109} INFO - [2022-06-07 03:31:44,672] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:31:44,672] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:31:44,684] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 03:32:14,945] {processor.py:163} INFO - Started process (PID=884713) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:32:14,946] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:32:14,946] {logging_mixin.py:109} INFO - [2022-06-07 03:32:14,946] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:32:44,956] {logging_mixin.py:109} INFO - [2022-06-07 03:32:44,955] {timeout.py:36} ERROR - Process timed out, PID: 884713
[2022-06-07 03:32:44,956] {logging_mixin.py:109} INFO - [2022-06-07 03:32:44,956] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 884713
[2022-06-07 03:32:44,956] {logging_mixin.py:109} INFO - [2022-06-07 03:32:44,956] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:32:44,957] {logging_mixin.py:109} INFO - [2022-06-07 03:32:44,957] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 884713

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:32:44,957] {logging_mixin.py:109} INFO - [2022-06-07 03:32:44,957] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:32:44,958] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:32:44,969] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 03:33:15,211] {processor.py:163} INFO - Started process (PID=885806) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:33:15,211] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:33:15,212] {logging_mixin.py:109} INFO - [2022-06-07 03:33:15,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:33:45,216] {logging_mixin.py:109} INFO - [2022-06-07 03:33:45,215] {timeout.py:36} ERROR - Process timed out, PID: 885806
[2022-06-07 03:33:45,216] {logging_mixin.py:109} INFO - [2022-06-07 03:33:45,216] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 885806
[2022-06-07 03:33:45,216] {logging_mixin.py:109} INFO - [2022-06-07 03:33:45,216] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:33:45,217] {logging_mixin.py:109} INFO - [2022-06-07 03:33:45,217] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 885806

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:33:45,217] {logging_mixin.py:109} INFO - [2022-06-07 03:33:45,217] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:33:45,218] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:33:45,230] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 03:34:15,686] {processor.py:163} INFO - Started process (PID=886900) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:34:15,686] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:34:15,686] {logging_mixin.py:109} INFO - [2022-06-07 03:34:15,686] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:34:45,688] {logging_mixin.py:109} INFO - [2022-06-07 03:34:45,688] {timeout.py:36} ERROR - Process timed out, PID: 886900
[2022-06-07 03:34:45,689] {logging_mixin.py:109} INFO - [2022-06-07 03:34:45,688] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 886900
[2022-06-07 03:34:45,689] {logging_mixin.py:109} INFO - [2022-06-07 03:34:45,689] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:34:45,689] {logging_mixin.py:109} INFO - [2022-06-07 03:34:45,689] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 886900

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:34:45,690] {logging_mixin.py:109} INFO - [2022-06-07 03:34:45,689] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:34:45,690] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:34:45,701] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:35:16,042] {processor.py:163} INFO - Started process (PID=887993) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:35:16,042] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:35:16,043] {logging_mixin.py:109} INFO - [2022-06-07 03:35:16,043] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:35:46,043] {logging_mixin.py:109} INFO - [2022-06-07 03:35:46,043] {timeout.py:36} ERROR - Process timed out, PID: 887993
[2022-06-07 03:35:46,044] {logging_mixin.py:109} INFO - [2022-06-07 03:35:46,043] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 887993
[2022-06-07 03:35:46,044] {logging_mixin.py:109} INFO - [2022-06-07 03:35:46,044] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:35:46,045] {logging_mixin.py:109} INFO - [2022-06-07 03:35:46,044] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 887993

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:35:46,045] {logging_mixin.py:109} INFO - [2022-06-07 03:35:46,045] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:35:46,045] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:35:46,058] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:36:16,536] {processor.py:163} INFO - Started process (PID=889087) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:36:16,536] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:36:16,536] {logging_mixin.py:109} INFO - [2022-06-07 03:36:16,536] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:36:46,538] {logging_mixin.py:109} INFO - [2022-06-07 03:36:46,538] {timeout.py:36} ERROR - Process timed out, PID: 889087
[2022-06-07 03:36:46,539] {logging_mixin.py:109} INFO - [2022-06-07 03:36:46,538] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 889087
[2022-06-07 03:36:46,539] {logging_mixin.py:109} INFO - [2022-06-07 03:36:46,539] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:36:46,539] {logging_mixin.py:109} INFO - [2022-06-07 03:36:46,539] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 889087

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:36:46,540] {logging_mixin.py:109} INFO - [2022-06-07 03:36:46,539] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:36:46,540] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:36:46,551] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:37:17,048] {processor.py:163} INFO - Started process (PID=890180) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:37:17,048] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:37:17,049] {logging_mixin.py:109} INFO - [2022-06-07 03:37:17,048] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:37:47,050] {logging_mixin.py:109} INFO - [2022-06-07 03:37:47,049] {timeout.py:36} ERROR - Process timed out, PID: 890180
[2022-06-07 03:37:47,053] {logging_mixin.py:109} INFO - [2022-06-07 03:37:47,050] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 890180
[2022-06-07 03:37:47,053] {logging_mixin.py:109} INFO - [2022-06-07 03:37:47,053] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:37:47,054] {logging_mixin.py:109} INFO - [2022-06-07 03:37:47,054] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 890180

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:37:47,054] {logging_mixin.py:109} INFO - [2022-06-07 03:37:47,054] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:37:47,054] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:37:47,066] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 03:38:17,571] {processor.py:163} INFO - Started process (PID=891274) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:38:17,571] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:38:17,571] {logging_mixin.py:109} INFO - [2022-06-07 03:38:17,571] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:38:47,579] {logging_mixin.py:109} INFO - [2022-06-07 03:38:47,578] {timeout.py:36} ERROR - Process timed out, PID: 891274
[2022-06-07 03:38:47,579] {logging_mixin.py:109} INFO - [2022-06-07 03:38:47,579] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 891274
[2022-06-07 03:38:47,579] {logging_mixin.py:109} INFO - [2022-06-07 03:38:47,579] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:38:47,580] {logging_mixin.py:109} INFO - [2022-06-07 03:38:47,579] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 891274

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:38:47,580] {logging_mixin.py:109} INFO - [2022-06-07 03:38:47,580] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:38:47,580] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:38:47,593] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 03:39:18,028] {processor.py:163} INFO - Started process (PID=892368) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:39:18,029] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:39:18,029] {logging_mixin.py:109} INFO - [2022-06-07 03:39:18,029] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:39:48,030] {logging_mixin.py:109} INFO - [2022-06-07 03:39:48,030] {timeout.py:36} ERROR - Process timed out, PID: 892368
[2022-06-07 03:39:48,030] {logging_mixin.py:109} INFO - [2022-06-07 03:39:48,030] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 892368
[2022-06-07 03:39:48,031] {logging_mixin.py:109} INFO - [2022-06-07 03:39:48,031] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:39:48,031] {logging_mixin.py:109} INFO - [2022-06-07 03:39:48,031] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 892368

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:39:48,031] {logging_mixin.py:109} INFO - [2022-06-07 03:39:48,031] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:39:48,032] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:39:48,044] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:40:18,206] {processor.py:163} INFO - Started process (PID=893426) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:40:18,207] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:40:18,207] {logging_mixin.py:109} INFO - [2022-06-07 03:40:18,207] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:40:48,221] {logging_mixin.py:109} INFO - [2022-06-07 03:40:48,221] {timeout.py:36} ERROR - Process timed out, PID: 893426
[2022-06-07 03:40:48,222] {logging_mixin.py:109} INFO - [2022-06-07 03:40:48,221] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 893426
[2022-06-07 03:40:48,222] {logging_mixin.py:109} INFO - [2022-06-07 03:40:48,222] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:40:48,222] {logging_mixin.py:109} INFO - [2022-06-07 03:40:48,222] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 893426

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:40:48,223] {logging_mixin.py:109} INFO - [2022-06-07 03:40:48,223] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:40:48,223] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:40:48,234] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.030 seconds
[2022-06-07 03:41:18,572] {processor.py:163} INFO - Started process (PID=894520) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:41:18,572] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:41:18,573] {logging_mixin.py:109} INFO - [2022-06-07 03:41:18,572] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:41:48,576] {logging_mixin.py:109} INFO - [2022-06-07 03:41:48,576] {timeout.py:36} ERROR - Process timed out, PID: 894520
[2022-06-07 03:41:48,577] {logging_mixin.py:109} INFO - [2022-06-07 03:41:48,576] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 894520
[2022-06-07 03:41:48,577] {logging_mixin.py:109} INFO - [2022-06-07 03:41:48,577] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:41:48,577] {logging_mixin.py:109} INFO - [2022-06-07 03:41:48,577] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 894520

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:41:48,578] {logging_mixin.py:109} INFO - [2022-06-07 03:41:48,577] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:41:48,578] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:41:48,588] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:42:19,219] {processor.py:163} INFO - Started process (PID=895613) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:42:19,219] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:42:19,220] {logging_mixin.py:109} INFO - [2022-06-07 03:42:19,219] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:42:49,221] {logging_mixin.py:109} INFO - [2022-06-07 03:42:49,220] {timeout.py:36} ERROR - Process timed out, PID: 895613
[2022-06-07 03:42:49,221] {logging_mixin.py:109} INFO - [2022-06-07 03:42:49,221] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 895613
[2022-06-07 03:42:49,222] {logging_mixin.py:109} INFO - [2022-06-07 03:42:49,221] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:42:49,222] {logging_mixin.py:109} INFO - [2022-06-07 03:42:49,222] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 895613

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:42:49,222] {logging_mixin.py:109} INFO - [2022-06-07 03:42:49,222] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:42:49,223] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:42:49,235] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:43:19,458] {processor.py:163} INFO - Started process (PID=896708) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:43:19,458] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:43:19,459] {logging_mixin.py:109} INFO - [2022-06-07 03:43:19,459] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:43:49,465] {logging_mixin.py:109} INFO - [2022-06-07 03:43:49,465] {timeout.py:36} ERROR - Process timed out, PID: 896708
[2022-06-07 03:43:49,466] {logging_mixin.py:109} INFO - [2022-06-07 03:43:49,465] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 896708
[2022-06-07 03:43:49,466] {logging_mixin.py:109} INFO - [2022-06-07 03:43:49,466] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:43:49,466] {logging_mixin.py:109} INFO - [2022-06-07 03:43:49,466] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 896708

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:43:49,467] {logging_mixin.py:109} INFO - [2022-06-07 03:43:49,467] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:43:49,467] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:43:49,478] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 03:44:19,603] {processor.py:163} INFO - Started process (PID=897802) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:44:19,603] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:44:19,604] {logging_mixin.py:109} INFO - [2022-06-07 03:44:19,604] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:44:49,607] {logging_mixin.py:109} INFO - [2022-06-07 03:44:49,607] {timeout.py:36} ERROR - Process timed out, PID: 897802
[2022-06-07 03:44:49,608] {logging_mixin.py:109} INFO - [2022-06-07 03:44:49,607] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 897802
[2022-06-07 03:44:49,608] {logging_mixin.py:109} INFO - [2022-06-07 03:44:49,608] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:44:49,608] {logging_mixin.py:109} INFO - [2022-06-07 03:44:49,608] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 897802

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:44:49,609] {logging_mixin.py:109} INFO - [2022-06-07 03:44:49,608] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:44:49,609] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:44:49,620] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 03:45:19,795] {processor.py:163} INFO - Started process (PID=898895) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:45:19,795] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:45:19,796] {logging_mixin.py:109} INFO - [2022-06-07 03:45:19,796] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:45:49,797] {logging_mixin.py:109} INFO - [2022-06-07 03:45:49,797] {timeout.py:36} ERROR - Process timed out, PID: 898895
[2022-06-07 03:45:49,798] {logging_mixin.py:109} INFO - [2022-06-07 03:45:49,797] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 898895
[2022-06-07 03:45:49,798] {logging_mixin.py:109} INFO - [2022-06-07 03:45:49,798] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:45:49,798] {logging_mixin.py:109} INFO - [2022-06-07 03:45:49,798] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 898895

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:45:49,799] {logging_mixin.py:109} INFO - [2022-06-07 03:45:49,799] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:45:49,799] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:45:49,811] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:46:20,133] {processor.py:163} INFO - Started process (PID=899989) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:46:20,134] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:46:20,134] {logging_mixin.py:109} INFO - [2022-06-07 03:46:20,134] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:46:50,136] {logging_mixin.py:109} INFO - [2022-06-07 03:46:50,136] {timeout.py:36} ERROR - Process timed out, PID: 899989
[2022-06-07 03:46:50,137] {logging_mixin.py:109} INFO - [2022-06-07 03:46:50,136] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 899989
[2022-06-07 03:46:50,137] {logging_mixin.py:109} INFO - [2022-06-07 03:46:50,137] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:46:50,137] {logging_mixin.py:109} INFO - [2022-06-07 03:46:50,137] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 899989

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:46:50,138] {logging_mixin.py:109} INFO - [2022-06-07 03:46:50,137] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:46:50,138] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:46:50,149] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:47:20,238] {processor.py:163} INFO - Started process (PID=901083) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:47:20,238] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:47:20,239] {logging_mixin.py:109} INFO - [2022-06-07 03:47:20,239] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:47:50,244] {logging_mixin.py:109} INFO - [2022-06-07 03:47:50,244] {timeout.py:36} ERROR - Process timed out, PID: 901083
[2022-06-07 03:47:50,245] {logging_mixin.py:109} INFO - [2022-06-07 03:47:50,244] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 901083
[2022-06-07 03:47:50,245] {logging_mixin.py:109} INFO - [2022-06-07 03:47:50,245] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:47:50,245] {logging_mixin.py:109} INFO - [2022-06-07 03:47:50,245] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 901083

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:47:50,246] {logging_mixin.py:109} INFO - [2022-06-07 03:47:50,245] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:47:50,246] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:47:50,257] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 03:48:20,616] {processor.py:163} INFO - Started process (PID=902168) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:48:20,616] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:48:20,617] {logging_mixin.py:109} INFO - [2022-06-07 03:48:20,617] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:48:50,619] {logging_mixin.py:109} INFO - [2022-06-07 03:48:50,618] {timeout.py:36} ERROR - Process timed out, PID: 902168
[2022-06-07 03:48:50,619] {logging_mixin.py:109} INFO - [2022-06-07 03:48:50,619] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 902168
[2022-06-07 03:48:50,619] {logging_mixin.py:109} INFO - [2022-06-07 03:48:50,619] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:48:50,620] {logging_mixin.py:109} INFO - [2022-06-07 03:48:50,620] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 902168

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:48:50,620] {logging_mixin.py:109} INFO - [2022-06-07 03:48:50,620] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:48:50,620] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:48:50,631] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:49:20,649] {processor.py:163} INFO - Started process (PID=903262) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:49:20,649] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:49:20,650] {logging_mixin.py:109} INFO - [2022-06-07 03:49:20,650] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:49:50,666] {logging_mixin.py:109} INFO - [2022-06-07 03:49:50,665] {timeout.py:36} ERROR - Process timed out, PID: 903262
[2022-06-07 03:49:50,666] {logging_mixin.py:109} INFO - [2022-06-07 03:49:50,666] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 903262
[2022-06-07 03:49:50,666] {logging_mixin.py:109} INFO - [2022-06-07 03:49:50,666] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:49:50,667] {logging_mixin.py:109} INFO - [2022-06-07 03:49:50,666] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 903262

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:49:50,667] {logging_mixin.py:109} INFO - [2022-06-07 03:49:50,667] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:49:50,668] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:49:50,679] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.032 seconds
[2022-06-07 03:50:20,732] {processor.py:163} INFO - Started process (PID=904355) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:50:20,732] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:50:20,732] {logging_mixin.py:109} INFO - [2022-06-07 03:50:20,732] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:50:50,739] {logging_mixin.py:109} INFO - [2022-06-07 03:50:50,739] {timeout.py:36} ERROR - Process timed out, PID: 904355
[2022-06-07 03:50:50,740] {logging_mixin.py:109} INFO - [2022-06-07 03:50:50,739] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 904355
[2022-06-07 03:50:50,740] {logging_mixin.py:109} INFO - [2022-06-07 03:50:50,740] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:50:50,740] {logging_mixin.py:109} INFO - [2022-06-07 03:50:50,740] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 904355

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:50:50,741] {logging_mixin.py:109} INFO - [2022-06-07 03:50:50,740] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:50:50,741] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:50:50,753] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 03:51:20,830] {processor.py:163} INFO - Started process (PID=905448) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:51:20,831] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:51:20,831] {logging_mixin.py:109} INFO - [2022-06-07 03:51:20,831] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:51:50,839] {logging_mixin.py:109} INFO - [2022-06-07 03:51:50,838] {timeout.py:36} ERROR - Process timed out, PID: 905448
[2022-06-07 03:51:50,839] {logging_mixin.py:109} INFO - [2022-06-07 03:51:50,839] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 905448
[2022-06-07 03:51:50,839] {logging_mixin.py:109} INFO - [2022-06-07 03:51:50,839] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:51:50,840] {logging_mixin.py:109} INFO - [2022-06-07 03:51:50,840] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 905448

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:51:50,840] {logging_mixin.py:109} INFO - [2022-06-07 03:51:50,840] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:51:50,841] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:51:50,853] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 03:52:21,306] {processor.py:163} INFO - Started process (PID=906488) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:52:21,306] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:52:21,307] {logging_mixin.py:109} INFO - [2022-06-07 03:52:21,307] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:52:51,308] {logging_mixin.py:109} INFO - [2022-06-07 03:52:51,308] {timeout.py:36} ERROR - Process timed out, PID: 906488
[2022-06-07 03:52:51,309] {logging_mixin.py:109} INFO - [2022-06-07 03:52:51,308] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 906488
[2022-06-07 03:52:51,309] {logging_mixin.py:109} INFO - [2022-06-07 03:52:51,309] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:52:51,309] {logging_mixin.py:109} INFO - [2022-06-07 03:52:51,309] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 906488

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:52:51,310] {logging_mixin.py:109} INFO - [2022-06-07 03:52:51,309] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:52:51,310] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:52:51,322] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:53:22,290] {processor.py:163} INFO - Started process (PID=907582) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:53:22,291] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:53:22,291] {logging_mixin.py:109} INFO - [2022-06-07 03:53:22,291] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:53:52,295] {logging_mixin.py:109} INFO - [2022-06-07 03:53:52,294] {timeout.py:36} ERROR - Process timed out, PID: 907582
[2022-06-07 03:53:52,295] {logging_mixin.py:109} INFO - [2022-06-07 03:53:52,295] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 907582
[2022-06-07 03:53:52,295] {logging_mixin.py:109} INFO - [2022-06-07 03:53:52,295] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:53:52,296] {logging_mixin.py:109} INFO - [2022-06-07 03:53:52,296] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 907582

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:53:52,296] {logging_mixin.py:109} INFO - [2022-06-07 03:53:52,296] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:53:52,296] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:53:52,313] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 03:54:22,864] {processor.py:163} INFO - Started process (PID=908676) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:54:22,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:54:22,865] {logging_mixin.py:109} INFO - [2022-06-07 03:54:22,864] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:54:52,867] {logging_mixin.py:109} INFO - [2022-06-07 03:54:52,866] {timeout.py:36} ERROR - Process timed out, PID: 908676
[2022-06-07 03:54:52,867] {logging_mixin.py:109} INFO - [2022-06-07 03:54:52,867] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 908676
[2022-06-07 03:54:52,867] {logging_mixin.py:109} INFO - [2022-06-07 03:54:52,867] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:54:52,868] {logging_mixin.py:109} INFO - [2022-06-07 03:54:52,867] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 908676

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:54:52,868] {logging_mixin.py:109} INFO - [2022-06-07 03:54:52,868] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:54:52,868] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:54:52,879] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 03:55:23,839] {processor.py:163} INFO - Started process (PID=909770) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:55:23,840] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:55:23,840] {logging_mixin.py:109} INFO - [2022-06-07 03:55:23,840] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:55:53,844] {logging_mixin.py:109} INFO - [2022-06-07 03:55:53,844] {timeout.py:36} ERROR - Process timed out, PID: 909770
[2022-06-07 03:55:53,845] {logging_mixin.py:109} INFO - [2022-06-07 03:55:53,844] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 909770
[2022-06-07 03:55:53,845] {logging_mixin.py:109} INFO - [2022-06-07 03:55:53,845] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:55:53,845] {logging_mixin.py:109} INFO - [2022-06-07 03:55:53,845] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 909770

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:55:53,846] {logging_mixin.py:109} INFO - [2022-06-07 03:55:53,845] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:55:53,846] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:55:53,857] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 03:56:23,884] {processor.py:163} INFO - Started process (PID=910862) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:56:23,885] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:56:23,885] {logging_mixin.py:109} INFO - [2022-06-07 03:56:23,885] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:56:53,890] {logging_mixin.py:109} INFO - [2022-06-07 03:56:53,890] {timeout.py:36} ERROR - Process timed out, PID: 910862
[2022-06-07 03:56:53,891] {logging_mixin.py:109} INFO - [2022-06-07 03:56:53,890] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 910862
[2022-06-07 03:56:53,891] {logging_mixin.py:109} INFO - [2022-06-07 03:56:53,891] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:56:53,891] {logging_mixin.py:109} INFO - [2022-06-07 03:56:53,891] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 910862

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:56:53,892] {logging_mixin.py:109} INFO - [2022-06-07 03:56:53,892] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:56:53,892] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:56:53,903] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 03:57:24,339] {processor.py:163} INFO - Started process (PID=911918) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:57:24,340] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:57:24,340] {logging_mixin.py:109} INFO - [2022-06-07 03:57:24,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:57:54,341] {logging_mixin.py:109} INFO - [2022-06-07 03:57:54,341] {timeout.py:36} ERROR - Process timed out, PID: 911918
[2022-06-07 03:57:54,341] {logging_mixin.py:109} INFO - [2022-06-07 03:57:54,341] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 911918
[2022-06-07 03:57:54,342] {logging_mixin.py:109} INFO - [2022-06-07 03:57:54,341] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:57:54,342] {logging_mixin.py:109} INFO - [2022-06-07 03:57:54,342] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 911918

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:57:54,342] {logging_mixin.py:109} INFO - [2022-06-07 03:57:54,342] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:57:54,343] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:57:54,353] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 03:58:24,810] {processor.py:163} INFO - Started process (PID=913011) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:58:24,810] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:58:24,810] {logging_mixin.py:109} INFO - [2022-06-07 03:58:24,810] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:58:54,813] {logging_mixin.py:109} INFO - [2022-06-07 03:58:54,813] {timeout.py:36} ERROR - Process timed out, PID: 913011
[2022-06-07 03:58:54,814] {logging_mixin.py:109} INFO - [2022-06-07 03:58:54,813] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 913011
[2022-06-07 03:58:54,814] {logging_mixin.py:109} INFO - [2022-06-07 03:58:54,814] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:58:54,814] {logging_mixin.py:109} INFO - [2022-06-07 03:58:54,814] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 913011

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:58:54,814] {logging_mixin.py:109} INFO - [2022-06-07 03:58:54,814] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:58:54,815] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:58:54,826] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 03:59:25,031] {processor.py:163} INFO - Started process (PID=914104) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 03:59:25,031] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 03:59:25,031] {logging_mixin.py:109} INFO - [2022-06-07 03:59:25,031] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:59:55,037] {logging_mixin.py:109} INFO - [2022-06-07 03:59:55,036] {timeout.py:36} ERROR - Process timed out, PID: 914104
[2022-06-07 03:59:55,037] {logging_mixin.py:109} INFO - [2022-06-07 03:59:55,037] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 914104
[2022-06-07 03:59:55,038] {logging_mixin.py:109} INFO - [2022-06-07 03:59:55,038] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 03:59:55,038] {logging_mixin.py:109} INFO - [2022-06-07 03:59:55,038] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 914104

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 03:59:55,038] {logging_mixin.py:109} INFO - [2022-06-07 03:59:55,038] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 03:59:55,039] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 03:59:55,050] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 04:00:25,218] {processor.py:163} INFO - Started process (PID=915199) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:00:25,219] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:00:25,219] {logging_mixin.py:109} INFO - [2022-06-07 04:00:25,219] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:00:55,222] {logging_mixin.py:109} INFO - [2022-06-07 04:00:55,222] {timeout.py:36} ERROR - Process timed out, PID: 915199
[2022-06-07 04:00:55,223] {logging_mixin.py:109} INFO - [2022-06-07 04:00:55,222] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 915199
[2022-06-07 04:00:55,223] {logging_mixin.py:109} INFO - [2022-06-07 04:00:55,223] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:00:55,223] {logging_mixin.py:109} INFO - [2022-06-07 04:00:55,223] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 915199

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:00:55,224] {logging_mixin.py:109} INFO - [2022-06-07 04:00:55,224] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:00:55,224] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:00:55,235] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:01:25,770] {processor.py:163} INFO - Started process (PID=916293) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:01:25,770] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:01:25,770] {logging_mixin.py:109} INFO - [2022-06-07 04:01:25,770] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:01:55,771] {logging_mixin.py:109} INFO - [2022-06-07 04:01:55,771] {timeout.py:36} ERROR - Process timed out, PID: 916293
[2022-06-07 04:01:55,772] {logging_mixin.py:109} INFO - [2022-06-07 04:01:55,772] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 916293
[2022-06-07 04:01:55,772] {logging_mixin.py:109} INFO - [2022-06-07 04:01:55,772] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:01:55,773] {logging_mixin.py:109} INFO - [2022-06-07 04:01:55,772] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 916293

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:01:55,773] {logging_mixin.py:109} INFO - [2022-06-07 04:01:55,773] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:01:55,773] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:01:55,784] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 04:02:25,904] {processor.py:163} INFO - Started process (PID=917387) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:02:25,905] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:02:25,905] {logging_mixin.py:109} INFO - [2022-06-07 04:02:25,905] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:02:55,909] {logging_mixin.py:109} INFO - [2022-06-07 04:02:55,909] {timeout.py:36} ERROR - Process timed out, PID: 917387
[2022-06-07 04:02:55,910] {logging_mixin.py:109} INFO - [2022-06-07 04:02:55,909] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 917387
[2022-06-07 04:02:55,910] {logging_mixin.py:109} INFO - [2022-06-07 04:02:55,910] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:02:55,911] {logging_mixin.py:109} INFO - [2022-06-07 04:02:55,910] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 917387

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:02:55,911] {logging_mixin.py:109} INFO - [2022-06-07 04:02:55,911] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:02:55,911] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:02:55,922] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 04:03:26,551] {processor.py:163} INFO - Started process (PID=918481) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:03:26,551] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:03:26,551] {logging_mixin.py:109} INFO - [2022-06-07 04:03:26,551] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:03:56,553] {logging_mixin.py:109} INFO - [2022-06-07 04:03:56,553] {timeout.py:36} ERROR - Process timed out, PID: 918481
[2022-06-07 04:03:56,554] {logging_mixin.py:109} INFO - [2022-06-07 04:03:56,553] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 918481
[2022-06-07 04:03:56,554] {logging_mixin.py:109} INFO - [2022-06-07 04:03:56,554] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:03:56,554] {logging_mixin.py:109} INFO - [2022-06-07 04:03:56,554] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 918481

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:03:56,555] {logging_mixin.py:109} INFO - [2022-06-07 04:03:56,554] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:03:56,555] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:03:56,567] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:04:27,547] {processor.py:163} INFO - Started process (PID=919574) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:04:27,548] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:04:27,548] {logging_mixin.py:109} INFO - [2022-06-07 04:04:27,548] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:04:57,550] {logging_mixin.py:109} INFO - [2022-06-07 04:04:57,550] {timeout.py:36} ERROR - Process timed out, PID: 919574
[2022-06-07 04:04:57,551] {logging_mixin.py:109} INFO - [2022-06-07 04:04:57,551] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 919574
[2022-06-07 04:04:57,551] {logging_mixin.py:109} INFO - [2022-06-07 04:04:57,551] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:04:57,552] {logging_mixin.py:109} INFO - [2022-06-07 04:04:57,551] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 919574

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:04:57,552] {logging_mixin.py:109} INFO - [2022-06-07 04:04:57,552] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:04:57,552] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:04:57,564] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:05:28,264] {processor.py:163} INFO - Started process (PID=920667) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:05:28,264] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:05:28,265] {logging_mixin.py:109} INFO - [2022-06-07 04:05:28,265] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:05:58,267] {logging_mixin.py:109} INFO - [2022-06-07 04:05:58,266] {timeout.py:36} ERROR - Process timed out, PID: 920667
[2022-06-07 04:05:58,267] {logging_mixin.py:109} INFO - [2022-06-07 04:05:58,267] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 920667
[2022-06-07 04:05:58,267] {logging_mixin.py:109} INFO - [2022-06-07 04:05:58,267] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:05:58,268] {logging_mixin.py:109} INFO - [2022-06-07 04:05:58,267] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 920667

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:05:58,268] {logging_mixin.py:109} INFO - [2022-06-07 04:05:58,268] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:05:58,268] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:05:58,281] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:06:28,945] {processor.py:163} INFO - Started process (PID=921761) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:06:28,946] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:06:28,946] {logging_mixin.py:109} INFO - [2022-06-07 04:06:28,946] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:06:58,947] {logging_mixin.py:109} INFO - [2022-06-07 04:06:58,946] {timeout.py:36} ERROR - Process timed out, PID: 921761
[2022-06-07 04:06:58,947] {logging_mixin.py:109} INFO - [2022-06-07 04:06:58,947] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 921761
[2022-06-07 04:06:58,948] {logging_mixin.py:109} INFO - [2022-06-07 04:06:58,947] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:06:58,948] {logging_mixin.py:109} INFO - [2022-06-07 04:06:58,948] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 921761

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:06:58,949] {logging_mixin.py:109} INFO - [2022-06-07 04:06:58,948] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:06:58,949] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:06:58,962] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:07:29,912] {processor.py:163} INFO - Started process (PID=922855) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:07:29,912] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:07:29,912] {logging_mixin.py:109} INFO - [2022-06-07 04:07:29,912] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:07:59,913] {logging_mixin.py:109} INFO - [2022-06-07 04:07:59,913] {timeout.py:36} ERROR - Process timed out, PID: 922855
[2022-06-07 04:07:59,914] {logging_mixin.py:109} INFO - [2022-06-07 04:07:59,914] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 922855
[2022-06-07 04:07:59,914] {logging_mixin.py:109} INFO - [2022-06-07 04:07:59,914] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:07:59,915] {logging_mixin.py:109} INFO - [2022-06-07 04:07:59,914] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 922855

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:07:59,915] {logging_mixin.py:109} INFO - [2022-06-07 04:07:59,915] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:07:59,915] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:07:59,927] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 04:08:30,022] {processor.py:163} INFO - Started process (PID=923949) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:08:30,022] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:08:30,023] {logging_mixin.py:109} INFO - [2022-06-07 04:08:30,023] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:09:00,029] {logging_mixin.py:109} INFO - [2022-06-07 04:09:00,028] {timeout.py:36} ERROR - Process timed out, PID: 923949
[2022-06-07 04:09:00,029] {logging_mixin.py:109} INFO - [2022-06-07 04:09:00,029] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 923949
[2022-06-07 04:09:00,030] {logging_mixin.py:109} INFO - [2022-06-07 04:09:00,030] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:09:00,030] {logging_mixin.py:109} INFO - [2022-06-07 04:09:00,030] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 923949

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:09:00,031] {logging_mixin.py:109} INFO - [2022-06-07 04:09:00,030] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:09:00,031] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:09:00,043] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 04:09:30,920] {processor.py:163} INFO - Started process (PID=925042) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:09:30,920] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:09:30,921] {logging_mixin.py:109} INFO - [2022-06-07 04:09:30,921] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:10:00,923] {logging_mixin.py:109} INFO - [2022-06-07 04:10:00,922] {timeout.py:36} ERROR - Process timed out, PID: 925042
[2022-06-07 04:10:00,923] {logging_mixin.py:109} INFO - [2022-06-07 04:10:00,923] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 925042
[2022-06-07 04:10:00,923] {logging_mixin.py:109} INFO - [2022-06-07 04:10:00,923] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:10:00,924] {logging_mixin.py:109} INFO - [2022-06-07 04:10:00,923] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 925042

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:10:00,924] {logging_mixin.py:109} INFO - [2022-06-07 04:10:00,924] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:10:00,924] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:10:00,935] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 04:10:31,323] {processor.py:163} INFO - Started process (PID=926135) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:10:31,323] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:10:31,323] {logging_mixin.py:109} INFO - [2022-06-07 04:10:31,323] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:11:01,328] {logging_mixin.py:109} INFO - [2022-06-07 04:11:01,328] {timeout.py:36} ERROR - Process timed out, PID: 926135
[2022-06-07 04:11:01,329] {logging_mixin.py:109} INFO - [2022-06-07 04:11:01,328] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 926135
[2022-06-07 04:11:01,329] {logging_mixin.py:109} INFO - [2022-06-07 04:11:01,329] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:11:01,329] {logging_mixin.py:109} INFO - [2022-06-07 04:11:01,329] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 926135

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:11:01,330] {logging_mixin.py:109} INFO - [2022-06-07 04:11:01,330] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:11:01,330] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:11:01,341] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:11:31,798] {processor.py:163} INFO - Started process (PID=927194) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:11:31,798] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:11:31,799] {logging_mixin.py:109} INFO - [2022-06-07 04:11:31,798] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:12:01,808] {logging_mixin.py:109} INFO - [2022-06-07 04:12:01,808] {timeout.py:36} ERROR - Process timed out, PID: 927194
[2022-06-07 04:12:01,809] {logging_mixin.py:109} INFO - [2022-06-07 04:12:01,808] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 927194
[2022-06-07 04:12:01,809] {logging_mixin.py:109} INFO - [2022-06-07 04:12:01,809] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:12:01,810] {logging_mixin.py:109} INFO - [2022-06-07 04:12:01,809] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 927194

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:12:01,810] {logging_mixin.py:109} INFO - [2022-06-07 04:12:01,810] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:12:01,810] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:12:01,821] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 04:12:32,600] {processor.py:163} INFO - Started process (PID=928289) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:12:32,600] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:12:32,601] {logging_mixin.py:109} INFO - [2022-06-07 04:12:32,601] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:13:02,602] {logging_mixin.py:109} INFO - [2022-06-07 04:13:02,601] {timeout.py:36} ERROR - Process timed out, PID: 928289
[2022-06-07 04:13:02,602] {logging_mixin.py:109} INFO - [2022-06-07 04:13:02,602] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 928289
[2022-06-07 04:13:02,602] {logging_mixin.py:109} INFO - [2022-06-07 04:13:02,602] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:13:02,603] {logging_mixin.py:109} INFO - [2022-06-07 04:13:02,602] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 928289

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:13:02,603] {logging_mixin.py:109} INFO - [2022-06-07 04:13:02,603] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:13:02,603] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:13:02,617] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 04:13:33,235] {processor.py:163} INFO - Started process (PID=929382) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:13:33,235] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:13:33,236] {logging_mixin.py:109} INFO - [2022-06-07 04:13:33,236] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:14:03,241] {logging_mixin.py:109} INFO - [2022-06-07 04:14:03,241] {timeout.py:36} ERROR - Process timed out, PID: 929382
[2022-06-07 04:14:03,242] {logging_mixin.py:109} INFO - [2022-06-07 04:14:03,241] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 929382
[2022-06-07 04:14:03,242] {logging_mixin.py:109} INFO - [2022-06-07 04:14:03,242] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:14:03,242] {logging_mixin.py:109} INFO - [2022-06-07 04:14:03,242] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 929382

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:14:03,243] {logging_mixin.py:109} INFO - [2022-06-07 04:14:03,242] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:14:03,243] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:14:03,254] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 04:14:33,881] {processor.py:163} INFO - Started process (PID=930475) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:14:33,882] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:14:33,882] {logging_mixin.py:109} INFO - [2022-06-07 04:14:33,882] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:15:03,883] {logging_mixin.py:109} INFO - [2022-06-07 04:15:03,883] {timeout.py:36} ERROR - Process timed out, PID: 930475
[2022-06-07 04:15:03,883] {logging_mixin.py:109} INFO - [2022-06-07 04:15:03,883] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 930475
[2022-06-07 04:15:03,884] {logging_mixin.py:109} INFO - [2022-06-07 04:15:03,883] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:15:03,884] {logging_mixin.py:109} INFO - [2022-06-07 04:15:03,884] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 930475

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:15:03,884] {logging_mixin.py:109} INFO - [2022-06-07 04:15:03,884] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:15:03,885] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:15:03,897] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 04:15:34,008] {processor.py:163} INFO - Started process (PID=931550) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:15:34,009] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:15:34,009] {logging_mixin.py:109} INFO - [2022-06-07 04:15:34,009] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:16:04,010] {logging_mixin.py:109} INFO - [2022-06-07 04:16:04,009] {timeout.py:36} ERROR - Process timed out, PID: 931550
[2022-06-07 04:16:04,010] {logging_mixin.py:109} INFO - [2022-06-07 04:16:04,010] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 931550
[2022-06-07 04:16:04,010] {logging_mixin.py:109} INFO - [2022-06-07 04:16:04,010] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:16:04,011] {logging_mixin.py:109} INFO - [2022-06-07 04:16:04,010] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 931550

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:16:04,011] {logging_mixin.py:109} INFO - [2022-06-07 04:16:04,011] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:16:04,012] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:16:04,025] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:16:34,204] {processor.py:163} INFO - Started process (PID=932632) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:16:34,204] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:16:34,204] {logging_mixin.py:109} INFO - [2022-06-07 04:16:34,204] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:17:04,207] {logging_mixin.py:109} INFO - [2022-06-07 04:17:04,206] {timeout.py:36} ERROR - Process timed out, PID: 932632
[2022-06-07 04:17:04,207] {logging_mixin.py:109} INFO - [2022-06-07 04:17:04,207] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 932632
[2022-06-07 04:17:04,207] {logging_mixin.py:109} INFO - [2022-06-07 04:17:04,207] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:17:04,208] {logging_mixin.py:109} INFO - [2022-06-07 04:17:04,207] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 932632

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:17:04,208] {logging_mixin.py:109} INFO - [2022-06-07 04:17:04,208] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:17:04,208] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:17:04,220] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:17:34,439] {processor.py:163} INFO - Started process (PID=933725) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:17:34,440] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:17:34,440] {logging_mixin.py:109} INFO - [2022-06-07 04:17:34,440] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:18:04,447] {logging_mixin.py:109} INFO - [2022-06-07 04:18:04,446] {timeout.py:36} ERROR - Process timed out, PID: 933725
[2022-06-07 04:18:04,447] {logging_mixin.py:109} INFO - [2022-06-07 04:18:04,447] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 933725
[2022-06-07 04:18:04,447] {logging_mixin.py:109} INFO - [2022-06-07 04:18:04,447] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:18:04,448] {logging_mixin.py:109} INFO - [2022-06-07 04:18:04,447] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 933725

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:18:04,448] {logging_mixin.py:109} INFO - [2022-06-07 04:18:04,448] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:18:04,448] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:18:04,460] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 04:18:34,649] {processor.py:163} INFO - Started process (PID=934819) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:18:34,650] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:18:34,650] {logging_mixin.py:109} INFO - [2022-06-07 04:18:34,650] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:19:04,663] {logging_mixin.py:109} INFO - [2022-06-07 04:19:04,662] {timeout.py:36} ERROR - Process timed out, PID: 934819
[2022-06-07 04:19:04,663] {logging_mixin.py:109} INFO - [2022-06-07 04:19:04,663] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 934819
[2022-06-07 04:19:04,663] {logging_mixin.py:109} INFO - [2022-06-07 04:19:04,663] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:19:04,664] {logging_mixin.py:109} INFO - [2022-06-07 04:19:04,663] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 934819

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:19:04,664] {logging_mixin.py:109} INFO - [2022-06-07 04:19:04,664] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:19:04,664] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:19:04,676] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 04:19:34,987] {processor.py:163} INFO - Started process (PID=935912) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:19:34,988] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:19:34,988] {logging_mixin.py:109} INFO - [2022-06-07 04:19:34,988] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:20:04,991] {logging_mixin.py:109} INFO - [2022-06-07 04:20:04,991] {timeout.py:36} ERROR - Process timed out, PID: 935912
[2022-06-07 04:20:04,992] {logging_mixin.py:109} INFO - [2022-06-07 04:20:04,991] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 935912
[2022-06-07 04:20:04,992] {logging_mixin.py:109} INFO - [2022-06-07 04:20:04,992] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:20:04,992] {logging_mixin.py:109} INFO - [2022-06-07 04:20:04,992] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 935912

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:20:04,992] {logging_mixin.py:109} INFO - [2022-06-07 04:20:04,992] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:20:04,993] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:20:05,004] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:20:35,256] {processor.py:163} INFO - Started process (PID=937006) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:20:35,257] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:20:35,257] {logging_mixin.py:109} INFO - [2022-06-07 04:20:35,257] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:21:05,259] {logging_mixin.py:109} INFO - [2022-06-07 04:21:05,259] {timeout.py:36} ERROR - Process timed out, PID: 937006
[2022-06-07 04:21:05,260] {logging_mixin.py:109} INFO - [2022-06-07 04:21:05,259] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 937006
[2022-06-07 04:21:05,260] {logging_mixin.py:109} INFO - [2022-06-07 04:21:05,260] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:21:05,260] {logging_mixin.py:109} INFO - [2022-06-07 04:21:05,260] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 937006

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:21:05,261] {logging_mixin.py:109} INFO - [2022-06-07 04:21:05,260] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:21:05,261] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:21:05,273] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:21:35,898] {processor.py:163} INFO - Started process (PID=938100) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:21:35,899] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:21:35,899] {logging_mixin.py:109} INFO - [2022-06-07 04:21:35,899] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:22:05,906] {logging_mixin.py:109} INFO - [2022-06-07 04:22:05,906] {timeout.py:36} ERROR - Process timed out, PID: 938100
[2022-06-07 04:22:05,907] {logging_mixin.py:109} INFO - [2022-06-07 04:22:05,906] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 938100
[2022-06-07 04:22:05,907] {logging_mixin.py:109} INFO - [2022-06-07 04:22:05,907] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:22:05,907] {logging_mixin.py:109} INFO - [2022-06-07 04:22:05,907] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 938100

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:22:05,908] {logging_mixin.py:109} INFO - [2022-06-07 04:22:05,908] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:22:05,908] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:22:05,920] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 04:22:36,334] {processor.py:163} INFO - Started process (PID=939193) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:22:36,335] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:22:36,335] {logging_mixin.py:109} INFO - [2022-06-07 04:22:36,335] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:23:06,345] {logging_mixin.py:109} INFO - [2022-06-07 04:23:06,345] {timeout.py:36} ERROR - Process timed out, PID: 939193
[2022-06-07 04:23:06,346] {logging_mixin.py:109} INFO - [2022-06-07 04:23:06,346] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 939193
[2022-06-07 04:23:06,346] {logging_mixin.py:109} INFO - [2022-06-07 04:23:06,346] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:23:06,347] {logging_mixin.py:109} INFO - [2022-06-07 04:23:06,346] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 939193

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:23:06,347] {logging_mixin.py:109} INFO - [2022-06-07 04:23:06,347] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:23:06,347] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:23:06,359] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 04:23:36,657] {processor.py:163} INFO - Started process (PID=940287) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:23:36,657] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:23:36,657] {logging_mixin.py:109} INFO - [2022-06-07 04:23:36,657] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:24:06,658] {logging_mixin.py:109} INFO - [2022-06-07 04:24:06,658] {timeout.py:36} ERROR - Process timed out, PID: 940287
[2022-06-07 04:24:06,659] {logging_mixin.py:109} INFO - [2022-06-07 04:24:06,658] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 940287
[2022-06-07 04:24:06,659] {logging_mixin.py:109} INFO - [2022-06-07 04:24:06,659] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:24:06,659] {logging_mixin.py:109} INFO - [2022-06-07 04:24:06,659] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 940287

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:24:06,660] {logging_mixin.py:109} INFO - [2022-06-07 04:24:06,660] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:24:06,660] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:24:06,673] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 04:24:37,061] {processor.py:163} INFO - Started process (PID=941381) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:24:37,062] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:24:37,062] {logging_mixin.py:109} INFO - [2022-06-07 04:24:37,062] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:25:07,064] {logging_mixin.py:109} INFO - [2022-06-07 04:25:07,064] {timeout.py:36} ERROR - Process timed out, PID: 941381
[2022-06-07 04:25:07,065] {logging_mixin.py:109} INFO - [2022-06-07 04:25:07,064] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 941381
[2022-06-07 04:25:07,065] {logging_mixin.py:109} INFO - [2022-06-07 04:25:07,065] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:25:07,065] {logging_mixin.py:109} INFO - [2022-06-07 04:25:07,065] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 941381

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:25:07,066] {logging_mixin.py:109} INFO - [2022-06-07 04:25:07,066] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:25:07,066] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:25:07,078] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:25:37,456] {processor.py:163} INFO - Started process (PID=942474) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:25:37,457] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:25:37,457] {logging_mixin.py:109} INFO - [2022-06-07 04:25:37,457] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:26:07,459] {logging_mixin.py:109} INFO - [2022-06-07 04:26:07,458] {timeout.py:36} ERROR - Process timed out, PID: 942474
[2022-06-07 04:26:07,459] {logging_mixin.py:109} INFO - [2022-06-07 04:26:07,459] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 942474
[2022-06-07 04:26:07,459] {logging_mixin.py:109} INFO - [2022-06-07 04:26:07,459] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:26:07,460] {logging_mixin.py:109} INFO - [2022-06-07 04:26:07,459] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 942474

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:26:07,460] {logging_mixin.py:109} INFO - [2022-06-07 04:26:07,460] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:26:07,461] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:26:07,473] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:26:37,786] {processor.py:163} INFO - Started process (PID=943569) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:26:37,786] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:26:37,786] {logging_mixin.py:109} INFO - [2022-06-07 04:26:37,786] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:27:07,790] {logging_mixin.py:109} INFO - [2022-06-07 04:27:07,790] {timeout.py:36} ERROR - Process timed out, PID: 943569
[2022-06-07 04:27:07,791] {logging_mixin.py:109} INFO - [2022-06-07 04:27:07,790] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 943569
[2022-06-07 04:27:07,791] {logging_mixin.py:109} INFO - [2022-06-07 04:27:07,791] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:27:07,791] {logging_mixin.py:109} INFO - [2022-06-07 04:27:07,791] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 943569

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:27:07,792] {logging_mixin.py:109} INFO - [2022-06-07 04:27:07,791] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:27:07,792] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:27:07,804] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:27:37,990] {processor.py:163} INFO - Started process (PID=944657) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:27:37,990] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:27:37,990] {logging_mixin.py:109} INFO - [2022-06-07 04:27:37,990] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:28:07,992] {logging_mixin.py:109} INFO - [2022-06-07 04:28:07,991] {timeout.py:36} ERROR - Process timed out, PID: 944657
[2022-06-07 04:28:07,993] {logging_mixin.py:109} INFO - [2022-06-07 04:28:07,992] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 944657
[2022-06-07 04:28:07,993] {logging_mixin.py:109} INFO - [2022-06-07 04:28:07,993] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:28:07,994] {logging_mixin.py:109} INFO - [2022-06-07 04:28:07,993] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 944657

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:28:07,994] {logging_mixin.py:109} INFO - [2022-06-07 04:28:07,994] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:28:07,995] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:28:08,008] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:28:38,320] {processor.py:163} INFO - Started process (PID=945737) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:28:38,320] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:28:38,321] {logging_mixin.py:109} INFO - [2022-06-07 04:28:38,321] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:29:08,322] {logging_mixin.py:109} INFO - [2022-06-07 04:29:08,321] {timeout.py:36} ERROR - Process timed out, PID: 945737
[2022-06-07 04:29:08,322] {logging_mixin.py:109} INFO - [2022-06-07 04:29:08,322] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 945737
[2022-06-07 04:29:08,322] {logging_mixin.py:109} INFO - [2022-06-07 04:29:08,322] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:29:08,323] {logging_mixin.py:109} INFO - [2022-06-07 04:29:08,322] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 945737

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:29:08,323] {logging_mixin.py:109} INFO - [2022-06-07 04:29:08,323] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:29:08,324] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:29:08,336] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:29:38,723] {processor.py:163} INFO - Started process (PID=946791) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:29:38,723] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:29:38,724] {logging_mixin.py:109} INFO - [2022-06-07 04:29:38,723] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:30:08,726] {logging_mixin.py:109} INFO - [2022-06-07 04:30:08,725] {timeout.py:36} ERROR - Process timed out, PID: 946791
[2022-06-07 04:30:08,726] {logging_mixin.py:109} INFO - [2022-06-07 04:30:08,726] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 946791
[2022-06-07 04:30:08,726] {logging_mixin.py:109} INFO - [2022-06-07 04:30:08,726] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:30:08,727] {logging_mixin.py:109} INFO - [2022-06-07 04:30:08,726] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 946791

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:30:08,727] {logging_mixin.py:109} INFO - [2022-06-07 04:30:08,727] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:30:08,727] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:30:08,738] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 04:30:38,888] {processor.py:163} INFO - Started process (PID=947883) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:30:38,889] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:30:38,889] {logging_mixin.py:109} INFO - [2022-06-07 04:30:38,889] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:31:08,894] {logging_mixin.py:109} INFO - [2022-06-07 04:31:08,893] {timeout.py:36} ERROR - Process timed out, PID: 947883
[2022-06-07 04:31:08,894] {logging_mixin.py:109} INFO - [2022-06-07 04:31:08,894] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 947883
[2022-06-07 04:31:08,894] {logging_mixin.py:109} INFO - [2022-06-07 04:31:08,894] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:31:08,895] {logging_mixin.py:109} INFO - [2022-06-07 04:31:08,895] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 947883

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:31:08,895] {logging_mixin.py:109} INFO - [2022-06-07 04:31:08,895] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:31:08,895] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:31:08,907] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:31:39,118] {processor.py:163} INFO - Started process (PID=948976) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:31:39,118] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:31:39,118] {logging_mixin.py:109} INFO - [2022-06-07 04:31:39,118] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:32:09,129] {logging_mixin.py:109} INFO - [2022-06-07 04:32:09,129] {timeout.py:36} ERROR - Process timed out, PID: 948976
[2022-06-07 04:32:09,130] {logging_mixin.py:109} INFO - [2022-06-07 04:32:09,130] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 948976
[2022-06-07 04:32:09,130] {logging_mixin.py:109} INFO - [2022-06-07 04:32:09,130] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:32:09,131] {logging_mixin.py:109} INFO - [2022-06-07 04:32:09,130] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 948976

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:32:09,131] {logging_mixin.py:109} INFO - [2022-06-07 04:32:09,131] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:32:09,131] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:32:09,143] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.027 seconds
[2022-06-07 04:32:39,497] {processor.py:163} INFO - Started process (PID=950071) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:32:39,497] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:32:39,497] {logging_mixin.py:109} INFO - [2022-06-07 04:32:39,497] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:33:09,501] {logging_mixin.py:109} INFO - [2022-06-07 04:33:09,501] {timeout.py:36} ERROR - Process timed out, PID: 950071
[2022-06-07 04:33:09,502] {logging_mixin.py:109} INFO - [2022-06-07 04:33:09,501] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 950071
[2022-06-07 04:33:09,502] {logging_mixin.py:109} INFO - [2022-06-07 04:33:09,502] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:33:09,502] {logging_mixin.py:109} INFO - [2022-06-07 04:33:09,502] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 950071

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:33:09,503] {logging_mixin.py:109} INFO - [2022-06-07 04:33:09,502] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:33:09,503] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:33:09,515] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:33:39,805] {processor.py:163} INFO - Started process (PID=951164) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:33:39,806] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:33:39,806] {logging_mixin.py:109} INFO - [2022-06-07 04:33:39,806] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:34:09,808] {logging_mixin.py:109} INFO - [2022-06-07 04:34:09,808] {timeout.py:36} ERROR - Process timed out, PID: 951164
[2022-06-07 04:34:09,809] {logging_mixin.py:109} INFO - [2022-06-07 04:34:09,808] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 951164
[2022-06-07 04:34:09,809] {logging_mixin.py:109} INFO - [2022-06-07 04:34:09,809] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:34:09,809] {logging_mixin.py:109} INFO - [2022-06-07 04:34:09,809] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 951164

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:34:09,810] {logging_mixin.py:109} INFO - [2022-06-07 04:34:09,809] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:34:09,810] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:34:09,821] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 04:34:40,236] {processor.py:163} INFO - Started process (PID=952259) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:34:40,236] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:34:40,236] {logging_mixin.py:109} INFO - [2022-06-07 04:34:40,236] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:35:10,250] {logging_mixin.py:109} INFO - [2022-06-07 04:35:10,249] {timeout.py:36} ERROR - Process timed out, PID: 952259
[2022-06-07 04:35:10,250] {logging_mixin.py:109} INFO - [2022-06-07 04:35:10,250] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 952259
[2022-06-07 04:35:10,250] {logging_mixin.py:109} INFO - [2022-06-07 04:35:10,250] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:35:10,251] {logging_mixin.py:109} INFO - [2022-06-07 04:35:10,250] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 952259

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:35:10,251] {logging_mixin.py:109} INFO - [2022-06-07 04:35:10,251] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:35:10,251] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:35:10,263] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 04:35:40,576] {processor.py:163} INFO - Started process (PID=953353) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:35:40,576] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:35:40,577] {logging_mixin.py:109} INFO - [2022-06-07 04:35:40,577] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:36:10,579] {logging_mixin.py:109} INFO - [2022-06-07 04:36:10,579] {timeout.py:36} ERROR - Process timed out, PID: 953353
[2022-06-07 04:36:10,580] {logging_mixin.py:109} INFO - [2022-06-07 04:36:10,579] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 953353
[2022-06-07 04:36:10,580] {logging_mixin.py:109} INFO - [2022-06-07 04:36:10,580] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:36:10,580] {logging_mixin.py:109} INFO - [2022-06-07 04:36:10,580] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 953353

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:36:10,581] {logging_mixin.py:109} INFO - [2022-06-07 04:36:10,581] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:36:10,581] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:36:10,592] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 04:36:41,035] {processor.py:163} INFO - Started process (PID=954448) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:36:41,035] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:36:41,035] {logging_mixin.py:109} INFO - [2022-06-07 04:36:41,035] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:37:11,048] {logging_mixin.py:109} INFO - [2022-06-07 04:37:11,047] {timeout.py:36} ERROR - Process timed out, PID: 954448
[2022-06-07 04:37:11,048] {logging_mixin.py:109} INFO - [2022-06-07 04:37:11,048] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 954448
[2022-06-07 04:37:11,048] {logging_mixin.py:109} INFO - [2022-06-07 04:37:11,048] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:37:11,049] {logging_mixin.py:109} INFO - [2022-06-07 04:37:11,049] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 954448

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:37:11,049] {logging_mixin.py:109} INFO - [2022-06-07 04:37:11,049] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:37:11,050] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:37:11,061] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 04:37:41,584] {processor.py:163} INFO - Started process (PID=955543) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:37:41,585] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:37:41,585] {logging_mixin.py:109} INFO - [2022-06-07 04:37:41,585] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:38:11,589] {logging_mixin.py:109} INFO - [2022-06-07 04:38:11,588] {timeout.py:36} ERROR - Process timed out, PID: 955543
[2022-06-07 04:38:11,589] {logging_mixin.py:109} INFO - [2022-06-07 04:38:11,589] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 955543
[2022-06-07 04:38:11,589] {logging_mixin.py:109} INFO - [2022-06-07 04:38:11,589] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:38:11,590] {logging_mixin.py:109} INFO - [2022-06-07 04:38:11,589] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 955543

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:38:11,590] {logging_mixin.py:109} INFO - [2022-06-07 04:38:11,590] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:38:11,590] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:38:11,603] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:38:41,925] {processor.py:163} INFO - Started process (PID=956636) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:38:41,925] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:38:41,926] {logging_mixin.py:109} INFO - [2022-06-07 04:38:41,925] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:39:11,929] {logging_mixin.py:109} INFO - [2022-06-07 04:39:11,929] {timeout.py:36} ERROR - Process timed out, PID: 956636
[2022-06-07 04:39:11,930] {logging_mixin.py:109} INFO - [2022-06-07 04:39:11,929] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 956636
[2022-06-07 04:39:11,930] {logging_mixin.py:109} INFO - [2022-06-07 04:39:11,930] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:39:11,930] {logging_mixin.py:109} INFO - [2022-06-07 04:39:11,930] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 956636

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:39:11,931] {logging_mixin.py:109} INFO - [2022-06-07 04:39:11,931] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:39:11,931] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:39:11,944] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 04:39:42,430] {processor.py:163} INFO - Started process (PID=957729) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:39:42,430] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:39:42,431] {logging_mixin.py:109} INFO - [2022-06-07 04:39:42,430] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:40:12,443] {logging_mixin.py:109} INFO - [2022-06-07 04:40:12,442] {timeout.py:36} ERROR - Process timed out, PID: 957729
[2022-06-07 04:40:12,443] {logging_mixin.py:109} INFO - [2022-06-07 04:40:12,443] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 957729
[2022-06-07 04:40:12,443] {logging_mixin.py:109} INFO - [2022-06-07 04:40:12,443] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:40:12,444] {logging_mixin.py:109} INFO - [2022-06-07 04:40:12,444] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 957729

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:40:12,444] {logging_mixin.py:109} INFO - [2022-06-07 04:40:12,444] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:40:12,445] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:40:12,456] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 04:40:42,844] {processor.py:163} INFO - Started process (PID=958824) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:40:42,845] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:40:42,845] {logging_mixin.py:109} INFO - [2022-06-07 04:40:42,845] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:41:12,847] {logging_mixin.py:109} INFO - [2022-06-07 04:41:12,846] {timeout.py:36} ERROR - Process timed out, PID: 958824
[2022-06-07 04:41:12,847] {logging_mixin.py:109} INFO - [2022-06-07 04:41:12,847] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 958824
[2022-06-07 04:41:12,847] {logging_mixin.py:109} INFO - [2022-06-07 04:41:12,847] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:41:12,848] {logging_mixin.py:109} INFO - [2022-06-07 04:41:12,847] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 958824

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:41:12,848] {logging_mixin.py:109} INFO - [2022-06-07 04:41:12,848] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:41:12,848] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:41:12,860] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 04:41:43,279] {processor.py:163} INFO - Started process (PID=959916) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:41:43,279] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:41:43,280] {logging_mixin.py:109} INFO - [2022-06-07 04:41:43,280] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:42:13,300] {logging_mixin.py:109} INFO - [2022-06-07 04:42:13,299] {timeout.py:36} ERROR - Process timed out, PID: 959916
[2022-06-07 04:42:13,300] {logging_mixin.py:109} INFO - [2022-06-07 04:42:13,300] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 959916
[2022-06-07 04:42:13,300] {logging_mixin.py:109} INFO - [2022-06-07 04:42:13,300] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:42:13,301] {logging_mixin.py:109} INFO - [2022-06-07 04:42:13,300] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 959916

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:42:13,301] {logging_mixin.py:109} INFO - [2022-06-07 04:42:13,301] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:42:13,301] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:42:13,313] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.035 seconds
[2022-06-07 04:42:43,735] {processor.py:163} INFO - Started process (PID=961010) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:42:43,736] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:42:43,736] {logging_mixin.py:109} INFO - [2022-06-07 04:42:43,736] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:43:13,738] {logging_mixin.py:109} INFO - [2022-06-07 04:43:13,738] {timeout.py:36} ERROR - Process timed out, PID: 961010
[2022-06-07 04:43:13,739] {logging_mixin.py:109} INFO - [2022-06-07 04:43:13,738] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 961010
[2022-06-07 04:43:13,739] {logging_mixin.py:109} INFO - [2022-06-07 04:43:13,739] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:43:13,739] {logging_mixin.py:109} INFO - [2022-06-07 04:43:13,739] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 961010

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:43:13,740] {logging_mixin.py:109} INFO - [2022-06-07 04:43:13,739] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:43:13,740] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:43:13,752] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:43:44,183] {processor.py:163} INFO - Started process (PID=962102) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:43:44,184] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:43:44,184] {logging_mixin.py:109} INFO - [2022-06-07 04:43:44,184] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:44:14,185] {logging_mixin.py:109} INFO - [2022-06-07 04:44:14,185] {timeout.py:36} ERROR - Process timed out, PID: 962102
[2022-06-07 04:44:14,186] {logging_mixin.py:109} INFO - [2022-06-07 04:44:14,185] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 962102
[2022-06-07 04:44:14,186] {logging_mixin.py:109} INFO - [2022-06-07 04:44:14,186] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:44:14,186] {logging_mixin.py:109} INFO - [2022-06-07 04:44:14,186] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 962102

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:44:14,187] {logging_mixin.py:109} INFO - [2022-06-07 04:44:14,186] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:44:14,187] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:44:14,197] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 04:44:44,822] {processor.py:163} INFO - Started process (PID=963161) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:44:44,822] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:44:44,823] {logging_mixin.py:109} INFO - [2022-06-07 04:44:44,823] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:45:14,824] {logging_mixin.py:109} INFO - [2022-06-07 04:45:14,824] {timeout.py:36} ERROR - Process timed out, PID: 963161
[2022-06-07 04:45:14,825] {logging_mixin.py:109} INFO - [2022-06-07 04:45:14,824] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 963161
[2022-06-07 04:45:14,825] {logging_mixin.py:109} INFO - [2022-06-07 04:45:14,825] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:45:14,826] {logging_mixin.py:109} INFO - [2022-06-07 04:45:14,825] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 963161

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:45:14,826] {logging_mixin.py:109} INFO - [2022-06-07 04:45:14,826] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:45:14,826] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:45:14,839] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:45:45,220] {processor.py:163} INFO - Started process (PID=964256) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:45:45,220] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:45:45,220] {logging_mixin.py:109} INFO - [2022-06-07 04:45:45,220] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:46:15,225] {logging_mixin.py:109} INFO - [2022-06-07 04:46:15,224] {timeout.py:36} ERROR - Process timed out, PID: 964256
[2022-06-07 04:46:15,226] {logging_mixin.py:109} INFO - [2022-06-07 04:46:15,225] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 964256
[2022-06-07 04:46:15,226] {logging_mixin.py:109} INFO - [2022-06-07 04:46:15,226] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:46:15,226] {logging_mixin.py:109} INFO - [2022-06-07 04:46:15,226] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 964256

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:46:15,227] {logging_mixin.py:109} INFO - [2022-06-07 04:46:15,226] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:46:15,227] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:46:15,238] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:46:45,696] {processor.py:163} INFO - Started process (PID=965348) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:46:45,696] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:46:45,697] {logging_mixin.py:109} INFO - [2022-06-07 04:46:45,697] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:47:15,701] {logging_mixin.py:109} INFO - [2022-06-07 04:47:15,700] {timeout.py:36} ERROR - Process timed out, PID: 965348
[2022-06-07 04:47:15,701] {logging_mixin.py:109} INFO - [2022-06-07 04:47:15,701] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 965348
[2022-06-07 04:47:15,701] {logging_mixin.py:109} INFO - [2022-06-07 04:47:15,701] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:47:15,702] {logging_mixin.py:109} INFO - [2022-06-07 04:47:15,701] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 965348

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:47:15,702] {logging_mixin.py:109} INFO - [2022-06-07 04:47:15,702] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:47:15,702] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:47:15,715] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:47:46,000] {processor.py:163} INFO - Started process (PID=966418) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:47:46,001] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:47:46,001] {logging_mixin.py:109} INFO - [2022-06-07 04:47:46,001] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:48:16,003] {logging_mixin.py:109} INFO - [2022-06-07 04:48:16,002] {timeout.py:36} ERROR - Process timed out, PID: 966418
[2022-06-07 04:48:16,003] {logging_mixin.py:109} INFO - [2022-06-07 04:48:16,003] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 966418
[2022-06-07 04:48:16,003] {logging_mixin.py:109} INFO - [2022-06-07 04:48:16,003] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:48:16,004] {logging_mixin.py:109} INFO - [2022-06-07 04:48:16,003] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 966418

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:48:16,004] {logging_mixin.py:109} INFO - [2022-06-07 04:48:16,004] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:48:16,004] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:48:16,016] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 04:48:46,544] {processor.py:163} INFO - Started process (PID=967513) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:48:46,544] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:48:46,544] {logging_mixin.py:109} INFO - [2022-06-07 04:48:46,544] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:49:16,546] {logging_mixin.py:109} INFO - [2022-06-07 04:49:16,546] {timeout.py:36} ERROR - Process timed out, PID: 967513
[2022-06-07 04:49:16,547] {logging_mixin.py:109} INFO - [2022-06-07 04:49:16,546] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 967513
[2022-06-07 04:49:16,547] {logging_mixin.py:109} INFO - [2022-06-07 04:49:16,547] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:49:16,547] {logging_mixin.py:109} INFO - [2022-06-07 04:49:16,547] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 967513

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:49:16,548] {logging_mixin.py:109} INFO - [2022-06-07 04:49:16,547] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:49:16,548] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:49:16,560] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:49:46,972] {processor.py:163} INFO - Started process (PID=968608) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:49:46,973] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:49:46,973] {logging_mixin.py:109} INFO - [2022-06-07 04:49:46,973] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:50:16,976] {logging_mixin.py:109} INFO - [2022-06-07 04:50:16,976] {timeout.py:36} ERROR - Process timed out, PID: 968608
[2022-06-07 04:50:16,977] {logging_mixin.py:109} INFO - [2022-06-07 04:50:16,976] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 968608
[2022-06-07 04:50:16,977] {logging_mixin.py:109} INFO - [2022-06-07 04:50:16,977] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:50:16,977] {logging_mixin.py:109} INFO - [2022-06-07 04:50:16,977] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 968608

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:50:16,978] {logging_mixin.py:109} INFO - [2022-06-07 04:50:16,977] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:50:16,978] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:50:16,990] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:50:47,422] {processor.py:163} INFO - Started process (PID=969702) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:50:47,422] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:50:47,422] {logging_mixin.py:109} INFO - [2022-06-07 04:50:47,422] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:51:17,423] {logging_mixin.py:109} INFO - [2022-06-07 04:51:17,423] {timeout.py:36} ERROR - Process timed out, PID: 969702
[2022-06-07 04:51:17,424] {logging_mixin.py:109} INFO - [2022-06-07 04:51:17,423] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 969702
[2022-06-07 04:51:17,424] {logging_mixin.py:109} INFO - [2022-06-07 04:51:17,424] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:51:17,424] {logging_mixin.py:109} INFO - [2022-06-07 04:51:17,424] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 969702

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:51:17,425] {logging_mixin.py:109} INFO - [2022-06-07 04:51:17,424] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:51:17,425] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:51:17,436] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 04:51:47,891] {processor.py:163} INFO - Started process (PID=970795) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:51:47,891] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:51:47,892] {logging_mixin.py:109} INFO - [2022-06-07 04:51:47,892] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:52:17,896] {logging_mixin.py:109} INFO - [2022-06-07 04:52:17,895] {timeout.py:36} ERROR - Process timed out, PID: 970795
[2022-06-07 04:52:17,896] {logging_mixin.py:109} INFO - [2022-06-07 04:52:17,896] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 970795
[2022-06-07 04:52:17,897] {logging_mixin.py:109} INFO - [2022-06-07 04:52:17,896] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:52:17,897] {logging_mixin.py:109} INFO - [2022-06-07 04:52:17,897] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 970795

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:52:17,897] {logging_mixin.py:109} INFO - [2022-06-07 04:52:17,897] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:52:17,898] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:52:17,909] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 04:52:48,439] {processor.py:163} INFO - Started process (PID=971889) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:52:48,440] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:52:48,440] {logging_mixin.py:109} INFO - [2022-06-07 04:52:48,440] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:53:18,441] {logging_mixin.py:109} INFO - [2022-06-07 04:53:18,441] {timeout.py:36} ERROR - Process timed out, PID: 971889
[2022-06-07 04:53:18,442] {logging_mixin.py:109} INFO - [2022-06-07 04:53:18,441] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 971889
[2022-06-07 04:53:18,442] {logging_mixin.py:109} INFO - [2022-06-07 04:53:18,442] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:53:18,443] {logging_mixin.py:109} INFO - [2022-06-07 04:53:18,442] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 971889

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:53:18,443] {logging_mixin.py:109} INFO - [2022-06-07 04:53:18,443] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:53:18,443] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:53:18,455] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:53:48,910] {processor.py:163} INFO - Started process (PID=972984) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:53:48,910] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:53:48,910] {logging_mixin.py:109} INFO - [2022-06-07 04:53:48,910] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:54:18,912] {logging_mixin.py:109} INFO - [2022-06-07 04:54:18,912] {timeout.py:36} ERROR - Process timed out, PID: 972984
[2022-06-07 04:54:18,913] {logging_mixin.py:109} INFO - [2022-06-07 04:54:18,912] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 972984
[2022-06-07 04:54:18,913] {logging_mixin.py:109} INFO - [2022-06-07 04:54:18,913] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:54:18,913] {logging_mixin.py:109} INFO - [2022-06-07 04:54:18,913] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 972984

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:54:18,914] {logging_mixin.py:109} INFO - [2022-06-07 04:54:18,914] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:54:18,914] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:54:18,925] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 04:54:49,390] {processor.py:163} INFO - Started process (PID=974077) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:54:49,390] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:54:49,391] {logging_mixin.py:109} INFO - [2022-06-07 04:54:49,391] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:55:19,397] {logging_mixin.py:109} INFO - [2022-06-07 04:55:19,397] {timeout.py:36} ERROR - Process timed out, PID: 974077
[2022-06-07 04:55:19,398] {logging_mixin.py:109} INFO - [2022-06-07 04:55:19,397] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 974077
[2022-06-07 04:55:19,398] {logging_mixin.py:109} INFO - [2022-06-07 04:55:19,398] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:55:19,399] {logging_mixin.py:109} INFO - [2022-06-07 04:55:19,398] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 974077

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:55:19,399] {logging_mixin.py:109} INFO - [2022-06-07 04:55:19,399] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:55:19,399] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:55:19,410] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 04:55:49,709] {processor.py:163} INFO - Started process (PID=975172) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:55:49,709] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:55:49,709] {logging_mixin.py:109} INFO - [2022-06-07 04:55:49,709] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:56:19,710] {logging_mixin.py:109} INFO - [2022-06-07 04:56:19,710] {timeout.py:36} ERROR - Process timed out, PID: 975172
[2022-06-07 04:56:19,711] {logging_mixin.py:109} INFO - [2022-06-07 04:56:19,710] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 975172
[2022-06-07 04:56:19,711] {logging_mixin.py:109} INFO - [2022-06-07 04:56:19,711] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:56:19,711] {logging_mixin.py:109} INFO - [2022-06-07 04:56:19,711] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 975172

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:56:19,712] {logging_mixin.py:109} INFO - [2022-06-07 04:56:19,712] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:56:19,712] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:56:19,724] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 04:56:49,847] {processor.py:163} INFO - Started process (PID=976240) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:56:49,848] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:56:49,848] {logging_mixin.py:109} INFO - [2022-06-07 04:56:49,848] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:57:19,851] {logging_mixin.py:109} INFO - [2022-06-07 04:57:19,851] {timeout.py:36} ERROR - Process timed out, PID: 976240
[2022-06-07 04:57:19,852] {logging_mixin.py:109} INFO - [2022-06-07 04:57:19,851] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 976240
[2022-06-07 04:57:19,852] {logging_mixin.py:109} INFO - [2022-06-07 04:57:19,852] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:57:19,853] {logging_mixin.py:109} INFO - [2022-06-07 04:57:19,852] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 976240

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:57:19,853] {logging_mixin.py:109} INFO - [2022-06-07 04:57:19,853] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:57:19,853] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:57:19,864] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 04:57:50,250] {processor.py:163} INFO - Started process (PID=977335) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:57:50,251] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:57:50,251] {logging_mixin.py:109} INFO - [2022-06-07 04:57:50,251] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:58:20,253] {logging_mixin.py:109} INFO - [2022-06-07 04:58:20,252] {timeout.py:36} ERROR - Process timed out, PID: 977335
[2022-06-07 04:58:20,253] {logging_mixin.py:109} INFO - [2022-06-07 04:58:20,253] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 977335
[2022-06-07 04:58:20,254] {logging_mixin.py:109} INFO - [2022-06-07 04:58:20,254] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:58:20,254] {logging_mixin.py:109} INFO - [2022-06-07 04:58:20,254] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 977335

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:58:20,254] {logging_mixin.py:109} INFO - [2022-06-07 04:58:20,254] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:58:20,255] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:58:20,266] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 04:58:50,725] {processor.py:163} INFO - Started process (PID=978428) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:58:50,726] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:58:50,726] {logging_mixin.py:109} INFO - [2022-06-07 04:58:50,726] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:59:20,727] {logging_mixin.py:109} INFO - [2022-06-07 04:59:20,727] {timeout.py:36} ERROR - Process timed out, PID: 978428
[2022-06-07 04:59:20,728] {logging_mixin.py:109} INFO - [2022-06-07 04:59:20,728] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 978428
[2022-06-07 04:59:20,728] {logging_mixin.py:109} INFO - [2022-06-07 04:59:20,728] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 04:59:20,729] {logging_mixin.py:109} INFO - [2022-06-07 04:59:20,728] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 978428

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 04:59:20,729] {logging_mixin.py:109} INFO - [2022-06-07 04:59:20,729] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 04:59:20,729] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 04:59:20,741] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 04:59:51,232] {processor.py:163} INFO - Started process (PID=979520) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 04:59:51,233] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 04:59:51,233] {logging_mixin.py:109} INFO - [2022-06-07 04:59:51,233] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:00:21,234] {logging_mixin.py:109} INFO - [2022-06-07 05:00:21,234] {timeout.py:36} ERROR - Process timed out, PID: 979520
[2022-06-07 05:00:21,235] {logging_mixin.py:109} INFO - [2022-06-07 05:00:21,234] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 979520
[2022-06-07 05:00:21,235] {logging_mixin.py:109} INFO - [2022-06-07 05:00:21,235] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:00:21,235] {logging_mixin.py:109} INFO - [2022-06-07 05:00:21,235] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 979520

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:00:21,236] {logging_mixin.py:109} INFO - [2022-06-07 05:00:21,235] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:00:21,236] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:00:21,247] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:00:51,312] {processor.py:163} INFO - Started process (PID=980540) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:00:51,312] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:00:51,313] {logging_mixin.py:109} INFO - [2022-06-07 05:00:51,313] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:01:21,314] {logging_mixin.py:109} INFO - [2022-06-07 05:01:21,314] {timeout.py:36} ERROR - Process timed out, PID: 980540
[2022-06-07 05:01:21,315] {logging_mixin.py:109} INFO - [2022-06-07 05:01:21,314] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 980540
[2022-06-07 05:01:21,315] {logging_mixin.py:109} INFO - [2022-06-07 05:01:21,315] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:01:21,315] {logging_mixin.py:109} INFO - [2022-06-07 05:01:21,315] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 980540

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:01:21,316] {logging_mixin.py:109} INFO - [2022-06-07 05:01:21,315] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:01:21,316] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:01:21,328] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:01:51,566] {processor.py:163} INFO - Started process (PID=981630) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:01:51,566] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:01:51,566] {logging_mixin.py:109} INFO - [2022-06-07 05:01:51,566] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:02:21,572] {logging_mixin.py:109} INFO - [2022-06-07 05:02:21,571] {timeout.py:36} ERROR - Process timed out, PID: 981630
[2022-06-07 05:02:21,572] {logging_mixin.py:109} INFO - [2022-06-07 05:02:21,572] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 981630
[2022-06-07 05:02:21,572] {logging_mixin.py:109} INFO - [2022-06-07 05:02:21,572] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:02:21,573] {logging_mixin.py:109} INFO - [2022-06-07 05:02:21,572] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 981630

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:02:21,573] {logging_mixin.py:109} INFO - [2022-06-07 05:02:21,573] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:02:21,573] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:02:21,584] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 05:02:52,256] {processor.py:163} INFO - Started process (PID=982724) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:02:52,257] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:02:52,257] {logging_mixin.py:109} INFO - [2022-06-07 05:02:52,257] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:03:22,260] {logging_mixin.py:109} INFO - [2022-06-07 05:03:22,259] {timeout.py:36} ERROR - Process timed out, PID: 982724
[2022-06-07 05:03:22,260] {logging_mixin.py:109} INFO - [2022-06-07 05:03:22,260] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 982724
[2022-06-07 05:03:22,260] {logging_mixin.py:109} INFO - [2022-06-07 05:03:22,260] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:03:22,261] {logging_mixin.py:109} INFO - [2022-06-07 05:03:22,261] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 982724

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:03:22,261] {logging_mixin.py:109} INFO - [2022-06-07 05:03:22,261] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:03:22,262] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:03:22,274] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 05:03:52,845] {processor.py:163} INFO - Started process (PID=983818) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:03:52,845] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:03:52,846] {logging_mixin.py:109} INFO - [2022-06-07 05:03:52,845] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:04:22,847] {logging_mixin.py:109} INFO - [2022-06-07 05:04:22,847] {timeout.py:36} ERROR - Process timed out, PID: 983818
[2022-06-07 05:04:22,848] {logging_mixin.py:109} INFO - [2022-06-07 05:04:22,847] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 983818
[2022-06-07 05:04:22,848] {logging_mixin.py:109} INFO - [2022-06-07 05:04:22,848] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:04:22,848] {logging_mixin.py:109} INFO - [2022-06-07 05:04:22,848] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 983818

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:04:22,849] {logging_mixin.py:109} INFO - [2022-06-07 05:04:22,848] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:04:22,849] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:04:22,860] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:04:52,942] {processor.py:163} INFO - Started process (PID=984911) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:04:52,943] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:04:52,943] {logging_mixin.py:109} INFO - [2022-06-07 05:04:52,943] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:05:22,944] {logging_mixin.py:109} INFO - [2022-06-07 05:05:22,944] {timeout.py:36} ERROR - Process timed out, PID: 984911
[2022-06-07 05:05:22,945] {logging_mixin.py:109} INFO - [2022-06-07 05:05:22,944] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 984911
[2022-06-07 05:05:22,945] {logging_mixin.py:109} INFO - [2022-06-07 05:05:22,945] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:05:22,945] {logging_mixin.py:109} INFO - [2022-06-07 05:05:22,945] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 984911

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:05:22,946] {logging_mixin.py:109} INFO - [2022-06-07 05:05:22,946] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:05:22,946] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:05:22,957] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:05:53,028] {processor.py:163} INFO - Started process (PID=986004) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:05:53,028] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:05:53,028] {logging_mixin.py:109} INFO - [2022-06-07 05:05:53,028] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:06:23,035] {logging_mixin.py:109} INFO - [2022-06-07 05:06:23,035] {timeout.py:36} ERROR - Process timed out, PID: 986004
[2022-06-07 05:06:23,036] {logging_mixin.py:109} INFO - [2022-06-07 05:06:23,035] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 986004
[2022-06-07 05:06:23,036] {logging_mixin.py:109} INFO - [2022-06-07 05:06:23,036] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:06:23,036] {logging_mixin.py:109} INFO - [2022-06-07 05:06:23,036] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 986004

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:06:23,037] {logging_mixin.py:109} INFO - [2022-06-07 05:06:23,036] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:06:23,037] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:06:23,048] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 05:06:53,650] {processor.py:163} INFO - Started process (PID=987099) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:06:53,650] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:06:53,651] {logging_mixin.py:109} INFO - [2022-06-07 05:06:53,651] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:07:23,652] {logging_mixin.py:109} INFO - [2022-06-07 05:07:23,651] {timeout.py:36} ERROR - Process timed out, PID: 987099
[2022-06-07 05:07:23,652] {logging_mixin.py:109} INFO - [2022-06-07 05:07:23,652] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 987099
[2022-06-07 05:07:23,652] {logging_mixin.py:109} INFO - [2022-06-07 05:07:23,652] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:07:23,653] {logging_mixin.py:109} INFO - [2022-06-07 05:07:23,652] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 987099

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:07:23,653] {logging_mixin.py:109} INFO - [2022-06-07 05:07:23,653] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:07:23,653] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:07:23,664] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:07:53,986] {processor.py:163} INFO - Started process (PID=988193) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:07:53,987] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:07:53,987] {logging_mixin.py:109} INFO - [2022-06-07 05:07:53,987] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:08:23,989] {logging_mixin.py:109} INFO - [2022-06-07 05:08:23,989] {timeout.py:36} ERROR - Process timed out, PID: 988193
[2022-06-07 05:08:23,990] {logging_mixin.py:109} INFO - [2022-06-07 05:08:23,990] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 988193
[2022-06-07 05:08:23,990] {logging_mixin.py:109} INFO - [2022-06-07 05:08:23,990] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:08:23,991] {logging_mixin.py:109} INFO - [2022-06-07 05:08:23,990] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 988193

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:08:23,991] {logging_mixin.py:109} INFO - [2022-06-07 05:08:23,991] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:08:23,991] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:08:24,003] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 05:08:54,572] {processor.py:163} INFO - Started process (PID=989286) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:08:54,572] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:08:54,572] {logging_mixin.py:109} INFO - [2022-06-07 05:08:54,572] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:09:24,576] {logging_mixin.py:109} INFO - [2022-06-07 05:09:24,575] {timeout.py:36} ERROR - Process timed out, PID: 989286
[2022-06-07 05:09:24,576] {logging_mixin.py:109} INFO - [2022-06-07 05:09:24,576] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 989286
[2022-06-07 05:09:24,576] {logging_mixin.py:109} INFO - [2022-06-07 05:09:24,576] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:09:24,577] {logging_mixin.py:109} INFO - [2022-06-07 05:09:24,576] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 989286

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:09:24,577] {logging_mixin.py:109} INFO - [2022-06-07 05:09:24,577] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:09:24,577] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:09:24,589] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 05:09:55,110] {processor.py:163} INFO - Started process (PID=990379) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:09:55,111] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:09:55,111] {logging_mixin.py:109} INFO - [2022-06-07 05:09:55,111] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:10:25,119] {logging_mixin.py:109} INFO - [2022-06-07 05:10:25,118] {timeout.py:36} ERROR - Process timed out, PID: 990379
[2022-06-07 05:10:25,120] {logging_mixin.py:109} INFO - [2022-06-07 05:10:25,119] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 990379
[2022-06-07 05:10:25,120] {logging_mixin.py:109} INFO - [2022-06-07 05:10:25,120] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:10:25,120] {logging_mixin.py:109} INFO - [2022-06-07 05:10:25,120] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 990379

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:10:25,121] {logging_mixin.py:109} INFO - [2022-06-07 05:10:25,120] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:10:25,121] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:10:25,133] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 05:10:55,603] {processor.py:163} INFO - Started process (PID=991473) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:10:55,604] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:10:55,604] {logging_mixin.py:109} INFO - [2022-06-07 05:10:55,604] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:11:25,607] {logging_mixin.py:109} INFO - [2022-06-07 05:11:25,606] {timeout.py:36} ERROR - Process timed out, PID: 991473
[2022-06-07 05:11:25,607] {logging_mixin.py:109} INFO - [2022-06-07 05:11:25,607] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 991473
[2022-06-07 05:11:25,607] {logging_mixin.py:109} INFO - [2022-06-07 05:11:25,607] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:11:25,608] {logging_mixin.py:109} INFO - [2022-06-07 05:11:25,607] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 991473

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:11:25,608] {logging_mixin.py:109} INFO - [2022-06-07 05:11:25,608] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:11:25,608] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:11:25,620] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 05:11:56,184] {processor.py:163} INFO - Started process (PID=992569) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:11:56,184] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:11:56,184] {logging_mixin.py:109} INFO - [2022-06-07 05:11:56,184] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:12:26,193] {logging_mixin.py:109} INFO - [2022-06-07 05:12:26,193] {timeout.py:36} ERROR - Process timed out, PID: 992569
[2022-06-07 05:12:26,194] {logging_mixin.py:109} INFO - [2022-06-07 05:12:26,193] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 992569
[2022-06-07 05:12:26,194] {logging_mixin.py:109} INFO - [2022-06-07 05:12:26,194] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:12:26,194] {logging_mixin.py:109} INFO - [2022-06-07 05:12:26,194] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 992569

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:12:26,195] {logging_mixin.py:109} INFO - [2022-06-07 05:12:26,195] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:12:26,195] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:12:26,206] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 05:12:56,247] {processor.py:163} INFO - Started process (PID=993662) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:12:56,247] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:12:56,248] {logging_mixin.py:109} INFO - [2022-06-07 05:12:56,247] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:13:26,252] {logging_mixin.py:109} INFO - [2022-06-07 05:13:26,251] {timeout.py:36} ERROR - Process timed out, PID: 993662
[2022-06-07 05:13:26,252] {logging_mixin.py:109} INFO - [2022-06-07 05:13:26,252] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 993662
[2022-06-07 05:13:26,252] {logging_mixin.py:109} INFO - [2022-06-07 05:13:26,252] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:13:26,253] {logging_mixin.py:109} INFO - [2022-06-07 05:13:26,252] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 993662

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:13:26,253] {logging_mixin.py:109} INFO - [2022-06-07 05:13:26,253] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:13:26,253] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:13:26,266] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 05:13:56,421] {processor.py:163} INFO - Started process (PID=994755) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:13:56,422] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:13:56,422] {logging_mixin.py:109} INFO - [2022-06-07 05:13:56,422] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:14:26,424] {logging_mixin.py:109} INFO - [2022-06-07 05:14:26,423] {timeout.py:36} ERROR - Process timed out, PID: 994755
[2022-06-07 05:14:26,424] {logging_mixin.py:109} INFO - [2022-06-07 05:14:26,424] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 994755
[2022-06-07 05:14:26,424] {logging_mixin.py:109} INFO - [2022-06-07 05:14:26,424] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:14:26,425] {logging_mixin.py:109} INFO - [2022-06-07 05:14:26,424] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 994755

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:14:26,425] {logging_mixin.py:109} INFO - [2022-06-07 05:14:26,425] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:14:26,425] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:14:26,437] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:14:56,675] {processor.py:163} INFO - Started process (PID=995813) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:14:56,676] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:14:56,676] {logging_mixin.py:109} INFO - [2022-06-07 05:14:56,676] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:15:26,677] {logging_mixin.py:109} INFO - [2022-06-07 05:15:26,677] {timeout.py:36} ERROR - Process timed out, PID: 995813
[2022-06-07 05:15:26,678] {logging_mixin.py:109} INFO - [2022-06-07 05:15:26,677] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 995813
[2022-06-07 05:15:26,678] {logging_mixin.py:109} INFO - [2022-06-07 05:15:26,678] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:15:26,679] {logging_mixin.py:109} INFO - [2022-06-07 05:15:26,678] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 995813

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:15:26,679] {logging_mixin.py:109} INFO - [2022-06-07 05:15:26,679] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:15:26,679] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:15:26,691] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:15:57,633] {processor.py:163} INFO - Started process (PID=996906) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:15:57,634] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:15:57,634] {logging_mixin.py:109} INFO - [2022-06-07 05:15:57,634] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:16:27,635] {logging_mixin.py:109} INFO - [2022-06-07 05:16:27,635] {timeout.py:36} ERROR - Process timed out, PID: 996906
[2022-06-07 05:16:27,636] {logging_mixin.py:109} INFO - [2022-06-07 05:16:27,635] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 996906
[2022-06-07 05:16:27,636] {logging_mixin.py:109} INFO - [2022-06-07 05:16:27,636] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:16:27,637] {logging_mixin.py:109} INFO - [2022-06-07 05:16:27,636] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 996906

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:16:27,637] {logging_mixin.py:109} INFO - [2022-06-07 05:16:27,637] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:16:27,637] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:16:27,649] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 05:16:57,909] {processor.py:163} INFO - Started process (PID=998000) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:16:57,910] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:16:57,910] {logging_mixin.py:109} INFO - [2022-06-07 05:16:57,910] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:17:27,915] {logging_mixin.py:109} INFO - [2022-06-07 05:17:27,915] {timeout.py:36} ERROR - Process timed out, PID: 998000
[2022-06-07 05:17:27,916] {logging_mixin.py:109} INFO - [2022-06-07 05:17:27,915] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 998000
[2022-06-07 05:17:27,916] {logging_mixin.py:109} INFO - [2022-06-07 05:17:27,916] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:17:27,917] {logging_mixin.py:109} INFO - [2022-06-07 05:17:27,916] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 998000

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:17:27,917] {logging_mixin.py:109} INFO - [2022-06-07 05:17:27,917] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:17:27,917] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:17:27,928] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 05:17:58,065] {processor.py:163} INFO - Started process (PID=999094) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:17:58,066] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:17:58,066] {logging_mixin.py:109} INFO - [2022-06-07 05:17:58,066] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:18:28,076] {logging_mixin.py:109} INFO - [2022-06-07 05:18:28,076] {timeout.py:36} ERROR - Process timed out, PID: 999094
[2022-06-07 05:18:28,077] {logging_mixin.py:109} INFO - [2022-06-07 05:18:28,076] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 999094
[2022-06-07 05:18:28,077] {logging_mixin.py:109} INFO - [2022-06-07 05:18:28,077] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:18:28,077] {logging_mixin.py:109} INFO - [2022-06-07 05:18:28,077] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 999094

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:18:28,078] {logging_mixin.py:109} INFO - [2022-06-07 05:18:28,078] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:18:28,078] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:18:28,089] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 05:18:58,514] {processor.py:163} INFO - Started process (PID=1000188) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:18:58,515] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:18:58,515] {logging_mixin.py:109} INFO - [2022-06-07 05:18:58,515] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:19:28,527] {logging_mixin.py:109} INFO - [2022-06-07 05:19:28,527] {timeout.py:36} ERROR - Process timed out, PID: 1000188
[2022-06-07 05:19:28,527] {logging_mixin.py:109} INFO - [2022-06-07 05:19:28,527] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1000188
[2022-06-07 05:19:28,528] {logging_mixin.py:109} INFO - [2022-06-07 05:19:28,528] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:19:28,528] {logging_mixin.py:109} INFO - [2022-06-07 05:19:28,528] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1000188

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:19:28,528] {logging_mixin.py:109} INFO - [2022-06-07 05:19:28,528] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:19:28,529] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:19:28,542] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.029 seconds
[2022-06-07 05:19:58,783] {processor.py:163} INFO - Started process (PID=1001282) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:19:58,784] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:19:58,784] {logging_mixin.py:109} INFO - [2022-06-07 05:19:58,784] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:20:28,786] {logging_mixin.py:109} INFO - [2022-06-07 05:20:28,786] {timeout.py:36} ERROR - Process timed out, PID: 1001282
[2022-06-07 05:20:28,787] {logging_mixin.py:109} INFO - [2022-06-07 05:20:28,786] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1001282
[2022-06-07 05:20:28,787] {logging_mixin.py:109} INFO - [2022-06-07 05:20:28,787] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:20:28,787] {logging_mixin.py:109} INFO - [2022-06-07 05:20:28,787] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1001282

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:20:28,788] {logging_mixin.py:109} INFO - [2022-06-07 05:20:28,788] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:20:28,788] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:20:28,800] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 05:20:59,565] {processor.py:163} INFO - Started process (PID=1002378) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:20:59,566] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:20:59,566] {logging_mixin.py:109} INFO - [2022-06-07 05:20:59,566] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:21:29,573] {logging_mixin.py:109} INFO - [2022-06-07 05:21:29,572] {timeout.py:36} ERROR - Process timed out, PID: 1002378
[2022-06-07 05:21:29,573] {logging_mixin.py:109} INFO - [2022-06-07 05:21:29,573] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1002378
[2022-06-07 05:21:29,574] {logging_mixin.py:109} INFO - [2022-06-07 05:21:29,573] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:21:29,574] {logging_mixin.py:109} INFO - [2022-06-07 05:21:29,574] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1002378

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:21:29,574] {logging_mixin.py:109} INFO - [2022-06-07 05:21:29,574] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:21:29,575] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:21:29,586] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 05:22:00,216] {processor.py:163} INFO - Started process (PID=1003467) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:22:00,217] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:22:00,217] {logging_mixin.py:109} INFO - [2022-06-07 05:22:00,217] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:22:30,223] {logging_mixin.py:109} INFO - [2022-06-07 05:22:30,223] {timeout.py:36} ERROR - Process timed out, PID: 1003467
[2022-06-07 05:22:30,224] {logging_mixin.py:109} INFO - [2022-06-07 05:22:30,223] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1003467
[2022-06-07 05:22:30,224] {logging_mixin.py:109} INFO - [2022-06-07 05:22:30,224] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:22:30,224] {logging_mixin.py:109} INFO - [2022-06-07 05:22:30,224] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1003467

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:22:30,225] {logging_mixin.py:109} INFO - [2022-06-07 05:22:30,224] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:22:30,225] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:22:30,236] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 05:23:01,000] {processor.py:163} INFO - Started process (PID=1004562) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:23:01,001] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:23:01,001] {logging_mixin.py:109} INFO - [2022-06-07 05:23:01,001] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:23:31,006] {logging_mixin.py:109} INFO - [2022-06-07 05:23:31,006] {timeout.py:36} ERROR - Process timed out, PID: 1004562
[2022-06-07 05:23:31,007] {logging_mixin.py:109} INFO - [2022-06-07 05:23:31,006] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1004562
[2022-06-07 05:23:31,007] {logging_mixin.py:109} INFO - [2022-06-07 05:23:31,007] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:23:31,007] {logging_mixin.py:109} INFO - [2022-06-07 05:23:31,007] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1004562

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:23:31,008] {logging_mixin.py:109} INFO - [2022-06-07 05:23:31,007] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:23:31,008] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:23:31,019] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 05:24:01,607] {processor.py:163} INFO - Started process (PID=1005656) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:24:01,607] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:24:01,607] {logging_mixin.py:109} INFO - [2022-06-07 05:24:01,607] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:24:31,617] {logging_mixin.py:109} INFO - [2022-06-07 05:24:31,617] {timeout.py:36} ERROR - Process timed out, PID: 1005656
[2022-06-07 05:24:31,618] {logging_mixin.py:109} INFO - [2022-06-07 05:24:31,618] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1005656
[2022-06-07 05:24:31,618] {logging_mixin.py:109} INFO - [2022-06-07 05:24:31,618] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:24:31,619] {logging_mixin.py:109} INFO - [2022-06-07 05:24:31,618] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1005656

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:24:31,619] {logging_mixin.py:109} INFO - [2022-06-07 05:24:31,619] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:24:31,619] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:24:31,631] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 05:25:01,927] {processor.py:163} INFO - Started process (PID=1006751) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:25:01,927] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:25:01,928] {logging_mixin.py:109} INFO - [2022-06-07 05:25:01,928] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:25:31,929] {logging_mixin.py:109} INFO - [2022-06-07 05:25:31,928] {timeout.py:36} ERROR - Process timed out, PID: 1006751
[2022-06-07 05:25:31,929] {logging_mixin.py:109} INFO - [2022-06-07 05:25:31,929] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1006751
[2022-06-07 05:25:31,929] {logging_mixin.py:109} INFO - [2022-06-07 05:25:31,929] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:25:31,930] {logging_mixin.py:109} INFO - [2022-06-07 05:25:31,929] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1006751

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:25:31,930] {logging_mixin.py:109} INFO - [2022-06-07 05:25:31,930] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:25:31,930] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:25:31,942] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:26:02,772] {processor.py:163} INFO - Started process (PID=1007846) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:26:02,773] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:26:02,773] {logging_mixin.py:109} INFO - [2022-06-07 05:26:02,773] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:26:32,774] {logging_mixin.py:109} INFO - [2022-06-07 05:26:32,774] {timeout.py:36} ERROR - Process timed out, PID: 1007846
[2022-06-07 05:26:32,775] {logging_mixin.py:109} INFO - [2022-06-07 05:26:32,774] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1007846
[2022-06-07 05:26:32,775] {logging_mixin.py:109} INFO - [2022-06-07 05:26:32,775] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:26:32,775] {logging_mixin.py:109} INFO - [2022-06-07 05:26:32,775] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1007846

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:26:32,776] {logging_mixin.py:109} INFO - [2022-06-07 05:26:32,776] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:26:32,776] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:26:32,788] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:27:02,988] {processor.py:163} INFO - Started process (PID=1008939) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:27:02,988] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:27:02,988] {logging_mixin.py:109} INFO - [2022-06-07 05:27:02,988] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:27:32,990] {logging_mixin.py:109} INFO - [2022-06-07 05:27:32,990] {timeout.py:36} ERROR - Process timed out, PID: 1008939
[2022-06-07 05:27:32,991] {logging_mixin.py:109} INFO - [2022-06-07 05:27:32,990] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1008939
[2022-06-07 05:27:32,991] {logging_mixin.py:109} INFO - [2022-06-07 05:27:32,991] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:27:32,991] {logging_mixin.py:109} INFO - [2022-06-07 05:27:32,991] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1008939

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:27:32,992] {logging_mixin.py:109} INFO - [2022-06-07 05:27:32,991] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:27:32,992] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:27:33,004] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:28:03,187] {processor.py:163} INFO - Started process (PID=1010032) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:28:03,187] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:28:03,188] {logging_mixin.py:109} INFO - [2022-06-07 05:28:03,188] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:28:33,189] {logging_mixin.py:109} INFO - [2022-06-07 05:28:33,188] {timeout.py:36} ERROR - Process timed out, PID: 1010032
[2022-06-07 05:28:33,189] {logging_mixin.py:109} INFO - [2022-06-07 05:28:33,189] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1010032
[2022-06-07 05:28:33,189] {logging_mixin.py:109} INFO - [2022-06-07 05:28:33,189] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:28:33,190] {logging_mixin.py:109} INFO - [2022-06-07 05:28:33,189] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1010032

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:28:33,190] {logging_mixin.py:109} INFO - [2022-06-07 05:28:33,190] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:28:33,190] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:28:33,202] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:29:03,549] {processor.py:163} INFO - Started process (PID=1011107) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:29:03,550] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:29:03,550] {logging_mixin.py:109} INFO - [2022-06-07 05:29:03,550] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:29:33,551] {logging_mixin.py:109} INFO - [2022-06-07 05:29:33,551] {timeout.py:36} ERROR - Process timed out, PID: 1011107
[2022-06-07 05:29:33,552] {logging_mixin.py:109} INFO - [2022-06-07 05:29:33,551] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1011107
[2022-06-07 05:29:33,552] {logging_mixin.py:109} INFO - [2022-06-07 05:29:33,552] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:29:33,552] {logging_mixin.py:109} INFO - [2022-06-07 05:29:33,552] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1011107

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:29:33,553] {logging_mixin.py:109} INFO - [2022-06-07 05:29:33,553] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:29:33,553] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:29:33,564] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:30:04,204] {processor.py:163} INFO - Started process (PID=1012166) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:30:04,204] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:30:04,205] {logging_mixin.py:109} INFO - [2022-06-07 05:30:04,205] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:30:34,207] {logging_mixin.py:109} INFO - [2022-06-07 05:30:34,206] {timeout.py:36} ERROR - Process timed out, PID: 1012166
[2022-06-07 05:30:34,207] {logging_mixin.py:109} INFO - [2022-06-07 05:30:34,207] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1012166
[2022-06-07 05:30:34,207] {logging_mixin.py:109} INFO - [2022-06-07 05:30:34,207] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:30:34,208] {logging_mixin.py:109} INFO - [2022-06-07 05:30:34,207] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1012166

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:30:34,208] {logging_mixin.py:109} INFO - [2022-06-07 05:30:34,208] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:30:34,208] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:30:34,221] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 05:31:04,728] {processor.py:163} INFO - Started process (PID=1013260) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:31:04,729] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:31:04,729] {logging_mixin.py:109} INFO - [2022-06-07 05:31:04,729] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:31:34,755] {logging_mixin.py:109} INFO - [2022-06-07 05:31:34,755] {timeout.py:36} ERROR - Process timed out, PID: 1013260
[2022-06-07 05:31:34,756] {logging_mixin.py:109} INFO - [2022-06-07 05:31:34,755] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1013260
[2022-06-07 05:31:34,756] {logging_mixin.py:109} INFO - [2022-06-07 05:31:34,756] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:31:34,757] {logging_mixin.py:109} INFO - [2022-06-07 05:31:34,756] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1013260

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:31:34,757] {logging_mixin.py:109} INFO - [2022-06-07 05:31:34,757] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:31:34,757] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:31:34,768] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.041 seconds
[2022-06-07 05:32:05,030] {processor.py:163} INFO - Started process (PID=1014329) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:32:05,030] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:32:05,030] {logging_mixin.py:109} INFO - [2022-06-07 05:32:05,030] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:32:35,032] {logging_mixin.py:109} INFO - [2022-06-07 05:32:35,032] {timeout.py:36} ERROR - Process timed out, PID: 1014329
[2022-06-07 05:32:35,033] {logging_mixin.py:109} INFO - [2022-06-07 05:32:35,032] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1014329
[2022-06-07 05:32:35,033] {logging_mixin.py:109} INFO - [2022-06-07 05:32:35,033] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:32:35,033] {logging_mixin.py:109} INFO - [2022-06-07 05:32:35,033] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1014329

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:32:35,033] {logging_mixin.py:109} INFO - [2022-06-07 05:32:35,033] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:32:35,034] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:32:35,045] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:33:05,095] {processor.py:163} INFO - Started process (PID=1015424) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:33:05,096] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:33:05,096] {logging_mixin.py:109} INFO - [2022-06-07 05:33:05,096] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:33:35,097] {logging_mixin.py:109} INFO - [2022-06-07 05:33:35,097] {timeout.py:36} ERROR - Process timed out, PID: 1015424
[2022-06-07 05:33:35,098] {logging_mixin.py:109} INFO - [2022-06-07 05:33:35,097] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1015424
[2022-06-07 05:33:35,098] {logging_mixin.py:109} INFO - [2022-06-07 05:33:35,098] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:33:35,099] {logging_mixin.py:109} INFO - [2022-06-07 05:33:35,098] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1015424

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:33:35,099] {logging_mixin.py:109} INFO - [2022-06-07 05:33:35,099] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:33:35,099] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:33:35,110] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:34:05,629] {processor.py:163} INFO - Started process (PID=1016517) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:34:05,630] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:34:05,630] {logging_mixin.py:109} INFO - [2022-06-07 05:34:05,630] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:34:35,637] {logging_mixin.py:109} INFO - [2022-06-07 05:34:35,637] {timeout.py:36} ERROR - Process timed out, PID: 1016517
[2022-06-07 05:34:35,638] {logging_mixin.py:109} INFO - [2022-06-07 05:34:35,638] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1016517
[2022-06-07 05:34:35,638] {logging_mixin.py:109} INFO - [2022-06-07 05:34:35,638] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:34:35,639] {logging_mixin.py:109} INFO - [2022-06-07 05:34:35,638] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1016517

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:34:35,639] {logging_mixin.py:109} INFO - [2022-06-07 05:34:35,639] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:34:35,639] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:34:35,651] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 05:35:06,564] {processor.py:163} INFO - Started process (PID=1017611) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:35:06,564] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:35:06,565] {logging_mixin.py:109} INFO - [2022-06-07 05:35:06,565] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:35:36,566] {logging_mixin.py:109} INFO - [2022-06-07 05:35:36,566] {timeout.py:36} ERROR - Process timed out, PID: 1017611
[2022-06-07 05:35:36,567] {logging_mixin.py:109} INFO - [2022-06-07 05:35:36,566] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1017611
[2022-06-07 05:35:36,567] {logging_mixin.py:109} INFO - [2022-06-07 05:35:36,567] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:35:36,567] {logging_mixin.py:109} INFO - [2022-06-07 05:35:36,567] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1017611

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:35:36,568] {logging_mixin.py:109} INFO - [2022-06-07 05:35:36,567] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:35:36,568] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:35:36,579] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:36:07,528] {processor.py:163} INFO - Started process (PID=1018705) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:36:07,529] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:36:07,529] {logging_mixin.py:109} INFO - [2022-06-07 05:36:07,529] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:36:37,533] {logging_mixin.py:109} INFO - [2022-06-07 05:36:37,533] {timeout.py:36} ERROR - Process timed out, PID: 1018705
[2022-06-07 05:36:37,534] {logging_mixin.py:109} INFO - [2022-06-07 05:36:37,533] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1018705
[2022-06-07 05:36:37,534] {logging_mixin.py:109} INFO - [2022-06-07 05:36:37,534] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:36:37,535] {logging_mixin.py:109} INFO - [2022-06-07 05:36:37,534] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1018705

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:36:37,535] {logging_mixin.py:109} INFO - [2022-06-07 05:36:37,535] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:36:37,535] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:36:37,547] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 05:37:08,193] {processor.py:163} INFO - Started process (PID=1019798) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:37:08,193] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:37:08,194] {logging_mixin.py:109} INFO - [2022-06-07 05:37:08,194] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:37:38,196] {logging_mixin.py:109} INFO - [2022-06-07 05:37:38,196] {timeout.py:36} ERROR - Process timed out, PID: 1019798
[2022-06-07 05:37:38,197] {logging_mixin.py:109} INFO - [2022-06-07 05:37:38,197] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1019798
[2022-06-07 05:37:38,197] {logging_mixin.py:109} INFO - [2022-06-07 05:37:38,197] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:37:38,198] {logging_mixin.py:109} INFO - [2022-06-07 05:37:38,197] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1019798

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:37:38,198] {logging_mixin.py:109} INFO - [2022-06-07 05:37:38,198] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:37:38,199] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:37:38,211] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 05:38:09,220] {processor.py:163} INFO - Started process (PID=1020893) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:38:09,220] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:38:09,221] {logging_mixin.py:109} INFO - [2022-06-07 05:38:09,221] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:38:39,222] {logging_mixin.py:109} INFO - [2022-06-07 05:38:39,222] {timeout.py:36} ERROR - Process timed out, PID: 1020893
[2022-06-07 05:38:39,223] {logging_mixin.py:109} INFO - [2022-06-07 05:38:39,223] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1020893
[2022-06-07 05:38:39,223] {logging_mixin.py:109} INFO - [2022-06-07 05:38:39,223] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:38:39,224] {logging_mixin.py:109} INFO - [2022-06-07 05:38:39,223] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1020893

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:38:39,224] {logging_mixin.py:109} INFO - [2022-06-07 05:38:39,224] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:38:39,224] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:38:39,236] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:39:10,065] {processor.py:163} INFO - Started process (PID=1021987) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:39:10,065] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:39:10,066] {logging_mixin.py:109} INFO - [2022-06-07 05:39:10,066] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:39:40,069] {logging_mixin.py:109} INFO - [2022-06-07 05:39:40,069] {timeout.py:36} ERROR - Process timed out, PID: 1021987
[2022-06-07 05:39:40,070] {logging_mixin.py:109} INFO - [2022-06-07 05:39:40,070] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1021987
[2022-06-07 05:39:40,070] {logging_mixin.py:109} INFO - [2022-06-07 05:39:40,070] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:39:40,071] {logging_mixin.py:109} INFO - [2022-06-07 05:39:40,070] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1021987

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:39:40,071] {logging_mixin.py:109} INFO - [2022-06-07 05:39:40,071] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:39:40,071] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:39:40,083] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 05:40:10,111] {processor.py:163} INFO - Started process (PID=1023081) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:40:10,111] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:40:10,111] {logging_mixin.py:109} INFO - [2022-06-07 05:40:10,111] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:40:40,155] {logging_mixin.py:109} INFO - [2022-06-07 05:40:40,155] {timeout.py:36} ERROR - Process timed out, PID: 1023081
[2022-06-07 05:40:40,156] {logging_mixin.py:109} INFO - [2022-06-07 05:40:40,155] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1023081
[2022-06-07 05:40:40,156] {logging_mixin.py:109} INFO - [2022-06-07 05:40:40,156] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:40:40,157] {logging_mixin.py:109} INFO - [2022-06-07 05:40:40,156] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1023081

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:40:40,157] {logging_mixin.py:109} INFO - [2022-06-07 05:40:40,157] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:40:40,157] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:40:40,168] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.059 seconds
[2022-06-07 05:41:10,677] {processor.py:163} INFO - Started process (PID=1024174) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:41:10,678] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:41:10,678] {logging_mixin.py:109} INFO - [2022-06-07 05:41:10,678] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:41:40,682] {logging_mixin.py:109} INFO - [2022-06-07 05:41:40,681] {timeout.py:36} ERROR - Process timed out, PID: 1024174
[2022-06-07 05:41:40,682] {logging_mixin.py:109} INFO - [2022-06-07 05:41:40,682] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1024174
[2022-06-07 05:41:40,682] {logging_mixin.py:109} INFO - [2022-06-07 05:41:40,682] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:41:40,683] {logging_mixin.py:109} INFO - [2022-06-07 05:41:40,682] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1024174

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:41:40,683] {logging_mixin.py:109} INFO - [2022-06-07 05:41:40,683] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:41:40,683] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:41:40,695] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 05:42:11,595] {processor.py:163} INFO - Started process (PID=1025267) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:42:11,596] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:42:11,596] {logging_mixin.py:109} INFO - [2022-06-07 05:42:11,596] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:42:41,597] {logging_mixin.py:109} INFO - [2022-06-07 05:42:41,596] {timeout.py:36} ERROR - Process timed out, PID: 1025267
[2022-06-07 05:42:41,597] {logging_mixin.py:109} INFO - [2022-06-07 05:42:41,597] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1025267
[2022-06-07 05:42:41,597] {logging_mixin.py:109} INFO - [2022-06-07 05:42:41,597] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:42:41,598] {logging_mixin.py:109} INFO - [2022-06-07 05:42:41,597] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1025267

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:42:41,598] {logging_mixin.py:109} INFO - [2022-06-07 05:42:41,598] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:42:41,598] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:42:41,609] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:43:12,474] {processor.py:163} INFO - Started process (PID=1026360) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:43:12,474] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:43:12,475] {logging_mixin.py:109} INFO - [2022-06-07 05:43:12,475] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:43:42,478] {logging_mixin.py:109} INFO - [2022-06-07 05:43:42,477] {timeout.py:36} ERROR - Process timed out, PID: 1026360
[2022-06-07 05:43:42,478] {logging_mixin.py:109} INFO - [2022-06-07 05:43:42,478] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1026360
[2022-06-07 05:43:42,478] {logging_mixin.py:109} INFO - [2022-06-07 05:43:42,478] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:43:42,479] {logging_mixin.py:109} INFO - [2022-06-07 05:43:42,478] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1026360

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:43:42,479] {logging_mixin.py:109} INFO - [2022-06-07 05:43:42,479] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:43:42,479] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:43:42,490] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 05:44:13,447] {processor.py:163} INFO - Started process (PID=1027454) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:44:13,448] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:44:13,448] {logging_mixin.py:109} INFO - [2022-06-07 05:44:13,448] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:44:43,456] {logging_mixin.py:109} INFO - [2022-06-07 05:44:43,456] {timeout.py:36} ERROR - Process timed out, PID: 1027454
[2022-06-07 05:44:43,457] {logging_mixin.py:109} INFO - [2022-06-07 05:44:43,456] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1027454
[2022-06-07 05:44:43,457] {logging_mixin.py:109} INFO - [2022-06-07 05:44:43,457] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:44:43,458] {logging_mixin.py:109} INFO - [2022-06-07 05:44:43,457] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1027454

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:44:43,458] {logging_mixin.py:109} INFO - [2022-06-07 05:44:43,458] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:44:43,458] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:44:43,469] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 05:45:14,405] {processor.py:163} INFO - Started process (PID=1028547) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:45:14,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:45:14,405] {logging_mixin.py:109} INFO - [2022-06-07 05:45:14,405] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:45:44,417] {logging_mixin.py:109} INFO - [2022-06-07 05:45:44,417] {timeout.py:36} ERROR - Process timed out, PID: 1028547
[2022-06-07 05:45:44,418] {logging_mixin.py:109} INFO - [2022-06-07 05:45:44,417] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1028547
[2022-06-07 05:45:44,418] {logging_mixin.py:109} INFO - [2022-06-07 05:45:44,418] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:45:44,418] {logging_mixin.py:109} INFO - [2022-06-07 05:45:44,418] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1028547

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:45:44,419] {logging_mixin.py:109} INFO - [2022-06-07 05:45:44,418] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:45:44,419] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:45:44,430] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.027 seconds
[2022-06-07 05:46:15,236] {processor.py:163} INFO - Started process (PID=1029641) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:46:15,237] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:46:15,237] {logging_mixin.py:109} INFO - [2022-06-07 05:46:15,237] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:46:45,242] {logging_mixin.py:109} INFO - [2022-06-07 05:46:45,241] {timeout.py:36} ERROR - Process timed out, PID: 1029641
[2022-06-07 05:46:45,242] {logging_mixin.py:109} INFO - [2022-06-07 05:46:45,242] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1029641
[2022-06-07 05:46:45,242] {logging_mixin.py:109} INFO - [2022-06-07 05:46:45,242] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:46:45,243] {logging_mixin.py:109} INFO - [2022-06-07 05:46:45,243] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1029641

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:46:45,243] {logging_mixin.py:109} INFO - [2022-06-07 05:46:45,243] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:46:45,243] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:46:45,255] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 05:47:16,152] {processor.py:163} INFO - Started process (PID=1030735) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:47:16,153] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:47:16,153] {logging_mixin.py:109} INFO - [2022-06-07 05:47:16,153] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:47:46,154] {logging_mixin.py:109} INFO - [2022-06-07 05:47:46,154] {timeout.py:36} ERROR - Process timed out, PID: 1030735
[2022-06-07 05:47:46,155] {logging_mixin.py:109} INFO - [2022-06-07 05:47:46,154] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1030735
[2022-06-07 05:47:46,155] {logging_mixin.py:109} INFO - [2022-06-07 05:47:46,155] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:47:46,155] {logging_mixin.py:109} INFO - [2022-06-07 05:47:46,155] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1030735

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:47:46,156] {logging_mixin.py:109} INFO - [2022-06-07 05:47:46,155] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:47:46,156] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:47:46,167] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:48:16,747] {processor.py:163} INFO - Started process (PID=1031829) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:48:16,747] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:48:16,748] {logging_mixin.py:109} INFO - [2022-06-07 05:48:16,747] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:48:46,752] {logging_mixin.py:109} INFO - [2022-06-07 05:48:46,751] {timeout.py:36} ERROR - Process timed out, PID: 1031829
[2022-06-07 05:48:46,752] {logging_mixin.py:109} INFO - [2022-06-07 05:48:46,752] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1031829
[2022-06-07 05:48:46,752] {logging_mixin.py:109} INFO - [2022-06-07 05:48:46,752] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:48:46,753] {logging_mixin.py:109} INFO - [2022-06-07 05:48:46,752] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1031829

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:48:46,753] {logging_mixin.py:109} INFO - [2022-06-07 05:48:46,753] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:48:46,753] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:48:46,765] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 05:49:17,521] {processor.py:163} INFO - Started process (PID=1032923) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:49:17,522] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:49:17,522] {logging_mixin.py:109} INFO - [2022-06-07 05:49:17,522] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:49:47,523] {logging_mixin.py:109} INFO - [2022-06-07 05:49:47,522] {timeout.py:36} ERROR - Process timed out, PID: 1032923
[2022-06-07 05:49:47,523] {logging_mixin.py:109} INFO - [2022-06-07 05:49:47,523] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1032923
[2022-06-07 05:49:47,524] {logging_mixin.py:109} INFO - [2022-06-07 05:49:47,523] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:49:47,524] {logging_mixin.py:109} INFO - [2022-06-07 05:49:47,524] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1032923

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:49:47,524] {logging_mixin.py:109} INFO - [2022-06-07 05:49:47,524] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:49:47,525] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:49:47,537] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 05:50:17,692] {processor.py:163} INFO - Started process (PID=1033986) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:50:17,693] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:50:17,693] {logging_mixin.py:109} INFO - [2022-06-07 05:50:17,693] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:50:47,694] {logging_mixin.py:109} INFO - [2022-06-07 05:50:47,694] {timeout.py:36} ERROR - Process timed out, PID: 1033986
[2022-06-07 05:50:47,695] {logging_mixin.py:109} INFO - [2022-06-07 05:50:47,695] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1033986
[2022-06-07 05:50:47,695] {logging_mixin.py:109} INFO - [2022-06-07 05:50:47,695] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:50:47,696] {logging_mixin.py:109} INFO - [2022-06-07 05:50:47,695] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1033986

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:50:47,696] {logging_mixin.py:109} INFO - [2022-06-07 05:50:47,696] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:50:47,696] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:50:47,707] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:51:18,010] {processor.py:163} INFO - Started process (PID=1035029) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:51:18,010] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:51:18,010] {logging_mixin.py:109} INFO - [2022-06-07 05:51:18,010] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:51:48,012] {logging_mixin.py:109} INFO - [2022-06-07 05:51:48,012] {timeout.py:36} ERROR - Process timed out, PID: 1035029
[2022-06-07 05:51:48,013] {logging_mixin.py:109} INFO - [2022-06-07 05:51:48,012] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1035029
[2022-06-07 05:51:48,013] {logging_mixin.py:109} INFO - [2022-06-07 05:51:48,013] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:51:48,014] {logging_mixin.py:109} INFO - [2022-06-07 05:51:48,013] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1035029

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:51:48,014] {logging_mixin.py:109} INFO - [2022-06-07 05:51:48,014] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:51:48,014] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:51:48,027] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 05:52:18,825] {processor.py:163} INFO - Started process (PID=1036126) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:52:18,826] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:52:18,826] {logging_mixin.py:109} INFO - [2022-06-07 05:52:18,826] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:52:48,833] {logging_mixin.py:109} INFO - [2022-06-07 05:52:48,833] {timeout.py:36} ERROR - Process timed out, PID: 1036126
[2022-06-07 05:52:48,834] {logging_mixin.py:109} INFO - [2022-06-07 05:52:48,833] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1036126
[2022-06-07 05:52:48,834] {logging_mixin.py:109} INFO - [2022-06-07 05:52:48,834] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:52:48,834] {logging_mixin.py:109} INFO - [2022-06-07 05:52:48,834] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1036126

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:52:48,835] {logging_mixin.py:109} INFO - [2022-06-07 05:52:48,834] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:52:48,835] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:52:48,846] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 05:53:19,805] {processor.py:163} INFO - Started process (PID=1037220) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:53:19,805] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:53:19,806] {logging_mixin.py:109} INFO - [2022-06-07 05:53:19,806] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:53:49,818] {logging_mixin.py:109} INFO - [2022-06-07 05:53:49,818] {timeout.py:36} ERROR - Process timed out, PID: 1037220
[2022-06-07 05:53:49,819] {logging_mixin.py:109} INFO - [2022-06-07 05:53:49,818] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1037220
[2022-06-07 05:53:49,819] {logging_mixin.py:109} INFO - [2022-06-07 05:53:49,819] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:53:49,819] {logging_mixin.py:109} INFO - [2022-06-07 05:53:49,819] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1037220

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:53:49,820] {logging_mixin.py:109} INFO - [2022-06-07 05:53:49,819] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:53:49,820] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:53:49,831] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.027 seconds
[2022-06-07 05:54:20,800] {processor.py:163} INFO - Started process (PID=1038315) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:54:20,800] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:54:20,801] {logging_mixin.py:109} INFO - [2022-06-07 05:54:20,801] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:54:50,803] {logging_mixin.py:109} INFO - [2022-06-07 05:54:50,803] {timeout.py:36} ERROR - Process timed out, PID: 1038315
[2022-06-07 05:54:50,804] {logging_mixin.py:109} INFO - [2022-06-07 05:54:50,803] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1038315
[2022-06-07 05:54:50,804] {logging_mixin.py:109} INFO - [2022-06-07 05:54:50,804] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:54:50,805] {logging_mixin.py:109} INFO - [2022-06-07 05:54:50,804] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1038315

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:54:50,805] {logging_mixin.py:109} INFO - [2022-06-07 05:54:50,805] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:54:50,805] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:54:50,817] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 05:55:21,528] {processor.py:163} INFO - Started process (PID=1039407) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:55:21,529] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:55:21,530] {logging_mixin.py:109} INFO - [2022-06-07 05:55:21,529] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:55:51,538] {logging_mixin.py:109} INFO - [2022-06-07 05:55:51,538] {timeout.py:36} ERROR - Process timed out, PID: 1039407
[2022-06-07 05:55:51,538] {logging_mixin.py:109} INFO - [2022-06-07 05:55:51,538] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1039407
[2022-06-07 05:55:51,539] {logging_mixin.py:109} INFO - [2022-06-07 05:55:51,539] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:55:51,539] {logging_mixin.py:109} INFO - [2022-06-07 05:55:51,539] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1039407

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:55:51,539] {logging_mixin.py:109} INFO - [2022-06-07 05:55:51,539] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:55:51,540] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:55:51,551] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 05:56:22,356] {processor.py:163} INFO - Started process (PID=1040503) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:56:22,357] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:56:22,357] {logging_mixin.py:109} INFO - [2022-06-07 05:56:22,357] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:56:52,369] {logging_mixin.py:109} INFO - [2022-06-07 05:56:52,369] {timeout.py:36} ERROR - Process timed out, PID: 1040503
[2022-06-07 05:56:52,370] {logging_mixin.py:109} INFO - [2022-06-07 05:56:52,369] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1040503
[2022-06-07 05:56:52,370] {logging_mixin.py:109} INFO - [2022-06-07 05:56:52,370] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:56:52,371] {logging_mixin.py:109} INFO - [2022-06-07 05:56:52,370] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1040503

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:56:52,371] {logging_mixin.py:109} INFO - [2022-06-07 05:56:52,371] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:56:52,371] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:56:52,383] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 05:57:22,491] {processor.py:163} INFO - Started process (PID=1041595) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:57:22,491] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:57:22,492] {logging_mixin.py:109} INFO - [2022-06-07 05:57:22,492] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:57:52,493] {logging_mixin.py:109} INFO - [2022-06-07 05:57:52,493] {timeout.py:36} ERROR - Process timed out, PID: 1041595
[2022-06-07 05:57:52,494] {logging_mixin.py:109} INFO - [2022-06-07 05:57:52,493] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1041595
[2022-06-07 05:57:52,494] {logging_mixin.py:109} INFO - [2022-06-07 05:57:52,494] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:57:52,495] {logging_mixin.py:109} INFO - [2022-06-07 05:57:52,494] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1041595

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:57:52,495] {logging_mixin.py:109} INFO - [2022-06-07 05:57:52,495] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:57:52,495] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:57:52,509] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 05:58:23,519] {processor.py:163} INFO - Started process (PID=1042690) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:58:23,520] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:58:23,520] {logging_mixin.py:109} INFO - [2022-06-07 05:58:23,520] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:58:53,521] {logging_mixin.py:109} INFO - [2022-06-07 05:58:53,521] {timeout.py:36} ERROR - Process timed out, PID: 1042690
[2022-06-07 05:58:53,522] {logging_mixin.py:109} INFO - [2022-06-07 05:58:53,521] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1042690
[2022-06-07 05:58:53,522] {logging_mixin.py:109} INFO - [2022-06-07 05:58:53,522] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:58:53,522] {logging_mixin.py:109} INFO - [2022-06-07 05:58:53,522] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1042690

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:58:53,522] {logging_mixin.py:109} INFO - [2022-06-07 05:58:53,522] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:58:53,523] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:58:53,534] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 05:59:24,518] {processor.py:163} INFO - Started process (PID=1043783) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 05:59:24,518] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 05:59:24,518] {logging_mixin.py:109} INFO - [2022-06-07 05:59:24,518] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:59:54,523] {logging_mixin.py:109} INFO - [2022-06-07 05:59:54,523] {timeout.py:36} ERROR - Process timed out, PID: 1043783
[2022-06-07 05:59:54,524] {logging_mixin.py:109} INFO - [2022-06-07 05:59:54,523] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1043783
[2022-06-07 05:59:54,524] {logging_mixin.py:109} INFO - [2022-06-07 05:59:54,524] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 05:59:54,525] {logging_mixin.py:109} INFO - [2022-06-07 05:59:54,524] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1043783

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 05:59:54,525] {logging_mixin.py:109} INFO - [2022-06-07 05:59:54,525] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 05:59:54,525] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 05:59:54,536] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 06:00:24,579] {processor.py:163} INFO - Started process (PID=1044876) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:00:24,579] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:00:24,579] {logging_mixin.py:109} INFO - [2022-06-07 06:00:24,579] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:00:54,590] {logging_mixin.py:109} INFO - [2022-06-07 06:00:54,589] {timeout.py:36} ERROR - Process timed out, PID: 1044876
[2022-06-07 06:00:54,590] {logging_mixin.py:109} INFO - [2022-06-07 06:00:54,590] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1044876
[2022-06-07 06:00:54,590] {logging_mixin.py:109} INFO - [2022-06-07 06:00:54,590] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:00:54,591] {logging_mixin.py:109} INFO - [2022-06-07 06:00:54,591] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1044876

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:00:54,591] {logging_mixin.py:109} INFO - [2022-06-07 06:00:54,591] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:00:54,592] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:00:54,603] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 06:01:24,710] {processor.py:163} INFO - Started process (PID=1045971) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:01:24,711] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:01:24,711] {logging_mixin.py:109} INFO - [2022-06-07 06:01:24,711] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:01:54,713] {logging_mixin.py:109} INFO - [2022-06-07 06:01:54,712] {timeout.py:36} ERROR - Process timed out, PID: 1045971
[2022-06-07 06:01:54,713] {logging_mixin.py:109} INFO - [2022-06-07 06:01:54,713] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1045971
[2022-06-07 06:01:54,713] {logging_mixin.py:109} INFO - [2022-06-07 06:01:54,713] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:01:54,714] {logging_mixin.py:109} INFO - [2022-06-07 06:01:54,713] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1045971

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:01:54,714] {logging_mixin.py:109} INFO - [2022-06-07 06:01:54,714] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:01:54,714] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:01:54,727] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:02:24,856] {processor.py:163} INFO - Started process (PID=1047065) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:02:24,856] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:02:24,857] {logging_mixin.py:109} INFO - [2022-06-07 06:02:24,857] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:02:54,861] {logging_mixin.py:109} INFO - [2022-06-07 06:02:54,860] {timeout.py:36} ERROR - Process timed out, PID: 1047065
[2022-06-07 06:02:54,861] {logging_mixin.py:109} INFO - [2022-06-07 06:02:54,861] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1047065
[2022-06-07 06:02:54,862] {logging_mixin.py:109} INFO - [2022-06-07 06:02:54,861] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:02:54,862] {logging_mixin.py:109} INFO - [2022-06-07 06:02:54,862] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1047065

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:02:54,862] {logging_mixin.py:109} INFO - [2022-06-07 06:02:54,862] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:02:54,863] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:02:54,874] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 06:03:25,862] {processor.py:163} INFO - Started process (PID=1048159) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:03:25,862] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:03:25,863] {logging_mixin.py:109} INFO - [2022-06-07 06:03:25,863] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:03:55,864] {logging_mixin.py:109} INFO - [2022-06-07 06:03:55,864] {timeout.py:36} ERROR - Process timed out, PID: 1048159
[2022-06-07 06:03:55,865] {logging_mixin.py:109} INFO - [2022-06-07 06:03:55,864] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1048159
[2022-06-07 06:03:55,865] {logging_mixin.py:109} INFO - [2022-06-07 06:03:55,865] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:03:55,865] {logging_mixin.py:109} INFO - [2022-06-07 06:03:55,865] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1048159

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:03:55,866] {logging_mixin.py:109} INFO - [2022-06-07 06:03:55,866] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:03:55,866] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:03:55,878] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 06:04:25,904] {processor.py:163} INFO - Started process (PID=1049252) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:04:25,904] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:04:25,905] {logging_mixin.py:109} INFO - [2022-06-07 06:04:25,905] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:04:55,921] {logging_mixin.py:109} INFO - [2022-06-07 06:04:55,921] {timeout.py:36} ERROR - Process timed out, PID: 1049252
[2022-06-07 06:04:55,922] {logging_mixin.py:109} INFO - [2022-06-07 06:04:55,921] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1049252
[2022-06-07 06:04:55,922] {logging_mixin.py:109} INFO - [2022-06-07 06:04:55,922] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:04:55,922] {logging_mixin.py:109} INFO - [2022-06-07 06:04:55,922] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1049252

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:04:55,923] {logging_mixin.py:109} INFO - [2022-06-07 06:04:55,922] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:04:55,923] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:04:55,934] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.032 seconds
[2022-06-07 06:05:26,370] {processor.py:163} INFO - Started process (PID=1050346) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:05:26,371] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:05:26,371] {logging_mixin.py:109} INFO - [2022-06-07 06:05:26,371] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:05:56,380] {logging_mixin.py:109} INFO - [2022-06-07 06:05:56,379] {timeout.py:36} ERROR - Process timed out, PID: 1050346
[2022-06-07 06:05:56,380] {logging_mixin.py:109} INFO - [2022-06-07 06:05:56,380] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1050346
[2022-06-07 06:05:56,380] {logging_mixin.py:109} INFO - [2022-06-07 06:05:56,380] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:05:56,381] {logging_mixin.py:109} INFO - [2022-06-07 06:05:56,380] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1050346

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:05:56,381] {logging_mixin.py:109} INFO - [2022-06-07 06:05:56,381] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:05:56,381] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:05:56,393] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 06:06:27,249] {processor.py:163} INFO - Started process (PID=1051439) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:06:27,249] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:06:27,250] {logging_mixin.py:109} INFO - [2022-06-07 06:06:27,250] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:06:57,251] {logging_mixin.py:109} INFO - [2022-06-07 06:06:57,251] {timeout.py:36} ERROR - Process timed out, PID: 1051439
[2022-06-07 06:06:57,252] {logging_mixin.py:109} INFO - [2022-06-07 06:06:57,252] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1051439
[2022-06-07 06:06:57,252] {logging_mixin.py:109} INFO - [2022-06-07 06:06:57,252] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:06:57,253] {logging_mixin.py:109} INFO - [2022-06-07 06:06:57,252] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1051439

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:06:57,253] {logging_mixin.py:109} INFO - [2022-06-07 06:06:57,253] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:06:57,253] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:06:57,264] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 06:07:28,206] {processor.py:163} INFO - Started process (PID=1052532) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:07:28,207] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:07:28,207] {logging_mixin.py:109} INFO - [2022-06-07 06:07:28,207] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:07:58,208] {logging_mixin.py:109} INFO - [2022-06-07 06:07:58,208] {timeout.py:36} ERROR - Process timed out, PID: 1052532
[2022-06-07 06:07:58,209] {logging_mixin.py:109} INFO - [2022-06-07 06:07:58,208] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1052532
[2022-06-07 06:07:58,209] {logging_mixin.py:109} INFO - [2022-06-07 06:07:58,209] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:07:58,210] {logging_mixin.py:109} INFO - [2022-06-07 06:07:58,209] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1052532

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:07:58,210] {logging_mixin.py:109} INFO - [2022-06-07 06:07:58,210] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:07:58,210] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:07:58,222] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 06:08:28,703] {processor.py:163} INFO - Started process (PID=1053625) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:08:28,704] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:08:28,704] {logging_mixin.py:109} INFO - [2022-06-07 06:08:28,704] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:08:58,705] {logging_mixin.py:109} INFO - [2022-06-07 06:08:58,705] {timeout.py:36} ERROR - Process timed out, PID: 1053625
[2022-06-07 06:08:58,706] {logging_mixin.py:109} INFO - [2022-06-07 06:08:58,705] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1053625
[2022-06-07 06:08:58,706] {logging_mixin.py:109} INFO - [2022-06-07 06:08:58,706] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:08:58,706] {logging_mixin.py:109} INFO - [2022-06-07 06:08:58,706] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1053625

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:08:58,706] {logging_mixin.py:109} INFO - [2022-06-07 06:08:58,706] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:08:58,707] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:08:58,718] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 06:09:28,765] {processor.py:163} INFO - Started process (PID=1054719) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:09:28,765] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:09:28,766] {logging_mixin.py:109} INFO - [2022-06-07 06:09:28,766] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:09:58,770] {logging_mixin.py:109} INFO - [2022-06-07 06:09:58,769] {timeout.py:36} ERROR - Process timed out, PID: 1054719
[2022-06-07 06:09:58,770] {logging_mixin.py:109} INFO - [2022-06-07 06:09:58,770] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1054719
[2022-06-07 06:09:58,770] {logging_mixin.py:109} INFO - [2022-06-07 06:09:58,770] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:09:58,771] {logging_mixin.py:109} INFO - [2022-06-07 06:09:58,770] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1054719

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:09:58,771] {logging_mixin.py:109} INFO - [2022-06-07 06:09:58,771] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:09:58,771] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:09:58,783] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 06:10:29,142] {processor.py:163} INFO - Started process (PID=1055815) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:10:29,143] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:10:29,143] {logging_mixin.py:109} INFO - [2022-06-07 06:10:29,143] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:10:59,149] {logging_mixin.py:109} INFO - [2022-06-07 06:10:59,149] {timeout.py:36} ERROR - Process timed out, PID: 1055815
[2022-06-07 06:10:59,150] {logging_mixin.py:109} INFO - [2022-06-07 06:10:59,149] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1055815
[2022-06-07 06:10:59,150] {logging_mixin.py:109} INFO - [2022-06-07 06:10:59,150] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:10:59,150] {logging_mixin.py:109} INFO - [2022-06-07 06:10:59,150] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1055815

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:10:59,151] {logging_mixin.py:109} INFO - [2022-06-07 06:10:59,151] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:10:59,151] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:10:59,162] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 06:11:30,027] {processor.py:163} INFO - Started process (PID=1056910) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:11:30,027] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:11:30,028] {logging_mixin.py:109} INFO - [2022-06-07 06:11:30,027] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:12:00,029] {logging_mixin.py:109} INFO - [2022-06-07 06:12:00,028] {timeout.py:36} ERROR - Process timed out, PID: 1056910
[2022-06-07 06:12:00,029] {logging_mixin.py:109} INFO - [2022-06-07 06:12:00,029] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1056910
[2022-06-07 06:12:00,029] {logging_mixin.py:109} INFO - [2022-06-07 06:12:00,029] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:12:00,030] {logging_mixin.py:109} INFO - [2022-06-07 06:12:00,030] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1056910

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:12:00,030] {logging_mixin.py:109} INFO - [2022-06-07 06:12:00,030] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:12:00,031] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:12:00,042] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 06:12:31,035] {processor.py:163} INFO - Started process (PID=1058003) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:12:31,035] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:12:31,036] {logging_mixin.py:109} INFO - [2022-06-07 06:12:31,036] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:13:01,051] {logging_mixin.py:109} INFO - [2022-06-07 06:13:01,050] {timeout.py:36} ERROR - Process timed out, PID: 1058003
[2022-06-07 06:13:01,051] {logging_mixin.py:109} INFO - [2022-06-07 06:13:01,051] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1058003
[2022-06-07 06:13:01,051] {logging_mixin.py:109} INFO - [2022-06-07 06:13:01,051] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:13:01,052] {logging_mixin.py:109} INFO - [2022-06-07 06:13:01,052] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1058003

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:13:01,052] {logging_mixin.py:109} INFO - [2022-06-07 06:13:01,052] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:13:01,052] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:13:01,064] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.030 seconds
[2022-06-07 06:13:31,556] {processor.py:163} INFO - Started process (PID=1059097) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:13:31,557] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:13:31,557] {logging_mixin.py:109} INFO - [2022-06-07 06:13:31,557] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:14:01,559] {logging_mixin.py:109} INFO - [2022-06-07 06:14:01,558] {timeout.py:36} ERROR - Process timed out, PID: 1059097
[2022-06-07 06:14:01,559] {logging_mixin.py:109} INFO - [2022-06-07 06:14:01,559] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1059097
[2022-06-07 06:14:01,559] {logging_mixin.py:109} INFO - [2022-06-07 06:14:01,559] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:14:01,560] {logging_mixin.py:109} INFO - [2022-06-07 06:14:01,560] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1059097

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:14:01,560] {logging_mixin.py:109} INFO - [2022-06-07 06:14:01,560] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:14:01,560] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:14:01,574] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 06:14:31,603] {processor.py:163} INFO - Started process (PID=1060189) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:14:31,603] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:14:31,603] {logging_mixin.py:109} INFO - [2022-06-07 06:14:31,603] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:15:01,604] {logging_mixin.py:109} INFO - [2022-06-07 06:15:01,604] {timeout.py:36} ERROR - Process timed out, PID: 1060189
[2022-06-07 06:15:01,605] {logging_mixin.py:109} INFO - [2022-06-07 06:15:01,604] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1060189
[2022-06-07 06:15:01,605] {logging_mixin.py:109} INFO - [2022-06-07 06:15:01,605] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:15:01,606] {logging_mixin.py:109} INFO - [2022-06-07 06:15:01,605] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1060189

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:15:01,606] {logging_mixin.py:109} INFO - [2022-06-07 06:15:01,606] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:15:01,606] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:15:01,618] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 06:15:31,664] {processor.py:163} INFO - Started process (PID=1061190) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:15:31,665] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:15:31,666] {logging_mixin.py:109} INFO - [2022-06-07 06:15:31,666] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:16:01,668] {logging_mixin.py:109} INFO - [2022-06-07 06:16:01,667] {timeout.py:36} ERROR - Process timed out, PID: 1061190
[2022-06-07 06:16:01,668] {logging_mixin.py:109} INFO - [2022-06-07 06:16:01,668] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1061190
[2022-06-07 06:16:01,668] {logging_mixin.py:109} INFO - [2022-06-07 06:16:01,668] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:16:01,669] {logging_mixin.py:109} INFO - [2022-06-07 06:16:01,668] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1061190

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:16:01,669] {logging_mixin.py:109} INFO - [2022-06-07 06:16:01,669] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:16:01,669] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:16:01,680] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:16:31,791] {processor.py:163} INFO - Started process (PID=1062286) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:16:31,792] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:16:31,792] {logging_mixin.py:109} INFO - [2022-06-07 06:16:31,792] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:17:01,800] {logging_mixin.py:109} INFO - [2022-06-07 06:17:01,799] {timeout.py:36} ERROR - Process timed out, PID: 1062286
[2022-06-07 06:17:01,800] {logging_mixin.py:109} INFO - [2022-06-07 06:17:01,800] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1062286
[2022-06-07 06:17:01,800] {logging_mixin.py:109} INFO - [2022-06-07 06:17:01,800] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:17:01,801] {logging_mixin.py:109} INFO - [2022-06-07 06:17:01,800] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1062286

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:17:01,801] {logging_mixin.py:109} INFO - [2022-06-07 06:17:01,801] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:17:01,801] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:17:01,813] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 06:17:32,811] {processor.py:163} INFO - Started process (PID=1063381) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:17:32,811] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:17:32,811] {logging_mixin.py:109} INFO - [2022-06-07 06:17:32,811] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:18:02,816] {logging_mixin.py:109} INFO - [2022-06-07 06:18:02,815] {timeout.py:36} ERROR - Process timed out, PID: 1063381
[2022-06-07 06:18:02,816] {logging_mixin.py:109} INFO - [2022-06-07 06:18:02,816] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1063381
[2022-06-07 06:18:02,817] {logging_mixin.py:109} INFO - [2022-06-07 06:18:02,816] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:18:02,817] {logging_mixin.py:109} INFO - [2022-06-07 06:18:02,817] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1063381

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:18:02,817] {logging_mixin.py:109} INFO - [2022-06-07 06:18:02,817] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:18:02,818] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:18:02,829] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 06:18:33,298] {processor.py:163} INFO - Started process (PID=1064474) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:18:33,298] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:18:33,299] {logging_mixin.py:109} INFO - [2022-06-07 06:18:33,299] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:19:03,300] {logging_mixin.py:109} INFO - [2022-06-07 06:19:03,300] {timeout.py:36} ERROR - Process timed out, PID: 1064474
[2022-06-07 06:19:03,301] {logging_mixin.py:109} INFO - [2022-06-07 06:19:03,300] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1064474
[2022-06-07 06:19:03,301] {logging_mixin.py:109} INFO - [2022-06-07 06:19:03,301] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:19:03,301] {logging_mixin.py:109} INFO - [2022-06-07 06:19:03,301] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1064474

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:19:03,301] {logging_mixin.py:109} INFO - [2022-06-07 06:19:03,301] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:19:03,302] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:19:03,313] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 06:19:33,352] {processor.py:163} INFO - Started process (PID=1065568) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:19:33,353] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:19:33,353] {logging_mixin.py:109} INFO - [2022-06-07 06:19:33,353] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:20:03,363] {logging_mixin.py:109} INFO - [2022-06-07 06:20:03,362] {timeout.py:36} ERROR - Process timed out, PID: 1065568
[2022-06-07 06:20:03,363] {logging_mixin.py:109} INFO - [2022-06-07 06:20:03,363] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1065568
[2022-06-07 06:20:03,363] {logging_mixin.py:109} INFO - [2022-06-07 06:20:03,363] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:20:03,364] {logging_mixin.py:109} INFO - [2022-06-07 06:20:03,363] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1065568

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:20:03,364] {logging_mixin.py:109} INFO - [2022-06-07 06:20:03,364] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:20:03,364] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:20:03,376] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 06:20:33,918] {processor.py:163} INFO - Started process (PID=1066663) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:20:33,918] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:20:33,919] {logging_mixin.py:109} INFO - [2022-06-07 06:20:33,919] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:21:03,929] {logging_mixin.py:109} INFO - [2022-06-07 06:21:03,929] {timeout.py:36} ERROR - Process timed out, PID: 1066663
[2022-06-07 06:21:03,930] {logging_mixin.py:109} INFO - [2022-06-07 06:21:03,929] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1066663
[2022-06-07 06:21:03,930] {logging_mixin.py:109} INFO - [2022-06-07 06:21:03,930] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:21:03,931] {logging_mixin.py:109} INFO - [2022-06-07 06:21:03,930] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1066663

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:21:03,931] {logging_mixin.py:109} INFO - [2022-06-07 06:21:03,931] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:21:03,931] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:21:03,943] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.027 seconds
[2022-06-07 06:21:34,405] {processor.py:163} INFO - Started process (PID=1067758) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:21:34,406] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:21:34,406] {logging_mixin.py:109} INFO - [2022-06-07 06:21:34,406] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:22:04,407] {logging_mixin.py:109} INFO - [2022-06-07 06:22:04,407] {timeout.py:36} ERROR - Process timed out, PID: 1067758
[2022-06-07 06:22:04,408] {logging_mixin.py:109} INFO - [2022-06-07 06:22:04,407] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1067758
[2022-06-07 06:22:04,408] {logging_mixin.py:109} INFO - [2022-06-07 06:22:04,408] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:22:04,408] {logging_mixin.py:109} INFO - [2022-06-07 06:22:04,408] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1067758

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:22:04,409] {logging_mixin.py:109} INFO - [2022-06-07 06:22:04,408] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:22:04,409] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:22:04,420] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 06:22:34,480] {processor.py:163} INFO - Started process (PID=1068851) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:22:34,481] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:22:34,481] {logging_mixin.py:109} INFO - [2022-06-07 06:22:34,481] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:23:04,482] {logging_mixin.py:109} INFO - [2022-06-07 06:23:04,482] {timeout.py:36} ERROR - Process timed out, PID: 1068851
[2022-06-07 06:23:04,483] {logging_mixin.py:109} INFO - [2022-06-07 06:23:04,482] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1068851
[2022-06-07 06:23:04,483] {logging_mixin.py:109} INFO - [2022-06-07 06:23:04,483] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:23:04,484] {logging_mixin.py:109} INFO - [2022-06-07 06:23:04,483] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1068851

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:23:04,484] {logging_mixin.py:109} INFO - [2022-06-07 06:23:04,484] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:23:04,484] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:23:04,495] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 06:23:34,923] {processor.py:163} INFO - Started process (PID=1069945) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:23:34,924] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:23:34,924] {logging_mixin.py:109} INFO - [2022-06-07 06:23:34,924] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:24:04,926] {logging_mixin.py:109} INFO - [2022-06-07 06:24:04,926] {timeout.py:36} ERROR - Process timed out, PID: 1069945
[2022-06-07 06:24:04,927] {logging_mixin.py:109} INFO - [2022-06-07 06:24:04,926] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1069945
[2022-06-07 06:24:04,927] {logging_mixin.py:109} INFO - [2022-06-07 06:24:04,927] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:24:04,928] {logging_mixin.py:109} INFO - [2022-06-07 06:24:04,927] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1069945

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:24:04,928] {logging_mixin.py:109} INFO - [2022-06-07 06:24:04,928] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:24:04,928] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:24:04,940] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:24:35,398] {processor.py:163} INFO - Started process (PID=1071039) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:24:35,399] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:24:35,399] {logging_mixin.py:109} INFO - [2022-06-07 06:24:35,399] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:25:05,401] {logging_mixin.py:109} INFO - [2022-06-07 06:25:05,400] {timeout.py:36} ERROR - Process timed out, PID: 1071039
[2022-06-07 06:25:05,409] {logging_mixin.py:109} INFO - [2022-06-07 06:25:05,405] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1071039
[2022-06-07 06:25:05,409] {logging_mixin.py:109} INFO - [2022-06-07 06:25:05,409] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:25:05,409] {logging_mixin.py:109} INFO - [2022-06-07 06:25:05,409] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1071039

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:25:05,410] {logging_mixin.py:109} INFO - [2022-06-07 06:25:05,410] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:25:05,410] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:25:05,422] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 06:25:36,126] {processor.py:163} INFO - Started process (PID=1072133) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:25:36,127] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:25:36,127] {logging_mixin.py:109} INFO - [2022-06-07 06:25:36,127] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:26:06,132] {logging_mixin.py:109} INFO - [2022-06-07 06:26:06,132] {timeout.py:36} ERROR - Process timed out, PID: 1072133
[2022-06-07 06:26:06,133] {logging_mixin.py:109} INFO - [2022-06-07 06:26:06,132] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1072133
[2022-06-07 06:26:06,133] {logging_mixin.py:109} INFO - [2022-06-07 06:26:06,133] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:26:06,134] {logging_mixin.py:109} INFO - [2022-06-07 06:26:06,133] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1072133

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:26:06,134] {logging_mixin.py:109} INFO - [2022-06-07 06:26:06,134] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:26:06,134] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:26:06,147] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 06:26:37,127] {processor.py:163} INFO - Started process (PID=1073227) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:26:37,128] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:26:37,128] {logging_mixin.py:109} INFO - [2022-06-07 06:26:37,128] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:27:07,130] {logging_mixin.py:109} INFO - [2022-06-07 06:27:07,129] {timeout.py:36} ERROR - Process timed out, PID: 1073227
[2022-06-07 06:27:07,130] {logging_mixin.py:109} INFO - [2022-06-07 06:27:07,130] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1073227
[2022-06-07 06:27:07,130] {logging_mixin.py:109} INFO - [2022-06-07 06:27:07,130] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:27:07,131] {logging_mixin.py:109} INFO - [2022-06-07 06:27:07,130] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1073227

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:27:07,131] {logging_mixin.py:109} INFO - [2022-06-07 06:27:07,131] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:27:07,131] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:27:07,143] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:27:37,352] {processor.py:163} INFO - Started process (PID=1074321) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:27:37,352] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:27:37,353] {logging_mixin.py:109} INFO - [2022-06-07 06:27:37,353] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:28:07,357] {logging_mixin.py:109} INFO - [2022-06-07 06:28:07,356] {timeout.py:36} ERROR - Process timed out, PID: 1074321
[2022-06-07 06:28:07,357] {logging_mixin.py:109} INFO - [2022-06-07 06:28:07,357] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1074321
[2022-06-07 06:28:07,357] {logging_mixin.py:109} INFO - [2022-06-07 06:28:07,357] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:28:07,358] {logging_mixin.py:109} INFO - [2022-06-07 06:28:07,357] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1074321

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:28:07,358] {logging_mixin.py:109} INFO - [2022-06-07 06:28:07,358] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:28:07,358] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:28:07,371] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 06:28:37,387] {processor.py:163} INFO - Started process (PID=1075415) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:28:37,388] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:28:37,388] {logging_mixin.py:109} INFO - [2022-06-07 06:28:37,388] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:29:07,389] {logging_mixin.py:109} INFO - [2022-06-07 06:29:07,389] {timeout.py:36} ERROR - Process timed out, PID: 1075415
[2022-06-07 06:29:07,390] {logging_mixin.py:109} INFO - [2022-06-07 06:29:07,389] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1075415
[2022-06-07 06:29:07,390] {logging_mixin.py:109} INFO - [2022-06-07 06:29:07,390] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:29:07,390] {logging_mixin.py:109} INFO - [2022-06-07 06:29:07,390] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1075415

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:29:07,391] {logging_mixin.py:109} INFO - [2022-06-07 06:29:07,391] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:29:07,391] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:29:07,404] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:29:37,659] {processor.py:163} INFO - Started process (PID=1076510) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:29:37,659] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:29:37,659] {logging_mixin.py:109} INFO - [2022-06-07 06:29:37,659] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:30:07,664] {logging_mixin.py:109} INFO - [2022-06-07 06:30:07,664] {timeout.py:36} ERROR - Process timed out, PID: 1076510
[2022-06-07 06:30:07,665] {logging_mixin.py:109} INFO - [2022-06-07 06:30:07,664] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1076510
[2022-06-07 06:30:07,665] {logging_mixin.py:109} INFO - [2022-06-07 06:30:07,665] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:30:07,665] {logging_mixin.py:109} INFO - [2022-06-07 06:30:07,665] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1076510

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:30:07,666] {logging_mixin.py:109} INFO - [2022-06-07 06:30:07,665] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:30:07,666] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:30:07,677] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 06:30:37,937] {processor.py:163} INFO - Started process (PID=1077605) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:30:37,938] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:30:37,938] {logging_mixin.py:109} INFO - [2022-06-07 06:30:37,938] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:31:07,940] {logging_mixin.py:109} INFO - [2022-06-07 06:31:07,939] {timeout.py:36} ERROR - Process timed out, PID: 1077605
[2022-06-07 06:31:07,940] {logging_mixin.py:109} INFO - [2022-06-07 06:31:07,940] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1077605
[2022-06-07 06:31:07,940] {logging_mixin.py:109} INFO - [2022-06-07 06:31:07,940] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:31:07,941] {logging_mixin.py:109} INFO - [2022-06-07 06:31:07,941] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1077605

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:31:07,941] {logging_mixin.py:109} INFO - [2022-06-07 06:31:07,941] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:31:07,942] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:31:07,952] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 06:31:38,296] {processor.py:163} INFO - Started process (PID=1078700) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:31:38,296] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:31:38,297] {logging_mixin.py:109} INFO - [2022-06-07 06:31:38,297] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:32:08,301] {logging_mixin.py:109} INFO - [2022-06-07 06:32:08,300] {timeout.py:36} ERROR - Process timed out, PID: 1078700
[2022-06-07 06:32:08,301] {logging_mixin.py:109} INFO - [2022-06-07 06:32:08,301] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1078700
[2022-06-07 06:32:08,301] {logging_mixin.py:109} INFO - [2022-06-07 06:32:08,301] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:32:08,302] {logging_mixin.py:109} INFO - [2022-06-07 06:32:08,301] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1078700

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:32:08,302] {logging_mixin.py:109} INFO - [2022-06-07 06:32:08,302] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:32:08,302] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:32:08,313] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 06:32:38,549] {processor.py:163} INFO - Started process (PID=1079793) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:32:38,550] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:32:38,550] {logging_mixin.py:109} INFO - [2022-06-07 06:32:38,550] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:33:08,552] {logging_mixin.py:109} INFO - [2022-06-07 06:33:08,552] {timeout.py:36} ERROR - Process timed out, PID: 1079793
[2022-06-07 06:33:08,553] {logging_mixin.py:109} INFO - [2022-06-07 06:33:08,552] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1079793
[2022-06-07 06:33:08,553] {logging_mixin.py:109} INFO - [2022-06-07 06:33:08,553] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:33:08,554] {logging_mixin.py:109} INFO - [2022-06-07 06:33:08,553] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1079793

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:33:08,554] {logging_mixin.py:109} INFO - [2022-06-07 06:33:08,554] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:33:08,554] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:33:08,566] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:33:38,769] {processor.py:163} INFO - Started process (PID=1080881) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:33:38,770] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:33:38,770] {logging_mixin.py:109} INFO - [2022-06-07 06:33:38,770] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:34:08,778] {logging_mixin.py:109} INFO - [2022-06-07 06:34:08,778] {timeout.py:36} ERROR - Process timed out, PID: 1080881
[2022-06-07 06:34:08,778] {logging_mixin.py:109} INFO - [2022-06-07 06:34:08,778] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1080881
[2022-06-07 06:34:08,779] {logging_mixin.py:109} INFO - [2022-06-07 06:34:08,779] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:34:08,779] {logging_mixin.py:109} INFO - [2022-06-07 06:34:08,779] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1080881

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:34:08,779] {logging_mixin.py:109} INFO - [2022-06-07 06:34:08,779] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:34:08,780] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:34:08,791] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 06:34:39,362] {processor.py:163} INFO - Started process (PID=1081976) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:34:39,363] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:34:39,363] {logging_mixin.py:109} INFO - [2022-06-07 06:34:39,363] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:35:09,369] {logging_mixin.py:109} INFO - [2022-06-07 06:35:09,369] {timeout.py:36} ERROR - Process timed out, PID: 1081976
[2022-06-07 06:35:09,370] {logging_mixin.py:109} INFO - [2022-06-07 06:35:09,369] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1081976
[2022-06-07 06:35:09,370] {logging_mixin.py:109} INFO - [2022-06-07 06:35:09,370] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:35:09,371] {logging_mixin.py:109} INFO - [2022-06-07 06:35:09,370] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1081976

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:35:09,371] {logging_mixin.py:109} INFO - [2022-06-07 06:35:09,371] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:35:09,371] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:35:09,383] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 06:35:39,586] {processor.py:163} INFO - Started process (PID=1083071) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:35:39,586] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:35:39,587] {logging_mixin.py:109} INFO - [2022-06-07 06:35:39,587] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:36:09,588] {logging_mixin.py:109} INFO - [2022-06-07 06:36:09,587] {timeout.py:36} ERROR - Process timed out, PID: 1083071
[2022-06-07 06:36:09,588] {logging_mixin.py:109} INFO - [2022-06-07 06:36:09,588] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1083071
[2022-06-07 06:36:09,589] {logging_mixin.py:109} INFO - [2022-06-07 06:36:09,589] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:36:09,589] {logging_mixin.py:109} INFO - [2022-06-07 06:36:09,589] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1083071

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:36:09,590] {logging_mixin.py:109} INFO - [2022-06-07 06:36:09,589] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:36:09,590] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:36:09,602] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:36:40,206] {processor.py:163} INFO - Started process (PID=1084165) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:36:40,207] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:36:40,207] {logging_mixin.py:109} INFO - [2022-06-07 06:36:40,207] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:37:10,211] {logging_mixin.py:109} INFO - [2022-06-07 06:37:10,211] {timeout.py:36} ERROR - Process timed out, PID: 1084165
[2022-06-07 06:37:10,212] {logging_mixin.py:109} INFO - [2022-06-07 06:37:10,211] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1084165
[2022-06-07 06:37:10,212] {logging_mixin.py:109} INFO - [2022-06-07 06:37:10,212] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:37:10,213] {logging_mixin.py:109} INFO - [2022-06-07 06:37:10,212] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1084165

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:37:10,213] {logging_mixin.py:109} INFO - [2022-06-07 06:37:10,213] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:37:10,213] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:37:10,225] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 06:37:40,626] {processor.py:163} INFO - Started process (PID=1085258) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:37:40,626] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:37:40,626] {logging_mixin.py:109} INFO - [2022-06-07 06:37:40,626] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:38:10,628] {logging_mixin.py:109} INFO - [2022-06-07 06:38:10,628] {timeout.py:36} ERROR - Process timed out, PID: 1085258
[2022-06-07 06:38:10,629] {logging_mixin.py:109} INFO - [2022-06-07 06:38:10,628] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1085258
[2022-06-07 06:38:10,629] {logging_mixin.py:109} INFO - [2022-06-07 06:38:10,629] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:38:10,629] {logging_mixin.py:109} INFO - [2022-06-07 06:38:10,629] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1085258

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:38:10,630] {logging_mixin.py:109} INFO - [2022-06-07 06:38:10,629] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:38:10,630] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:38:10,642] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:38:40,659] {processor.py:163} INFO - Started process (PID=1086352) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:38:40,659] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:38:40,660] {logging_mixin.py:109} INFO - [2022-06-07 06:38:40,660] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:39:10,662] {logging_mixin.py:109} INFO - [2022-06-07 06:39:10,661] {timeout.py:36} ERROR - Process timed out, PID: 1086352
[2022-06-07 06:39:10,662] {logging_mixin.py:109} INFO - [2022-06-07 06:39:10,662] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1086352
[2022-06-07 06:39:10,662] {logging_mixin.py:109} INFO - [2022-06-07 06:39:10,662] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:39:10,663] {logging_mixin.py:109} INFO - [2022-06-07 06:39:10,662] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1086352

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:39:10,663] {logging_mixin.py:109} INFO - [2022-06-07 06:39:10,663] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:39:10,663] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:39:10,674] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 06:39:41,034] {processor.py:163} INFO - Started process (PID=1087446) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:39:41,035] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:39:41,035] {logging_mixin.py:109} INFO - [2022-06-07 06:39:41,035] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:40:11,036] {logging_mixin.py:109} INFO - [2022-06-07 06:40:11,036] {timeout.py:36} ERROR - Process timed out, PID: 1087446
[2022-06-07 06:40:11,036] {logging_mixin.py:109} INFO - [2022-06-07 06:40:11,036] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1087446
[2022-06-07 06:40:11,037] {logging_mixin.py:109} INFO - [2022-06-07 06:40:11,037] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:40:11,037] {logging_mixin.py:109} INFO - [2022-06-07 06:40:11,037] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1087446

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:40:11,038] {logging_mixin.py:109} INFO - [2022-06-07 06:40:11,037] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:40:11,038] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:40:11,050] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 06:40:41,142] {processor.py:163} INFO - Started process (PID=1088484) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:40:41,142] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:40:41,143] {logging_mixin.py:109} INFO - [2022-06-07 06:40:41,143] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:41:11,145] {logging_mixin.py:109} INFO - [2022-06-07 06:41:11,144] {timeout.py:36} ERROR - Process timed out, PID: 1088484
[2022-06-07 06:41:11,145] {logging_mixin.py:109} INFO - [2022-06-07 06:41:11,145] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1088484
[2022-06-07 06:41:11,145] {logging_mixin.py:109} INFO - [2022-06-07 06:41:11,145] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:41:11,146] {logging_mixin.py:109} INFO - [2022-06-07 06:41:11,146] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1088484

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:41:11,146] {logging_mixin.py:109} INFO - [2022-06-07 06:41:11,146] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:41:11,146] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:41:11,158] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:41:41,285] {processor.py:163} INFO - Started process (PID=1089564) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:41:41,286] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:41:41,286] {logging_mixin.py:109} INFO - [2022-06-07 06:41:41,286] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:42:11,292] {logging_mixin.py:109} INFO - [2022-06-07 06:42:11,291] {timeout.py:36} ERROR - Process timed out, PID: 1089564
[2022-06-07 06:42:11,292] {logging_mixin.py:109} INFO - [2022-06-07 06:42:11,292] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1089564
[2022-06-07 06:42:11,292] {logging_mixin.py:109} INFO - [2022-06-07 06:42:11,292] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:42:11,293] {logging_mixin.py:109} INFO - [2022-06-07 06:42:11,292] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1089564

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:42:11,293] {logging_mixin.py:109} INFO - [2022-06-07 06:42:11,293] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:42:11,293] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:42:11,305] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 06:42:41,565] {processor.py:163} INFO - Started process (PID=1090659) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:42:41,565] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:42:41,565] {logging_mixin.py:109} INFO - [2022-06-07 06:42:41,565] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:43:11,566] {logging_mixin.py:109} INFO - [2022-06-07 06:43:11,566] {timeout.py:36} ERROR - Process timed out, PID: 1090659
[2022-06-07 06:43:11,567] {logging_mixin.py:109} INFO - [2022-06-07 06:43:11,567] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1090659
[2022-06-07 06:43:11,567] {logging_mixin.py:109} INFO - [2022-06-07 06:43:11,567] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:43:11,568] {logging_mixin.py:109} INFO - [2022-06-07 06:43:11,567] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1090659

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:43:11,568] {logging_mixin.py:109} INFO - [2022-06-07 06:43:11,568] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:43:11,568] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:43:11,582] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 06:43:41,681] {processor.py:163} INFO - Started process (PID=1091728) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:43:41,682] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:43:41,682] {logging_mixin.py:109} INFO - [2022-06-07 06:43:41,682] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:44:11,685] {logging_mixin.py:109} INFO - [2022-06-07 06:44:11,684] {timeout.py:36} ERROR - Process timed out, PID: 1091728
[2022-06-07 06:44:11,685] {logging_mixin.py:109} INFO - [2022-06-07 06:44:11,685] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1091728
[2022-06-07 06:44:11,685] {logging_mixin.py:109} INFO - [2022-06-07 06:44:11,685] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:44:11,686] {logging_mixin.py:109} INFO - [2022-06-07 06:44:11,686] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1091728

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:44:11,686] {logging_mixin.py:109} INFO - [2022-06-07 06:44:11,686] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:44:11,686] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:44:11,697] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 06:44:42,197] {processor.py:163} INFO - Started process (PID=1092822) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:44:42,198] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:44:42,198] {logging_mixin.py:109} INFO - [2022-06-07 06:44:42,198] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:45:12,199] {logging_mixin.py:109} INFO - [2022-06-07 06:45:12,198] {timeout.py:36} ERROR - Process timed out, PID: 1092822
[2022-06-07 06:45:12,199] {logging_mixin.py:109} INFO - [2022-06-07 06:45:12,199] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1092822
[2022-06-07 06:45:12,199] {logging_mixin.py:109} INFO - [2022-06-07 06:45:12,199] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:45:12,200] {logging_mixin.py:109} INFO - [2022-06-07 06:45:12,200] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1092822

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:45:12,200] {logging_mixin.py:109} INFO - [2022-06-07 06:45:12,200] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:45:12,200] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:45:12,212] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 06:45:42,317] {processor.py:163} INFO - Started process (PID=1093916) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:45:42,318] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:45:42,318] {logging_mixin.py:109} INFO - [2022-06-07 06:45:42,318] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:46:12,319] {logging_mixin.py:109} INFO - [2022-06-07 06:46:12,319] {timeout.py:36} ERROR - Process timed out, PID: 1093916
[2022-06-07 06:46:12,320] {logging_mixin.py:109} INFO - [2022-06-07 06:46:12,319] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1093916
[2022-06-07 06:46:12,320] {logging_mixin.py:109} INFO - [2022-06-07 06:46:12,320] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:46:12,320] {logging_mixin.py:109} INFO - [2022-06-07 06:46:12,320] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1093916

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:46:12,321] {logging_mixin.py:109} INFO - [2022-06-07 06:46:12,321] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:46:12,321] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:46:12,332] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 06:46:42,468] {processor.py:163} INFO - Started process (PID=1094991) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:46:42,469] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:46:42,469] {logging_mixin.py:109} INFO - [2022-06-07 06:46:42,469] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:47:12,473] {logging_mixin.py:109} INFO - [2022-06-07 06:47:12,472] {timeout.py:36} ERROR - Process timed out, PID: 1094991
[2022-06-07 06:47:12,473] {logging_mixin.py:109} INFO - [2022-06-07 06:47:12,473] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1094991
[2022-06-07 06:47:12,473] {logging_mixin.py:109} INFO - [2022-06-07 06:47:12,473] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:47:12,474] {logging_mixin.py:109} INFO - [2022-06-07 06:47:12,473] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1094991

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:47:12,474] {logging_mixin.py:109} INFO - [2022-06-07 06:47:12,474] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:47:12,474] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:47:12,487] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 06:47:43,188] {processor.py:163} INFO - Started process (PID=1096085) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:47:43,189] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:47:43,189] {logging_mixin.py:109} INFO - [2022-06-07 06:47:43,189] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:48:13,198] {logging_mixin.py:109} INFO - [2022-06-07 06:48:13,198] {timeout.py:36} ERROR - Process timed out, PID: 1096085
[2022-06-07 06:48:13,198] {logging_mixin.py:109} INFO - [2022-06-07 06:48:13,198] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1096085
[2022-06-07 06:48:13,199] {logging_mixin.py:109} INFO - [2022-06-07 06:48:13,199] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:48:13,199] {logging_mixin.py:109} INFO - [2022-06-07 06:48:13,199] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1096085

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:48:13,199] {logging_mixin.py:109} INFO - [2022-06-07 06:48:13,199] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:48:13,200] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:48:13,212] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 06:48:43,574] {processor.py:163} INFO - Started process (PID=1097179) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:48:43,575] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:48:43,575] {logging_mixin.py:109} INFO - [2022-06-07 06:48:43,575] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:49:13,596] {logging_mixin.py:109} INFO - [2022-06-07 06:49:13,596] {timeout.py:36} ERROR - Process timed out, PID: 1097179
[2022-06-07 06:49:13,597] {logging_mixin.py:109} INFO - [2022-06-07 06:49:13,596] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1097179
[2022-06-07 06:49:13,597] {logging_mixin.py:109} INFO - [2022-06-07 06:49:13,597] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:49:13,598] {logging_mixin.py:109} INFO - [2022-06-07 06:49:13,597] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1097179

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:49:13,598] {logging_mixin.py:109} INFO - [2022-06-07 06:49:13,598] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:49:13,598] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:49:13,611] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.038 seconds
[2022-06-07 06:49:44,207] {processor.py:163} INFO - Started process (PID=1098273) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:49:44,207] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:49:44,208] {logging_mixin.py:109} INFO - [2022-06-07 06:49:44,208] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:50:14,209] {logging_mixin.py:109} INFO - [2022-06-07 06:50:14,208] {timeout.py:36} ERROR - Process timed out, PID: 1098273
[2022-06-07 06:50:14,209] {logging_mixin.py:109} INFO - [2022-06-07 06:50:14,209] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1098273
[2022-06-07 06:50:14,209] {logging_mixin.py:109} INFO - [2022-06-07 06:50:14,209] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:50:14,210] {logging_mixin.py:109} INFO - [2022-06-07 06:50:14,209] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1098273

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:50:14,210] {logging_mixin.py:109} INFO - [2022-06-07 06:50:14,210] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:50:14,210] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:50:14,222] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 06:50:44,397] {processor.py:163} INFO - Started process (PID=1099333) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:50:44,397] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:50:44,398] {logging_mixin.py:109} INFO - [2022-06-07 06:50:44,398] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:51:14,402] {logging_mixin.py:109} INFO - [2022-06-07 06:51:14,401] {timeout.py:36} ERROR - Process timed out, PID: 1099333
[2022-06-07 06:51:14,402] {logging_mixin.py:109} INFO - [2022-06-07 06:51:14,402] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1099333
[2022-06-07 06:51:14,402] {logging_mixin.py:109} INFO - [2022-06-07 06:51:14,402] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:51:14,403] {logging_mixin.py:109} INFO - [2022-06-07 06:51:14,403] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1099333

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:51:14,403] {logging_mixin.py:109} INFO - [2022-06-07 06:51:14,403] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:51:14,403] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:51:14,415] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 06:51:45,007] {processor.py:163} INFO - Started process (PID=1100428) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:51:45,008] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:51:45,008] {logging_mixin.py:109} INFO - [2022-06-07 06:51:45,008] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:52:15,024] {logging_mixin.py:109} INFO - [2022-06-07 06:52:15,024] {timeout.py:36} ERROR - Process timed out, PID: 1100428
[2022-06-07 06:52:15,025] {logging_mixin.py:109} INFO - [2022-06-07 06:52:15,024] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1100428
[2022-06-07 06:52:15,025] {logging_mixin.py:109} INFO - [2022-06-07 06:52:15,025] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:52:15,026] {logging_mixin.py:109} INFO - [2022-06-07 06:52:15,025] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1100428

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:52:15,026] {logging_mixin.py:109} INFO - [2022-06-07 06:52:15,026] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:52:15,026] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:52:15,037] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.032 seconds
[2022-06-07 06:52:45,483] {processor.py:163} INFO - Started process (PID=1101521) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:52:45,483] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:52:45,483] {logging_mixin.py:109} INFO - [2022-06-07 06:52:45,483] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:53:15,486] {logging_mixin.py:109} INFO - [2022-06-07 06:53:15,485] {timeout.py:36} ERROR - Process timed out, PID: 1101521
[2022-06-07 06:53:15,486] {logging_mixin.py:109} INFO - [2022-06-07 06:53:15,486] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1101521
[2022-06-07 06:53:15,487] {logging_mixin.py:109} INFO - [2022-06-07 06:53:15,487] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:53:15,487] {logging_mixin.py:109} INFO - [2022-06-07 06:53:15,487] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1101521

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:53:15,487] {logging_mixin.py:109} INFO - [2022-06-07 06:53:15,487] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:53:15,488] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:53:15,500] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 06:53:45,934] {processor.py:163} INFO - Started process (PID=1102614) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:53:45,934] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:53:45,935] {logging_mixin.py:109} INFO - [2022-06-07 06:53:45,935] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:54:15,938] {logging_mixin.py:109} INFO - [2022-06-07 06:54:15,938] {timeout.py:36} ERROR - Process timed out, PID: 1102614
[2022-06-07 06:54:15,938] {logging_mixin.py:109} INFO - [2022-06-07 06:54:15,938] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1102614
[2022-06-07 06:54:15,939] {logging_mixin.py:109} INFO - [2022-06-07 06:54:15,939] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:54:15,939] {logging_mixin.py:109} INFO - [2022-06-07 06:54:15,939] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1102614

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:54:15,939] {logging_mixin.py:109} INFO - [2022-06-07 06:54:15,939] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:54:15,940] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:54:15,951] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 06:54:46,532] {processor.py:163} INFO - Started process (PID=1103707) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:54:46,533] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:54:46,533] {logging_mixin.py:109} INFO - [2022-06-07 06:54:46,533] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:55:16,535] {logging_mixin.py:109} INFO - [2022-06-07 06:55:16,534] {timeout.py:36} ERROR - Process timed out, PID: 1103707
[2022-06-07 06:55:16,535] {logging_mixin.py:109} INFO - [2022-06-07 06:55:16,535] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1103707
[2022-06-07 06:55:16,535] {logging_mixin.py:109} INFO - [2022-06-07 06:55:16,535] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:55:16,536] {logging_mixin.py:109} INFO - [2022-06-07 06:55:16,536] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1103707

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:55:16,536] {logging_mixin.py:109} INFO - [2022-06-07 06:55:16,536] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:55:16,537] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:55:16,547] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 06:55:46,886] {processor.py:163} INFO - Started process (PID=1104800) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:55:46,887] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:55:46,887] {logging_mixin.py:109} INFO - [2022-06-07 06:55:46,887] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:56:16,890] {logging_mixin.py:109} INFO - [2022-06-07 06:56:16,890] {timeout.py:36} ERROR - Process timed out, PID: 1104800
[2022-06-07 06:56:16,891] {logging_mixin.py:109} INFO - [2022-06-07 06:56:16,890] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1104800
[2022-06-07 06:56:16,891] {logging_mixin.py:109} INFO - [2022-06-07 06:56:16,891] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:56:16,891] {logging_mixin.py:109} INFO - [2022-06-07 06:56:16,891] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1104800

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:56:16,892] {logging_mixin.py:109} INFO - [2022-06-07 06:56:16,891] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:56:16,892] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:56:16,904] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 06:56:47,112] {processor.py:163} INFO - Started process (PID=1105893) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:56:47,112] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:56:47,113] {logging_mixin.py:109} INFO - [2022-06-07 06:56:47,113] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:57:17,116] {logging_mixin.py:109} INFO - [2022-06-07 06:57:17,116] {timeout.py:36} ERROR - Process timed out, PID: 1105893
[2022-06-07 06:57:17,117] {logging_mixin.py:109} INFO - [2022-06-07 06:57:17,116] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1105893
[2022-06-07 06:57:17,117] {logging_mixin.py:109} INFO - [2022-06-07 06:57:17,117] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:57:17,117] {logging_mixin.py:109} INFO - [2022-06-07 06:57:17,117] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1105893

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:57:17,118] {logging_mixin.py:109} INFO - [2022-06-07 06:57:17,117] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:57:17,118] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:57:17,130] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 06:57:47,235] {processor.py:163} INFO - Started process (PID=1106987) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:57:47,236] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:57:47,236] {logging_mixin.py:109} INFO - [2022-06-07 06:57:47,236] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:58:17,240] {logging_mixin.py:109} INFO - [2022-06-07 06:58:17,240] {timeout.py:36} ERROR - Process timed out, PID: 1106987
[2022-06-07 06:58:17,241] {logging_mixin.py:109} INFO - [2022-06-07 06:58:17,240] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1106987
[2022-06-07 06:58:17,241] {logging_mixin.py:109} INFO - [2022-06-07 06:58:17,241] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:58:17,241] {logging_mixin.py:109} INFO - [2022-06-07 06:58:17,241] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1106987

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:58:17,242] {logging_mixin.py:109} INFO - [2022-06-07 06:58:17,241] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:58:17,242] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:58:17,253] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 06:58:47,597] {processor.py:163} INFO - Started process (PID=1108081) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:58:47,598] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:58:47,598] {logging_mixin.py:109} INFO - [2022-06-07 06:58:47,598] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:59:17,600] {logging_mixin.py:109} INFO - [2022-06-07 06:59:17,599] {timeout.py:36} ERROR - Process timed out, PID: 1108081
[2022-06-07 06:59:17,600] {logging_mixin.py:109} INFO - [2022-06-07 06:59:17,600] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1108081
[2022-06-07 06:59:17,600] {logging_mixin.py:109} INFO - [2022-06-07 06:59:17,600] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 06:59:17,601] {logging_mixin.py:109} INFO - [2022-06-07 06:59:17,601] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1108081

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 06:59:17,601] {logging_mixin.py:109} INFO - [2022-06-07 06:59:17,601] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 06:59:17,602] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 06:59:17,613] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 06:59:47,920] {processor.py:163} INFO - Started process (PID=1109176) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 06:59:47,920] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 06:59:47,920] {logging_mixin.py:109} INFO - [2022-06-07 06:59:47,920] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:00:17,921] {logging_mixin.py:109} INFO - [2022-06-07 07:00:17,921] {timeout.py:36} ERROR - Process timed out, PID: 1109176
[2022-06-07 07:00:17,922] {logging_mixin.py:109} INFO - [2022-06-07 07:00:17,921] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1109176
[2022-06-07 07:00:17,922] {logging_mixin.py:109} INFO - [2022-06-07 07:00:17,922] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:00:17,922] {logging_mixin.py:109} INFO - [2022-06-07 07:00:17,922] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1109176

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:00:17,923] {logging_mixin.py:109} INFO - [2022-06-07 07:00:17,922] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:00:17,923] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:00:17,934] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.015 seconds
[2022-06-07 07:00:48,001] {processor.py:163} INFO - Started process (PID=1110269) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:00:48,001] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:00:48,002] {logging_mixin.py:109} INFO - [2022-06-07 07:00:48,001] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:01:18,003] {logging_mixin.py:109} INFO - [2022-06-07 07:01:18,002] {timeout.py:36} ERROR - Process timed out, PID: 1110269
[2022-06-07 07:01:18,003] {logging_mixin.py:109} INFO - [2022-06-07 07:01:18,003] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1110269
[2022-06-07 07:01:18,003] {logging_mixin.py:109} INFO - [2022-06-07 07:01:18,003] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:01:18,004] {logging_mixin.py:109} INFO - [2022-06-07 07:01:18,004] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1110269

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:01:18,004] {logging_mixin.py:109} INFO - [2022-06-07 07:01:18,004] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:01:18,005] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:01:18,016] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:01:48,327] {processor.py:163} INFO - Started process (PID=1111358) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:01:48,328] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:01:48,328] {logging_mixin.py:109} INFO - [2022-06-07 07:01:48,328] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:02:18,330] {logging_mixin.py:109} INFO - [2022-06-07 07:02:18,329] {timeout.py:36} ERROR - Process timed out, PID: 1111358
[2022-06-07 07:02:18,330] {logging_mixin.py:109} INFO - [2022-06-07 07:02:18,330] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1111358
[2022-06-07 07:02:18,330] {logging_mixin.py:109} INFO - [2022-06-07 07:02:18,330] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:02:18,331] {logging_mixin.py:109} INFO - [2022-06-07 07:02:18,330] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1111358

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:02:18,331] {logging_mixin.py:109} INFO - [2022-06-07 07:02:18,331] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:02:18,331] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:02:18,343] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:02:48,978] {processor.py:163} INFO - Started process (PID=1112451) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:02:48,979] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:02:48,979] {logging_mixin.py:109} INFO - [2022-06-07 07:02:48,979] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:03:18,981] {logging_mixin.py:109} INFO - [2022-06-07 07:03:18,980] {timeout.py:36} ERROR - Process timed out, PID: 1112451
[2022-06-07 07:03:18,981] {logging_mixin.py:109} INFO - [2022-06-07 07:03:18,981] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1112451
[2022-06-07 07:03:18,981] {logging_mixin.py:109} INFO - [2022-06-07 07:03:18,981] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:03:18,982] {logging_mixin.py:109} INFO - [2022-06-07 07:03:18,982] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1112451

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:03:18,982] {logging_mixin.py:109} INFO - [2022-06-07 07:03:18,982] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:03:18,983] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:03:18,994] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:03:49,292] {processor.py:163} INFO - Started process (PID=1113546) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:03:49,292] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:03:49,292] {logging_mixin.py:109} INFO - [2022-06-07 07:03:49,292] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:04:19,294] {logging_mixin.py:109} INFO - [2022-06-07 07:04:19,294] {timeout.py:36} ERROR - Process timed out, PID: 1113546
[2022-06-07 07:04:19,295] {logging_mixin.py:109} INFO - [2022-06-07 07:04:19,294] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1113546
[2022-06-07 07:04:19,295] {logging_mixin.py:109} INFO - [2022-06-07 07:04:19,295] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:04:19,295] {logging_mixin.py:109} INFO - [2022-06-07 07:04:19,295] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1113546

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:04:19,296] {logging_mixin.py:109} INFO - [2022-06-07 07:04:19,295] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:04:19,296] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:04:19,307] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:04:49,328] {processor.py:163} INFO - Started process (PID=1114629) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:04:49,328] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:04:49,329] {logging_mixin.py:109} INFO - [2022-06-07 07:04:49,329] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:05:19,331] {logging_mixin.py:109} INFO - [2022-06-07 07:05:19,330] {timeout.py:36} ERROR - Process timed out, PID: 1114629
[2022-06-07 07:05:19,331] {logging_mixin.py:109} INFO - [2022-06-07 07:05:19,331] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1114629
[2022-06-07 07:05:19,332] {logging_mixin.py:109} INFO - [2022-06-07 07:05:19,331] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:05:19,332] {logging_mixin.py:109} INFO - [2022-06-07 07:05:19,332] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1114629

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:05:19,332] {logging_mixin.py:109} INFO - [2022-06-07 07:05:19,332] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:05:19,333] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:05:19,343] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:05:49,755] {processor.py:163} INFO - Started process (PID=1115724) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:05:49,755] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:05:49,755] {logging_mixin.py:109} INFO - [2022-06-07 07:05:49,755] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:06:19,757] {logging_mixin.py:109} INFO - [2022-06-07 07:06:19,757] {timeout.py:36} ERROR - Process timed out, PID: 1115724
[2022-06-07 07:06:19,758] {logging_mixin.py:109} INFO - [2022-06-07 07:06:19,757] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1115724
[2022-06-07 07:06:19,758] {logging_mixin.py:109} INFO - [2022-06-07 07:06:19,758] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:06:19,759] {logging_mixin.py:109} INFO - [2022-06-07 07:06:19,758] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1115724

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:06:19,759] {logging_mixin.py:109} INFO - [2022-06-07 07:06:19,759] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:06:19,759] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:06:19,771] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:06:50,004] {processor.py:163} INFO - Started process (PID=1116819) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:06:50,004] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:06:50,004] {logging_mixin.py:109} INFO - [2022-06-07 07:06:50,004] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:07:20,010] {logging_mixin.py:109} INFO - [2022-06-07 07:07:20,010] {timeout.py:36} ERROR - Process timed out, PID: 1116819
[2022-06-07 07:07:20,011] {logging_mixin.py:109} INFO - [2022-06-07 07:07:20,010] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1116819
[2022-06-07 07:07:20,011] {logging_mixin.py:109} INFO - [2022-06-07 07:07:20,011] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:07:20,012] {logging_mixin.py:109} INFO - [2022-06-07 07:07:20,011] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1116819

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:07:20,012] {logging_mixin.py:109} INFO - [2022-06-07 07:07:20,012] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:07:20,012] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:07:20,024] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 07:07:50,325] {processor.py:163} INFO - Started process (PID=1117912) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:07:50,325] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:07:50,326] {logging_mixin.py:109} INFO - [2022-06-07 07:07:50,326] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:08:20,327] {logging_mixin.py:109} INFO - [2022-06-07 07:08:20,326] {timeout.py:36} ERROR - Process timed out, PID: 1117912
[2022-06-07 07:08:20,327] {logging_mixin.py:109} INFO - [2022-06-07 07:08:20,327] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1117912
[2022-06-07 07:08:20,327] {logging_mixin.py:109} INFO - [2022-06-07 07:08:20,327] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:08:20,328] {logging_mixin.py:109} INFO - [2022-06-07 07:08:20,328] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1117912

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:08:20,328] {logging_mixin.py:109} INFO - [2022-06-07 07:08:20,328] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:08:20,329] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:08:20,341] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:08:51,276] {processor.py:163} INFO - Started process (PID=1119007) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:08:51,277] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:08:51,278] {logging_mixin.py:109} INFO - [2022-06-07 07:08:51,277] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:09:21,295] {logging_mixin.py:109} INFO - [2022-06-07 07:09:21,295] {timeout.py:36} ERROR - Process timed out, PID: 1119007
[2022-06-07 07:09:21,296] {logging_mixin.py:109} INFO - [2022-06-07 07:09:21,295] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1119007
[2022-06-07 07:09:21,296] {logging_mixin.py:109} INFO - [2022-06-07 07:09:21,296] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:09:21,296] {logging_mixin.py:109} INFO - [2022-06-07 07:09:21,296] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1119007

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:09:21,297] {logging_mixin.py:109} INFO - [2022-06-07 07:09:21,296] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:09:21,297] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:09:21,309] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.034 seconds
[2022-06-07 07:09:51,455] {processor.py:163} INFO - Started process (PID=1120100) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:09:51,456] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:09:51,456] {logging_mixin.py:109} INFO - [2022-06-07 07:09:51,456] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:10:21,457] {logging_mixin.py:109} INFO - [2022-06-07 07:10:21,456] {timeout.py:36} ERROR - Process timed out, PID: 1120100
[2022-06-07 07:10:21,457] {logging_mixin.py:109} INFO - [2022-06-07 07:10:21,457] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1120100
[2022-06-07 07:10:21,458] {logging_mixin.py:109} INFO - [2022-06-07 07:10:21,458] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:10:21,458] {logging_mixin.py:109} INFO - [2022-06-07 07:10:21,458] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1120100

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:10:21,458] {logging_mixin.py:109} INFO - [2022-06-07 07:10:21,458] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:10:21,459] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:10:21,470] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:10:52,120] {processor.py:163} INFO - Started process (PID=1121146) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:10:52,121] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:10:52,121] {logging_mixin.py:109} INFO - [2022-06-07 07:10:52,121] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:11:22,128] {logging_mixin.py:109} INFO - [2022-06-07 07:11:22,127] {timeout.py:36} ERROR - Process timed out, PID: 1121146
[2022-06-07 07:11:22,128] {logging_mixin.py:109} INFO - [2022-06-07 07:11:22,128] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1121146
[2022-06-07 07:11:22,128] {logging_mixin.py:109} INFO - [2022-06-07 07:11:22,128] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:11:22,129] {logging_mixin.py:109} INFO - [2022-06-07 07:11:22,129] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1121146

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:11:22,129] {logging_mixin.py:109} INFO - [2022-06-07 07:11:22,129] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:11:22,129] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:11:22,145] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 07:11:52,348] {processor.py:163} INFO - Started process (PID=1122239) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:11:52,348] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:11:52,348] {logging_mixin.py:109} INFO - [2022-06-07 07:11:52,348] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:12:22,350] {logging_mixin.py:109} INFO - [2022-06-07 07:12:22,350] {timeout.py:36} ERROR - Process timed out, PID: 1122239
[2022-06-07 07:12:22,351] {logging_mixin.py:109} INFO - [2022-06-07 07:12:22,350] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1122239
[2022-06-07 07:12:22,351] {logging_mixin.py:109} INFO - [2022-06-07 07:12:22,351] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:12:22,351] {logging_mixin.py:109} INFO - [2022-06-07 07:12:22,351] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1122239

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:12:22,352] {logging_mixin.py:109} INFO - [2022-06-07 07:12:22,351] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:12:22,352] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:12:22,363] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:12:52,783] {processor.py:163} INFO - Started process (PID=1123332) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:12:52,784] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:12:52,784] {logging_mixin.py:109} INFO - [2022-06-07 07:12:52,784] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:13:22,786] {logging_mixin.py:109} INFO - [2022-06-07 07:13:22,786] {timeout.py:36} ERROR - Process timed out, PID: 1123332
[2022-06-07 07:13:22,787] {logging_mixin.py:109} INFO - [2022-06-07 07:13:22,787] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1123332
[2022-06-07 07:13:22,787] {logging_mixin.py:109} INFO - [2022-06-07 07:13:22,787] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:13:22,788] {logging_mixin.py:109} INFO - [2022-06-07 07:13:22,787] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1123332

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:13:22,788] {logging_mixin.py:109} INFO - [2022-06-07 07:13:22,788] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:13:22,788] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:13:22,800] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:13:52,935] {processor.py:163} INFO - Started process (PID=1124426) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:13:52,936] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:13:52,936] {logging_mixin.py:109} INFO - [2022-06-07 07:13:52,936] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:14:22,941] {logging_mixin.py:109} INFO - [2022-06-07 07:14:22,940] {timeout.py:36} ERROR - Process timed out, PID: 1124426
[2022-06-07 07:14:22,941] {logging_mixin.py:109} INFO - [2022-06-07 07:14:22,941] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1124426
[2022-06-07 07:14:22,941] {logging_mixin.py:109} INFO - [2022-06-07 07:14:22,941] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:14:22,942] {logging_mixin.py:109} INFO - [2022-06-07 07:14:22,942] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1124426

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:14:22,942] {logging_mixin.py:109} INFO - [2022-06-07 07:14:22,942] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:14:22,942] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:14:22,954] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 07:14:53,207] {processor.py:163} INFO - Started process (PID=1125509) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:14:53,207] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:14:53,207] {logging_mixin.py:109} INFO - [2022-06-07 07:14:53,207] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:15:23,208] {logging_mixin.py:109} INFO - [2022-06-07 07:15:23,208] {timeout.py:36} ERROR - Process timed out, PID: 1125509
[2022-06-07 07:15:23,209] {logging_mixin.py:109} INFO - [2022-06-07 07:15:23,209] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1125509
[2022-06-07 07:15:23,209] {logging_mixin.py:109} INFO - [2022-06-07 07:15:23,209] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:15:23,210] {logging_mixin.py:109} INFO - [2022-06-07 07:15:23,209] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1125509

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:15:23,210] {logging_mixin.py:109} INFO - [2022-06-07 07:15:23,210] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:15:23,210] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:15:23,223] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 07:15:54,107] {processor.py:163} INFO - Started process (PID=1126603) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:15:54,107] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:15:54,107] {logging_mixin.py:109} INFO - [2022-06-07 07:15:54,107] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:16:24,108] {logging_mixin.py:109} INFO - [2022-06-07 07:16:24,108] {timeout.py:36} ERROR - Process timed out, PID: 1126603
[2022-06-07 07:16:24,109] {logging_mixin.py:109} INFO - [2022-06-07 07:16:24,108] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1126603
[2022-06-07 07:16:24,109] {logging_mixin.py:109} INFO - [2022-06-07 07:16:24,109] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:16:24,110] {logging_mixin.py:109} INFO - [2022-06-07 07:16:24,109] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1126603

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:16:24,110] {logging_mixin.py:109} INFO - [2022-06-07 07:16:24,110] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:16:24,110] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:16:24,122] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:16:54,208] {processor.py:163} INFO - Started process (PID=1127688) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:16:54,209] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:16:54,209] {logging_mixin.py:109} INFO - [2022-06-07 07:16:54,209] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:17:24,215] {logging_mixin.py:109} INFO - [2022-06-07 07:17:24,215] {timeout.py:36} ERROR - Process timed out, PID: 1127688
[2022-06-07 07:17:24,216] {logging_mixin.py:109} INFO - [2022-06-07 07:17:24,215] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1127688
[2022-06-07 07:17:24,216] {logging_mixin.py:109} INFO - [2022-06-07 07:17:24,216] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:17:24,216] {logging_mixin.py:109} INFO - [2022-06-07 07:17:24,216] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1127688

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:17:24,217] {logging_mixin.py:109} INFO - [2022-06-07 07:17:24,216] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:17:24,217] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:17:24,228] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 07:17:54,637] {processor.py:163} INFO - Started process (PID=1128785) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:17:54,638] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:17:54,638] {logging_mixin.py:109} INFO - [2022-06-07 07:17:54,638] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:18:24,647] {logging_mixin.py:109} INFO - [2022-06-07 07:18:24,646] {timeout.py:36} ERROR - Process timed out, PID: 1128785
[2022-06-07 07:18:24,647] {logging_mixin.py:109} INFO - [2022-06-07 07:18:24,647] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1128785
[2022-06-07 07:18:24,647] {logging_mixin.py:109} INFO - [2022-06-07 07:18:24,647] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:18:24,648] {logging_mixin.py:109} INFO - [2022-06-07 07:18:24,648] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1128785

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:18:24,648] {logging_mixin.py:109} INFO - [2022-06-07 07:18:24,648] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:18:24,649] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:18:24,660] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 07:18:54,722] {processor.py:163} INFO - Started process (PID=1129879) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:18:54,723] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:18:54,723] {logging_mixin.py:109} INFO - [2022-06-07 07:18:54,723] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:19:24,732] {logging_mixin.py:109} INFO - [2022-06-07 07:19:24,731] {timeout.py:36} ERROR - Process timed out, PID: 1129879
[2022-06-07 07:19:24,732] {logging_mixin.py:109} INFO - [2022-06-07 07:19:24,732] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1129879
[2022-06-07 07:19:24,732] {logging_mixin.py:109} INFO - [2022-06-07 07:19:24,732] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:19:24,733] {logging_mixin.py:109} INFO - [2022-06-07 07:19:24,733] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1129879

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:19:24,733] {logging_mixin.py:109} INFO - [2022-06-07 07:19:24,733] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:19:24,734] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:19:24,745] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 07:19:55,154] {processor.py:163} INFO - Started process (PID=1130953) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:19:55,154] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:19:55,154] {logging_mixin.py:109} INFO - [2022-06-07 07:19:55,154] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:20:25,156] {logging_mixin.py:109} INFO - [2022-06-07 07:20:25,155] {timeout.py:36} ERROR - Process timed out, PID: 1130953
[2022-06-07 07:20:25,156] {logging_mixin.py:109} INFO - [2022-06-07 07:20:25,156] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1130953
[2022-06-07 07:20:25,156] {logging_mixin.py:109} INFO - [2022-06-07 07:20:25,156] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:20:25,157] {logging_mixin.py:109} INFO - [2022-06-07 07:20:25,157] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1130953

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:20:25,157] {logging_mixin.py:109} INFO - [2022-06-07 07:20:25,157] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:20:25,158] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:20:25,169] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:20:55,405] {processor.py:163} INFO - Started process (PID=1132046) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:20:55,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:20:55,406] {logging_mixin.py:109} INFO - [2022-06-07 07:20:55,406] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:21:25,420] {logging_mixin.py:109} INFO - [2022-06-07 07:21:25,420] {timeout.py:36} ERROR - Process timed out, PID: 1132046
[2022-06-07 07:21:25,421] {logging_mixin.py:109} INFO - [2022-06-07 07:21:25,420] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1132046
[2022-06-07 07:21:25,421] {logging_mixin.py:109} INFO - [2022-06-07 07:21:25,421] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:21:25,421] {logging_mixin.py:109} INFO - [2022-06-07 07:21:25,421] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1132046

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:21:25,422] {logging_mixin.py:109} INFO - [2022-06-07 07:21:25,422] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:21:25,422] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:21:25,434] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.030 seconds
[2022-06-07 07:21:55,475] {processor.py:163} INFO - Started process (PID=1133137) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:21:55,475] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:21:55,475] {logging_mixin.py:109} INFO - [2022-06-07 07:21:55,475] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:22:25,476] {logging_mixin.py:109} INFO - [2022-06-07 07:22:25,476] {timeout.py:36} ERROR - Process timed out, PID: 1133137
[2022-06-07 07:22:25,477] {logging_mixin.py:109} INFO - [2022-06-07 07:22:25,477] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1133137
[2022-06-07 07:22:25,477] {logging_mixin.py:109} INFO - [2022-06-07 07:22:25,477] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:22:25,478] {logging_mixin.py:109} INFO - [2022-06-07 07:22:25,477] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1133137

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:22:25,478] {logging_mixin.py:109} INFO - [2022-06-07 07:22:25,478] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:22:25,478] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:22:25,489] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 07:22:55,586] {processor.py:163} INFO - Started process (PID=1134220) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:22:55,586] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:22:55,587] {logging_mixin.py:109} INFO - [2022-06-07 07:22:55,587] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:23:25,590] {logging_mixin.py:109} INFO - [2022-06-07 07:23:25,590] {timeout.py:36} ERROR - Process timed out, PID: 1134220
[2022-06-07 07:23:25,590] {logging_mixin.py:109} INFO - [2022-06-07 07:23:25,590] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1134220
[2022-06-07 07:23:25,591] {logging_mixin.py:109} INFO - [2022-06-07 07:23:25,591] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:23:25,591] {logging_mixin.py:109} INFO - [2022-06-07 07:23:25,591] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1134220

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:23:25,591] {logging_mixin.py:109} INFO - [2022-06-07 07:23:25,591] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:23:25,592] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:23:25,603] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 07:23:56,566] {processor.py:163} INFO - Started process (PID=1135314) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:23:56,566] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:23:56,567] {logging_mixin.py:109} INFO - [2022-06-07 07:23:56,567] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:24:26,572] {logging_mixin.py:109} INFO - [2022-06-07 07:24:26,572] {timeout.py:36} ERROR - Process timed out, PID: 1135314
[2022-06-07 07:24:26,573] {logging_mixin.py:109} INFO - [2022-06-07 07:24:26,572] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1135314
[2022-06-07 07:24:26,573] {logging_mixin.py:109} INFO - [2022-06-07 07:24:26,573] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:24:26,574] {logging_mixin.py:109} INFO - [2022-06-07 07:24:26,573] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1135314

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:24:26,574] {logging_mixin.py:109} INFO - [2022-06-07 07:24:26,574] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:24:26,574] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:24:26,587] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 07:24:57,339] {processor.py:163} INFO - Started process (PID=1136408) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:24:57,340] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:24:57,340] {logging_mixin.py:109} INFO - [2022-06-07 07:24:57,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:25:27,342] {logging_mixin.py:109} INFO - [2022-06-07 07:25:27,342] {timeout.py:36} ERROR - Process timed out, PID: 1136408
[2022-06-07 07:25:27,343] {logging_mixin.py:109} INFO - [2022-06-07 07:25:27,342] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1136408
[2022-06-07 07:25:27,343] {logging_mixin.py:109} INFO - [2022-06-07 07:25:27,343] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:25:27,343] {logging_mixin.py:109} INFO - [2022-06-07 07:25:27,343] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1136408

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:25:27,343] {logging_mixin.py:109} INFO - [2022-06-07 07:25:27,343] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:25:27,344] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:25:27,355] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:25:58,040] {processor.py:163} INFO - Started process (PID=1137502) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:25:58,041] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:25:58,041] {logging_mixin.py:109} INFO - [2022-06-07 07:25:58,041] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:26:28,043] {logging_mixin.py:109} INFO - [2022-06-07 07:26:28,042] {timeout.py:36} ERROR - Process timed out, PID: 1137502
[2022-06-07 07:26:28,043] {logging_mixin.py:109} INFO - [2022-06-07 07:26:28,043] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1137502
[2022-06-07 07:26:28,043] {logging_mixin.py:109} INFO - [2022-06-07 07:26:28,043] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:26:28,044] {logging_mixin.py:109} INFO - [2022-06-07 07:26:28,044] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1137502

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:26:28,044] {logging_mixin.py:109} INFO - [2022-06-07 07:26:28,044] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:26:28,045] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:26:28,057] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:26:58,863] {processor.py:163} INFO - Started process (PID=1138597) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:26:58,864] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:26:58,864] {logging_mixin.py:109} INFO - [2022-06-07 07:26:58,864] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:27:28,865] {logging_mixin.py:109} INFO - [2022-06-07 07:27:28,865] {timeout.py:36} ERROR - Process timed out, PID: 1138597
[2022-06-07 07:27:28,866] {logging_mixin.py:109} INFO - [2022-06-07 07:27:28,865] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1138597
[2022-06-07 07:27:28,866] {logging_mixin.py:109} INFO - [2022-06-07 07:27:28,866] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:27:28,866] {logging_mixin.py:109} INFO - [2022-06-07 07:27:28,866] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1138597

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:27:28,867] {logging_mixin.py:109} INFO - [2022-06-07 07:27:28,866] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:27:28,867] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:27:28,879] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:27:59,628] {processor.py:163} INFO - Started process (PID=1139691) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:27:59,628] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:27:59,629] {logging_mixin.py:109} INFO - [2022-06-07 07:27:59,629] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:28:29,630] {logging_mixin.py:109} INFO - [2022-06-07 07:28:29,630] {timeout.py:36} ERROR - Process timed out, PID: 1139691
[2022-06-07 07:28:29,631] {logging_mixin.py:109} INFO - [2022-06-07 07:28:29,631] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1139691
[2022-06-07 07:28:29,631] {logging_mixin.py:109} INFO - [2022-06-07 07:28:29,631] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:28:29,632] {logging_mixin.py:109} INFO - [2022-06-07 07:28:29,631] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1139691

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:28:29,632] {logging_mixin.py:109} INFO - [2022-06-07 07:28:29,632] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:28:29,632] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:28:29,644] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:29:00,449] {processor.py:163} INFO - Started process (PID=1140785) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:29:00,450] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:29:00,450] {logging_mixin.py:109} INFO - [2022-06-07 07:29:00,450] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:29:30,454] {logging_mixin.py:109} INFO - [2022-06-07 07:29:30,453] {timeout.py:36} ERROR - Process timed out, PID: 1140785
[2022-06-07 07:29:30,455] {logging_mixin.py:109} INFO - [2022-06-07 07:29:30,455] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1140785
[2022-06-07 07:29:30,455] {logging_mixin.py:109} INFO - [2022-06-07 07:29:30,455] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:29:30,456] {logging_mixin.py:109} INFO - [2022-06-07 07:29:30,455] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1140785

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:29:30,456] {logging_mixin.py:109} INFO - [2022-06-07 07:29:30,456] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:29:30,456] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:29:30,468] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 07:30:01,211] {processor.py:163} INFO - Started process (PID=1141878) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:30:01,212] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:30:01,212] {logging_mixin.py:109} INFO - [2022-06-07 07:30:01,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:30:31,215] {logging_mixin.py:109} INFO - [2022-06-07 07:30:31,215] {timeout.py:36} ERROR - Process timed out, PID: 1141878
[2022-06-07 07:30:31,216] {logging_mixin.py:109} INFO - [2022-06-07 07:30:31,215] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1141878
[2022-06-07 07:30:31,216] {logging_mixin.py:109} INFO - [2022-06-07 07:30:31,216] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:30:31,217] {logging_mixin.py:109} INFO - [2022-06-07 07:30:31,216] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1141878

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:30:31,217] {logging_mixin.py:109} INFO - [2022-06-07 07:30:31,217] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:30:31,217] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:30:31,229] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 07:31:01,961] {processor.py:163} INFO - Started process (PID=1142972) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:31:01,961] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:31:01,961] {logging_mixin.py:109} INFO - [2022-06-07 07:31:01,961] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:31:31,962] {logging_mixin.py:109} INFO - [2022-06-07 07:31:31,962] {timeout.py:36} ERROR - Process timed out, PID: 1142972
[2022-06-07 07:31:31,963] {logging_mixin.py:109} INFO - [2022-06-07 07:31:31,963] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1142972
[2022-06-07 07:31:31,963] {logging_mixin.py:109} INFO - [2022-06-07 07:31:31,963] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:31:31,964] {logging_mixin.py:109} INFO - [2022-06-07 07:31:31,963] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1142972

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:31:31,964] {logging_mixin.py:109} INFO - [2022-06-07 07:31:31,964] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:31:31,964] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:31:31,975] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 07:32:02,713] {processor.py:163} INFO - Started process (PID=1144067) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:32:02,714] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:32:02,714] {logging_mixin.py:109} INFO - [2022-06-07 07:32:02,714] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:32:32,715] {logging_mixin.py:109} INFO - [2022-06-07 07:32:32,715] {timeout.py:36} ERROR - Process timed out, PID: 1144067
[2022-06-07 07:32:32,716] {logging_mixin.py:109} INFO - [2022-06-07 07:32:32,715] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1144067
[2022-06-07 07:32:32,716] {logging_mixin.py:109} INFO - [2022-06-07 07:32:32,716] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:32:32,716] {logging_mixin.py:109} INFO - [2022-06-07 07:32:32,716] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1144067

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:32:32,717] {logging_mixin.py:109} INFO - [2022-06-07 07:32:32,716] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:32:32,717] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:32:32,728] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 07:33:03,531] {processor.py:163} INFO - Started process (PID=1145160) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:33:03,531] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:33:03,532] {logging_mixin.py:109} INFO - [2022-06-07 07:33:03,532] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:33:33,533] {logging_mixin.py:109} INFO - [2022-06-07 07:33:33,532] {timeout.py:36} ERROR - Process timed out, PID: 1145160
[2022-06-07 07:33:33,533] {logging_mixin.py:109} INFO - [2022-06-07 07:33:33,533] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1145160
[2022-06-07 07:33:33,533] {logging_mixin.py:109} INFO - [2022-06-07 07:33:33,533] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:33:33,534] {logging_mixin.py:109} INFO - [2022-06-07 07:33:33,534] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1145160

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:33:33,534] {logging_mixin.py:109} INFO - [2022-06-07 07:33:33,534] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:33:33,535] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:33:33,546] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:34:04,147] {processor.py:163} INFO - Started process (PID=1146254) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:34:04,148] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:34:04,148] {logging_mixin.py:109} INFO - [2022-06-07 07:34:04,148] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:34:34,165] {logging_mixin.py:109} INFO - [2022-06-07 07:34:34,164] {timeout.py:36} ERROR - Process timed out, PID: 1146254
[2022-06-07 07:34:34,165] {logging_mixin.py:109} INFO - [2022-06-07 07:34:34,165] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1146254
[2022-06-07 07:34:34,165] {logging_mixin.py:109} INFO - [2022-06-07 07:34:34,165] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:34:34,166] {logging_mixin.py:109} INFO - [2022-06-07 07:34:34,165] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1146254

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:34:34,166] {logging_mixin.py:109} INFO - [2022-06-07 07:34:34,166] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:34:34,167] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:34:34,178] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.032 seconds
[2022-06-07 07:35:04,329] {processor.py:163} INFO - Started process (PID=1147347) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:35:04,330] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:35:04,330] {logging_mixin.py:109} INFO - [2022-06-07 07:35:04,330] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:35:34,334] {logging_mixin.py:109} INFO - [2022-06-07 07:35:34,334] {timeout.py:36} ERROR - Process timed out, PID: 1147347
[2022-06-07 07:35:34,335] {logging_mixin.py:109} INFO - [2022-06-07 07:35:34,334] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1147347
[2022-06-07 07:35:34,335] {logging_mixin.py:109} INFO - [2022-06-07 07:35:34,335] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:35:34,335] {logging_mixin.py:109} INFO - [2022-06-07 07:35:34,335] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1147347

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:35:34,335] {logging_mixin.py:109} INFO - [2022-06-07 07:35:34,335] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:35:34,336] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:35:34,347] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 07:36:04,411] {processor.py:163} INFO - Started process (PID=1148430) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:36:04,411] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:36:04,411] {logging_mixin.py:109} INFO - [2022-06-07 07:36:04,411] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:36:34,413] {logging_mixin.py:109} INFO - [2022-06-07 07:36:34,412] {timeout.py:36} ERROR - Process timed out, PID: 1148430
[2022-06-07 07:36:34,413] {logging_mixin.py:109} INFO - [2022-06-07 07:36:34,413] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1148430
[2022-06-07 07:36:34,414] {logging_mixin.py:109} INFO - [2022-06-07 07:36:34,414] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:36:34,414] {logging_mixin.py:109} INFO - [2022-06-07 07:36:34,414] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1148430

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:36:34,414] {logging_mixin.py:109} INFO - [2022-06-07 07:36:34,414] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:36:34,415] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:36:34,427] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:37:04,465] {processor.py:163} INFO - Started process (PID=1149504) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:37:04,466] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:37:04,466] {logging_mixin.py:109} INFO - [2022-06-07 07:37:04,466] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:37:34,468] {logging_mixin.py:109} INFO - [2022-06-07 07:37:34,467] {timeout.py:36} ERROR - Process timed out, PID: 1149504
[2022-06-07 07:37:34,468] {logging_mixin.py:109} INFO - [2022-06-07 07:37:34,468] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1149504
[2022-06-07 07:37:34,468] {logging_mixin.py:109} INFO - [2022-06-07 07:37:34,468] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:37:34,469] {logging_mixin.py:109} INFO - [2022-06-07 07:37:34,469] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1149504

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:37:34,469] {logging_mixin.py:109} INFO - [2022-06-07 07:37:34,469] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:37:34,470] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:37:34,481] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:38:04,503] {processor.py:163} INFO - Started process (PID=1150598) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:38:04,503] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:38:04,503] {logging_mixin.py:109} INFO - [2022-06-07 07:38:04,503] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:38:34,505] {logging_mixin.py:109} INFO - [2022-06-07 07:38:34,504] {timeout.py:36} ERROR - Process timed out, PID: 1150598
[2022-06-07 07:38:34,506] {logging_mixin.py:109} INFO - [2022-06-07 07:38:34,505] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1150598
[2022-06-07 07:38:34,506] {logging_mixin.py:109} INFO - [2022-06-07 07:38:34,506] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:38:34,506] {logging_mixin.py:109} INFO - [2022-06-07 07:38:34,506] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1150598

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:38:34,507] {logging_mixin.py:109} INFO - [2022-06-07 07:38:34,507] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:38:34,507] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:38:34,520] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 07:39:04,534] {processor.py:163} INFO - Started process (PID=1151692) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:39:04,535] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:39:04,535] {logging_mixin.py:109} INFO - [2022-06-07 07:39:04,535] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:39:34,536] {logging_mixin.py:109} INFO - [2022-06-07 07:39:34,536] {timeout.py:36} ERROR - Process timed out, PID: 1151692
[2022-06-07 07:39:34,536] {logging_mixin.py:109} INFO - [2022-06-07 07:39:34,536] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1151692
[2022-06-07 07:39:34,536] {logging_mixin.py:109} INFO - [2022-06-07 07:39:34,536] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:39:34,537] {logging_mixin.py:109} INFO - [2022-06-07 07:39:34,537] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1151692

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:39:34,537] {logging_mixin.py:109} INFO - [2022-06-07 07:39:34,537] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:39:34,538] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:39:34,551] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:40:04,831] {processor.py:163} INFO - Started process (PID=1152780) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:40:04,832] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:40:04,832] {logging_mixin.py:109} INFO - [2022-06-07 07:40:04,832] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:40:34,834] {logging_mixin.py:109} INFO - [2022-06-07 07:40:34,834] {timeout.py:36} ERROR - Process timed out, PID: 1152780
[2022-06-07 07:40:34,834] {logging_mixin.py:109} INFO - [2022-06-07 07:40:34,834] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1152780
[2022-06-07 07:40:34,835] {logging_mixin.py:109} INFO - [2022-06-07 07:40:34,835] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:40:34,835] {logging_mixin.py:109} INFO - [2022-06-07 07:40:34,835] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1152780

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:40:34,835] {logging_mixin.py:109} INFO - [2022-06-07 07:40:34,835] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:40:34,836] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:40:34,847] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:41:05,785] {processor.py:163} INFO - Started process (PID=1153873) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:41:05,785] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:41:05,785] {logging_mixin.py:109} INFO - [2022-06-07 07:41:05,785] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:41:35,787] {logging_mixin.py:109} INFO - [2022-06-07 07:41:35,786] {timeout.py:36} ERROR - Process timed out, PID: 1153873
[2022-06-07 07:41:35,787] {logging_mixin.py:109} INFO - [2022-06-07 07:41:35,787] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1153873
[2022-06-07 07:41:35,787] {logging_mixin.py:109} INFO - [2022-06-07 07:41:35,787] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:41:35,788] {logging_mixin.py:109} INFO - [2022-06-07 07:41:35,788] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1153873

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:41:35,788] {logging_mixin.py:109} INFO - [2022-06-07 07:41:35,788] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:41:35,788] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:41:35,801] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:42:06,247] {processor.py:163} INFO - Started process (PID=1154967) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:42:06,248] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:42:06,248] {logging_mixin.py:109} INFO - [2022-06-07 07:42:06,248] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:42:36,250] {logging_mixin.py:109} INFO - [2022-06-07 07:42:36,249] {timeout.py:36} ERROR - Process timed out, PID: 1154967
[2022-06-07 07:42:36,250] {logging_mixin.py:109} INFO - [2022-06-07 07:42:36,250] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1154967
[2022-06-07 07:42:36,250] {logging_mixin.py:109} INFO - [2022-06-07 07:42:36,250] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:42:36,251] {logging_mixin.py:109} INFO - [2022-06-07 07:42:36,250] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1154967

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:42:36,251] {logging_mixin.py:109} INFO - [2022-06-07 07:42:36,251] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:42:36,251] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:42:36,263] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:43:06,639] {processor.py:163} INFO - Started process (PID=1156060) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:43:06,640] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:43:06,640] {logging_mixin.py:109} INFO - [2022-06-07 07:43:06,640] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:43:36,642] {logging_mixin.py:109} INFO - [2022-06-07 07:43:36,642] {timeout.py:36} ERROR - Process timed out, PID: 1156060
[2022-06-07 07:43:36,643] {logging_mixin.py:109} INFO - [2022-06-07 07:43:36,642] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1156060
[2022-06-07 07:43:36,643] {logging_mixin.py:109} INFO - [2022-06-07 07:43:36,643] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:43:36,643] {logging_mixin.py:109} INFO - [2022-06-07 07:43:36,643] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1156060

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:43:36,644] {logging_mixin.py:109} INFO - [2022-06-07 07:43:36,644] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:43:36,644] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:43:36,655] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 07:44:07,027] {processor.py:163} INFO - Started process (PID=1157154) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:44:07,027] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:44:07,028] {logging_mixin.py:109} INFO - [2022-06-07 07:44:07,028] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:44:37,029] {logging_mixin.py:109} INFO - [2022-06-07 07:44:37,028] {timeout.py:36} ERROR - Process timed out, PID: 1157154
[2022-06-07 07:44:37,029] {logging_mixin.py:109} INFO - [2022-06-07 07:44:37,029] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1157154
[2022-06-07 07:44:37,030] {logging_mixin.py:109} INFO - [2022-06-07 07:44:37,029] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:44:37,030] {logging_mixin.py:109} INFO - [2022-06-07 07:44:37,030] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1157154

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:44:37,030] {logging_mixin.py:109} INFO - [2022-06-07 07:44:37,030] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:44:37,031] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:44:37,040] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.015 seconds
[2022-06-07 07:45:08,003] {processor.py:163} INFO - Started process (PID=1158247) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:45:08,004] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:45:08,004] {logging_mixin.py:109} INFO - [2022-06-07 07:45:08,004] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:45:38,006] {logging_mixin.py:109} INFO - [2022-06-07 07:45:38,006] {timeout.py:36} ERROR - Process timed out, PID: 1158247
[2022-06-07 07:45:38,007] {logging_mixin.py:109} INFO - [2022-06-07 07:45:38,007] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1158247
[2022-06-07 07:45:38,007] {logging_mixin.py:109} INFO - [2022-06-07 07:45:38,007] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:45:38,008] {logging_mixin.py:109} INFO - [2022-06-07 07:45:38,007] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1158247

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:45:38,008] {logging_mixin.py:109} INFO - [2022-06-07 07:45:38,008] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:45:38,008] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:45:38,020] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:46:08,364] {processor.py:163} INFO - Started process (PID=1159342) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:46:08,364] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:46:08,365] {logging_mixin.py:109} INFO - [2022-06-07 07:46:08,365] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:46:38,379] {logging_mixin.py:109} INFO - [2022-06-07 07:46:38,379] {timeout.py:36} ERROR - Process timed out, PID: 1159342
[2022-06-07 07:46:38,380] {logging_mixin.py:109} INFO - [2022-06-07 07:46:38,379] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1159342
[2022-06-07 07:46:38,380] {logging_mixin.py:109} INFO - [2022-06-07 07:46:38,380] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:46:38,380] {logging_mixin.py:109} INFO - [2022-06-07 07:46:38,380] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1159342

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:46:38,381] {logging_mixin.py:109} INFO - [2022-06-07 07:46:38,380] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:46:38,381] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:46:38,393] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.030 seconds
[2022-06-07 07:47:09,310] {processor.py:163} INFO - Started process (PID=1160436) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:47:09,310] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:47:09,310] {logging_mixin.py:109} INFO - [2022-06-07 07:47:09,310] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:47:39,313] {logging_mixin.py:109} INFO - [2022-06-07 07:47:39,313] {timeout.py:36} ERROR - Process timed out, PID: 1160436
[2022-06-07 07:47:39,314] {logging_mixin.py:109} INFO - [2022-06-07 07:47:39,314] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1160436
[2022-06-07 07:47:39,314] {logging_mixin.py:109} INFO - [2022-06-07 07:47:39,314] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:47:39,315] {logging_mixin.py:109} INFO - [2022-06-07 07:47:39,314] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1160436

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:47:39,315] {logging_mixin.py:109} INFO - [2022-06-07 07:47:39,315] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:47:39,315] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:47:39,327] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 07:48:09,437] {processor.py:163} INFO - Started process (PID=1161530) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:48:09,437] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:48:09,438] {logging_mixin.py:109} INFO - [2022-06-07 07:48:09,438] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:48:39,439] {logging_mixin.py:109} INFO - [2022-06-07 07:48:39,439] {timeout.py:36} ERROR - Process timed out, PID: 1161530
[2022-06-07 07:48:39,440] {logging_mixin.py:109} INFO - [2022-06-07 07:48:39,439] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1161530
[2022-06-07 07:48:39,440] {logging_mixin.py:109} INFO - [2022-06-07 07:48:39,440] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:48:39,440] {logging_mixin.py:109} INFO - [2022-06-07 07:48:39,440] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1161530

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:48:39,441] {logging_mixin.py:109} INFO - [2022-06-07 07:48:39,441] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:48:39,441] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:48:39,452] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 07:49:09,527] {processor.py:163} INFO - Started process (PID=1162623) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:49:09,528] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:49:09,528] {logging_mixin.py:109} INFO - [2022-06-07 07:49:09,528] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:49:39,531] {logging_mixin.py:109} INFO - [2022-06-07 07:49:39,530] {timeout.py:36} ERROR - Process timed out, PID: 1162623
[2022-06-07 07:49:39,531] {logging_mixin.py:109} INFO - [2022-06-07 07:49:39,531] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1162623
[2022-06-07 07:49:39,531] {logging_mixin.py:109} INFO - [2022-06-07 07:49:39,531] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:49:39,532] {logging_mixin.py:109} INFO - [2022-06-07 07:49:39,532] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1162623

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:49:39,532] {logging_mixin.py:109} INFO - [2022-06-07 07:49:39,532] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:49:39,533] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:49:39,544] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:50:09,575] {processor.py:163} INFO - Started process (PID=1163714) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:50:09,575] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:50:09,576] {logging_mixin.py:109} INFO - [2022-06-07 07:50:09,576] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:50:39,577] {logging_mixin.py:109} INFO - [2022-06-07 07:50:39,576] {timeout.py:36} ERROR - Process timed out, PID: 1163714
[2022-06-07 07:50:39,577] {logging_mixin.py:109} INFO - [2022-06-07 07:50:39,577] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1163714
[2022-06-07 07:50:39,577] {logging_mixin.py:109} INFO - [2022-06-07 07:50:39,577] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:50:39,578] {logging_mixin.py:109} INFO - [2022-06-07 07:50:39,578] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1163714

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:50:39,578] {logging_mixin.py:109} INFO - [2022-06-07 07:50:39,578] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:50:39,579] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:50:39,589] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 07:51:09,794] {processor.py:163} INFO - Started process (PID=1164807) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:51:09,794] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:51:09,794] {logging_mixin.py:109} INFO - [2022-06-07 07:51:09,794] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:51:39,796] {logging_mixin.py:109} INFO - [2022-06-07 07:51:39,795] {timeout.py:36} ERROR - Process timed out, PID: 1164807
[2022-06-07 07:51:39,796] {logging_mixin.py:109} INFO - [2022-06-07 07:51:39,796] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1164807
[2022-06-07 07:51:39,796] {logging_mixin.py:109} INFO - [2022-06-07 07:51:39,796] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:51:39,797] {logging_mixin.py:109} INFO - [2022-06-07 07:51:39,797] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1164807

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:51:39,797] {logging_mixin.py:109} INFO - [2022-06-07 07:51:39,797] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:51:39,798] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:51:39,833] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.041 seconds
[2022-06-07 07:52:10,708] {processor.py:163} INFO - Started process (PID=1165900) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:52:10,709] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:52:10,709] {logging_mixin.py:109} INFO - [2022-06-07 07:52:10,709] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:52:40,712] {logging_mixin.py:109} INFO - [2022-06-07 07:52:40,711] {timeout.py:36} ERROR - Process timed out, PID: 1165900
[2022-06-07 07:52:40,712] {logging_mixin.py:109} INFO - [2022-06-07 07:52:40,712] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1165900
[2022-06-07 07:52:40,712] {logging_mixin.py:109} INFO - [2022-06-07 07:52:40,712] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:52:40,713] {logging_mixin.py:109} INFO - [2022-06-07 07:52:40,712] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1165900

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:52:40,713] {logging_mixin.py:109} INFO - [2022-06-07 07:52:40,713] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:52:40,713] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:52:40,724] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:53:11,596] {processor.py:163} INFO - Started process (PID=1166994) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:53:11,596] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:53:11,596] {logging_mixin.py:109} INFO - [2022-06-07 07:53:11,596] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:53:41,599] {logging_mixin.py:109} INFO - [2022-06-07 07:53:41,599] {timeout.py:36} ERROR - Process timed out, PID: 1166994
[2022-06-07 07:53:41,600] {logging_mixin.py:109} INFO - [2022-06-07 07:53:41,599] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1166994
[2022-06-07 07:53:41,600] {logging_mixin.py:109} INFO - [2022-06-07 07:53:41,600] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:53:41,600] {logging_mixin.py:109} INFO - [2022-06-07 07:53:41,600] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1166994

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:53:41,600] {logging_mixin.py:109} INFO - [2022-06-07 07:53:41,600] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:53:41,601] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:53:41,613] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 07:54:12,413] {processor.py:163} INFO - Started process (PID=1168087) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:54:12,413] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:54:12,414] {logging_mixin.py:109} INFO - [2022-06-07 07:54:12,414] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:54:42,414] {logging_mixin.py:109} INFO - [2022-06-07 07:54:42,414] {timeout.py:36} ERROR - Process timed out, PID: 1168087
[2022-06-07 07:54:42,415] {logging_mixin.py:109} INFO - [2022-06-07 07:54:42,414] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1168087
[2022-06-07 07:54:42,415] {logging_mixin.py:109} INFO - [2022-06-07 07:54:42,415] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:54:42,415] {logging_mixin.py:109} INFO - [2022-06-07 07:54:42,415] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1168087

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:54:42,416] {logging_mixin.py:109} INFO - [2022-06-07 07:54:42,416] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:54:42,416] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:54:42,428] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 07:55:12,627] {processor.py:163} INFO - Started process (PID=1169161) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:55:12,627] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:55:12,627] {logging_mixin.py:109} INFO - [2022-06-07 07:55:12,627] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:55:42,641] {logging_mixin.py:109} INFO - [2022-06-07 07:55:42,640] {timeout.py:36} ERROR - Process timed out, PID: 1169161
[2022-06-07 07:55:42,641] {logging_mixin.py:109} INFO - [2022-06-07 07:55:42,641] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1169161
[2022-06-07 07:55:42,642] {logging_mixin.py:109} INFO - [2022-06-07 07:55:42,641] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:55:42,642] {logging_mixin.py:109} INFO - [2022-06-07 07:55:42,642] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1169161

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:55:42,642] {logging_mixin.py:109} INFO - [2022-06-07 07:55:42,642] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:55:42,643] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:55:42,654] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.029 seconds
[2022-06-07 07:56:13,562] {processor.py:163} INFO - Started process (PID=1170254) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:56:13,563] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:56:13,564] {logging_mixin.py:109} INFO - [2022-06-07 07:56:13,563] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:56:43,576] {logging_mixin.py:109} INFO - [2022-06-07 07:56:43,576] {timeout.py:36} ERROR - Process timed out, PID: 1170254
[2022-06-07 07:56:43,577] {logging_mixin.py:109} INFO - [2022-06-07 07:56:43,577] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1170254
[2022-06-07 07:56:43,577] {logging_mixin.py:109} INFO - [2022-06-07 07:56:43,577] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:56:43,578] {logging_mixin.py:109} INFO - [2022-06-07 07:56:43,577] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1170254

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:56:43,578] {logging_mixin.py:109} INFO - [2022-06-07 07:56:43,578] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:56:43,578] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:56:43,591] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.030 seconds
[2022-06-07 07:57:13,882] {processor.py:163} INFO - Started process (PID=1171348) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:57:13,883] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:57:13,883] {logging_mixin.py:109} INFO - [2022-06-07 07:57:13,883] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:57:43,886] {logging_mixin.py:109} INFO - [2022-06-07 07:57:43,886] {timeout.py:36} ERROR - Process timed out, PID: 1171348
[2022-06-07 07:57:43,887] {logging_mixin.py:109} INFO - [2022-06-07 07:57:43,887] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1171348
[2022-06-07 07:57:43,887] {logging_mixin.py:109} INFO - [2022-06-07 07:57:43,887] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:57:43,888] {logging_mixin.py:109} INFO - [2022-06-07 07:57:43,887] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1171348

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:57:43,888] {logging_mixin.py:109} INFO - [2022-06-07 07:57:43,888] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:57:43,888] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:57:43,900] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 07:58:14,022] {processor.py:163} INFO - Started process (PID=1172441) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:58:14,022] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:58:14,023] {logging_mixin.py:109} INFO - [2022-06-07 07:58:14,023] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:58:44,024] {logging_mixin.py:109} INFO - [2022-06-07 07:58:44,023] {timeout.py:36} ERROR - Process timed out, PID: 1172441
[2022-06-07 07:58:44,024] {logging_mixin.py:109} INFO - [2022-06-07 07:58:44,024] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1172441
[2022-06-07 07:58:44,024] {logging_mixin.py:109} INFO - [2022-06-07 07:58:44,024] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:58:44,025] {logging_mixin.py:109} INFO - [2022-06-07 07:58:44,025] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1172441

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:58:44,025] {logging_mixin.py:109} INFO - [2022-06-07 07:58:44,025] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:58:44,026] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:58:44,035] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.015 seconds
[2022-06-07 07:59:14,067] {processor.py:163} INFO - Started process (PID=1173507) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 07:59:14,067] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 07:59:14,067] {logging_mixin.py:109} INFO - [2022-06-07 07:59:14,067] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:59:44,070] {logging_mixin.py:109} INFO - [2022-06-07 07:59:44,069] {timeout.py:36} ERROR - Process timed out, PID: 1173507
[2022-06-07 07:59:44,070] {logging_mixin.py:109} INFO - [2022-06-07 07:59:44,070] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1173507
[2022-06-07 07:59:44,070] {logging_mixin.py:109} INFO - [2022-06-07 07:59:44,070] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 07:59:44,071] {logging_mixin.py:109} INFO - [2022-06-07 07:59:44,070] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1173507

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 07:59:44,071] {logging_mixin.py:109} INFO - [2022-06-07 07:59:44,071] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 07:59:44,071] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 07:59:44,084] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 08:00:14,726] {processor.py:163} INFO - Started process (PID=1174603) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:00:14,727] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:00:14,727] {logging_mixin.py:109} INFO - [2022-06-07 08:00:14,727] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:00:44,729] {logging_mixin.py:109} INFO - [2022-06-07 08:00:44,728] {timeout.py:36} ERROR - Process timed out, PID: 1174603
[2022-06-07 08:00:44,729] {logging_mixin.py:109} INFO - [2022-06-07 08:00:44,729] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1174603
[2022-06-07 08:00:44,729] {logging_mixin.py:109} INFO - [2022-06-07 08:00:44,729] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:00:44,730] {logging_mixin.py:109} INFO - [2022-06-07 08:00:44,729] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1174603

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:00:44,730] {logging_mixin.py:109} INFO - [2022-06-07 08:00:44,730] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:00:44,730] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:00:44,741] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 08:01:15,324] {processor.py:163} INFO - Started process (PID=1175697) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:01:15,325] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:01:15,325] {logging_mixin.py:109} INFO - [2022-06-07 08:01:15,325] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:01:45,326] {logging_mixin.py:109} INFO - [2022-06-07 08:01:45,326] {timeout.py:36} ERROR - Process timed out, PID: 1175697
[2022-06-07 08:01:45,327] {logging_mixin.py:109} INFO - [2022-06-07 08:01:45,327] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1175697
[2022-06-07 08:01:45,327] {logging_mixin.py:109} INFO - [2022-06-07 08:01:45,327] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:01:45,328] {logging_mixin.py:109} INFO - [2022-06-07 08:01:45,327] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1175697

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:01:45,328] {logging_mixin.py:109} INFO - [2022-06-07 08:01:45,328] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:01:45,328] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:01:45,340] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:02:15,989] {processor.py:163} INFO - Started process (PID=1176793) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:02:15,990] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:02:15,990] {logging_mixin.py:109} INFO - [2022-06-07 08:02:15,990] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:02:45,991] {logging_mixin.py:109} INFO - [2022-06-07 08:02:45,991] {timeout.py:36} ERROR - Process timed out, PID: 1176793
[2022-06-07 08:02:45,991] {logging_mixin.py:109} INFO - [2022-06-07 08:02:45,991] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1176793
[2022-06-07 08:02:45,992] {logging_mixin.py:109} INFO - [2022-06-07 08:02:45,992] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:02:45,992] {logging_mixin.py:109} INFO - [2022-06-07 08:02:45,992] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1176793

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:02:45,993] {logging_mixin.py:109} INFO - [2022-06-07 08:02:45,992] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:02:45,993] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:02:46,004] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:03:16,221] {processor.py:163} INFO - Started process (PID=1177874) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:03:16,222] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:03:16,222] {logging_mixin.py:109} INFO - [2022-06-07 08:03:16,222] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:03:46,223] {logging_mixin.py:109} INFO - [2022-06-07 08:03:46,223] {timeout.py:36} ERROR - Process timed out, PID: 1177874
[2022-06-07 08:03:46,224] {logging_mixin.py:109} INFO - [2022-06-07 08:03:46,223] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1177874
[2022-06-07 08:03:46,224] {logging_mixin.py:109} INFO - [2022-06-07 08:03:46,224] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:03:46,224] {logging_mixin.py:109} INFO - [2022-06-07 08:03:46,224] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1177874

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:03:46,224] {logging_mixin.py:109} INFO - [2022-06-07 08:03:46,224] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:03:46,225] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:03:46,235] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 08:04:16,544] {processor.py:163} INFO - Started process (PID=1178962) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:04:16,545] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:04:16,545] {logging_mixin.py:109} INFO - [2022-06-07 08:04:16,545] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:04:46,546] {logging_mixin.py:109} INFO - [2022-06-07 08:04:46,546] {timeout.py:36} ERROR - Process timed out, PID: 1178962
[2022-06-07 08:04:46,547] {logging_mixin.py:109} INFO - [2022-06-07 08:04:46,546] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1178962
[2022-06-07 08:04:46,547] {logging_mixin.py:109} INFO - [2022-06-07 08:04:46,547] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:04:46,547] {logging_mixin.py:109} INFO - [2022-06-07 08:04:46,547] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1178962

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:04:46,548] {logging_mixin.py:109} INFO - [2022-06-07 08:04:46,548] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:04:46,548] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:04:46,560] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:05:16,730] {processor.py:163} INFO - Started process (PID=1180027) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:05:16,730] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:05:16,731] {logging_mixin.py:109} INFO - [2022-06-07 08:05:16,731] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:05:46,731] {logging_mixin.py:109} INFO - [2022-06-07 08:05:46,731] {timeout.py:36} ERROR - Process timed out, PID: 1180027
[2022-06-07 08:05:46,732] {logging_mixin.py:109} INFO - [2022-06-07 08:05:46,732] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1180027
[2022-06-07 08:05:46,732] {logging_mixin.py:109} INFO - [2022-06-07 08:05:46,732] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:05:46,733] {logging_mixin.py:109} INFO - [2022-06-07 08:05:46,732] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1180027

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:05:46,733] {logging_mixin.py:109} INFO - [2022-06-07 08:05:46,733] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:05:46,733] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:05:46,745] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 08:06:17,158] {processor.py:163} INFO - Started process (PID=1181098) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:06:17,158] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:06:17,159] {logging_mixin.py:109} INFO - [2022-06-07 08:06:17,159] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:06:47,165] {logging_mixin.py:109} INFO - [2022-06-07 08:06:47,165] {timeout.py:36} ERROR - Process timed out, PID: 1181098
[2022-06-07 08:06:47,166] {logging_mixin.py:109} INFO - [2022-06-07 08:06:47,165] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1181098
[2022-06-07 08:06:47,166] {logging_mixin.py:109} INFO - [2022-06-07 08:06:47,166] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:06:47,166] {logging_mixin.py:109} INFO - [2022-06-07 08:06:47,166] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1181098

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:06:47,167] {logging_mixin.py:109} INFO - [2022-06-07 08:06:47,166] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:06:47,167] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:06:47,178] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 08:07:18,149] {processor.py:163} INFO - Started process (PID=1182192) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:07:18,150] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:07:18,150] {logging_mixin.py:109} INFO - [2022-06-07 08:07:18,150] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:07:48,151] {logging_mixin.py:109} INFO - [2022-06-07 08:07:48,151] {timeout.py:36} ERROR - Process timed out, PID: 1182192
[2022-06-07 08:07:48,151] {logging_mixin.py:109} INFO - [2022-06-07 08:07:48,151] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1182192
[2022-06-07 08:07:48,152] {logging_mixin.py:109} INFO - [2022-06-07 08:07:48,152] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:07:48,152] {logging_mixin.py:109} INFO - [2022-06-07 08:07:48,152] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1182192

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:07:48,152] {logging_mixin.py:109} INFO - [2022-06-07 08:07:48,152] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:07:48,153] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:07:48,164] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 08:08:19,106] {processor.py:163} INFO - Started process (PID=1183285) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:08:19,107] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:08:19,107] {logging_mixin.py:109} INFO - [2022-06-07 08:08:19,107] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:08:49,111] {logging_mixin.py:109} INFO - [2022-06-07 08:08:49,111] {timeout.py:36} ERROR - Process timed out, PID: 1183285
[2022-06-07 08:08:49,111] {logging_mixin.py:109} INFO - [2022-06-07 08:08:49,111] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1183285
[2022-06-07 08:08:49,112] {logging_mixin.py:109} INFO - [2022-06-07 08:08:49,112] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:08:49,112] {logging_mixin.py:109} INFO - [2022-06-07 08:08:49,112] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1183285

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:08:49,112] {logging_mixin.py:109} INFO - [2022-06-07 08:08:49,112] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:08:49,113] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:08:49,124] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 08:09:19,907] {processor.py:163} INFO - Started process (PID=1184378) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:09:19,908] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:09:19,908] {logging_mixin.py:109} INFO - [2022-06-07 08:09:19,908] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:09:49,910] {logging_mixin.py:109} INFO - [2022-06-07 08:09:49,909] {timeout.py:36} ERROR - Process timed out, PID: 1184378
[2022-06-07 08:09:49,910] {logging_mixin.py:109} INFO - [2022-06-07 08:09:49,910] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1184378
[2022-06-07 08:09:49,910] {logging_mixin.py:109} INFO - [2022-06-07 08:09:49,910] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:09:49,911] {logging_mixin.py:109} INFO - [2022-06-07 08:09:49,911] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1184378

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:09:49,911] {logging_mixin.py:109} INFO - [2022-06-07 08:09:49,911] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:09:49,911] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:09:49,923] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:10:20,083] {processor.py:163} INFO - Started process (PID=1185472) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:10:20,083] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:10:20,084] {logging_mixin.py:109} INFO - [2022-06-07 08:10:20,084] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:10:50,085] {logging_mixin.py:109} INFO - [2022-06-07 08:10:50,084] {timeout.py:36} ERROR - Process timed out, PID: 1185472
[2022-06-07 08:10:50,085] {logging_mixin.py:109} INFO - [2022-06-07 08:10:50,085] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1185472
[2022-06-07 08:10:50,085] {logging_mixin.py:109} INFO - [2022-06-07 08:10:50,085] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:10:50,086] {logging_mixin.py:109} INFO - [2022-06-07 08:10:50,085] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1185472

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:10:50,086] {logging_mixin.py:109} INFO - [2022-06-07 08:10:50,086] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:10:50,086] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:10:50,097] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 08:11:20,191] {processor.py:163} INFO - Started process (PID=1186537) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:11:20,191] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:11:20,192] {logging_mixin.py:109} INFO - [2022-06-07 08:11:20,192] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:11:50,198] {logging_mixin.py:109} INFO - [2022-06-07 08:11:50,197] {timeout.py:36} ERROR - Process timed out, PID: 1186537
[2022-06-07 08:11:50,198] {logging_mixin.py:109} INFO - [2022-06-07 08:11:50,198] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1186537
[2022-06-07 08:11:50,198] {logging_mixin.py:109} INFO - [2022-06-07 08:11:50,198] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:11:50,199] {logging_mixin.py:109} INFO - [2022-06-07 08:11:50,198] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1186537

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:11:50,199] {logging_mixin.py:109} INFO - [2022-06-07 08:11:50,199] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:11:50,199] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:11:50,210] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 08:12:21,189] {processor.py:163} INFO - Started process (PID=1187632) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:12:21,190] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:12:21,190] {logging_mixin.py:109} INFO - [2022-06-07 08:12:21,190] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:12:51,213] {logging_mixin.py:109} INFO - [2022-06-07 08:12:51,212] {timeout.py:36} ERROR - Process timed out, PID: 1187632
[2022-06-07 08:12:51,213] {logging_mixin.py:109} INFO - [2022-06-07 08:12:51,213] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1187632
[2022-06-07 08:12:51,213] {logging_mixin.py:109} INFO - [2022-06-07 08:12:51,213] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:12:51,214] {logging_mixin.py:109} INFO - [2022-06-07 08:12:51,214] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1187632

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:12:51,214] {logging_mixin.py:109} INFO - [2022-06-07 08:12:51,214] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:12:51,215] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:12:51,226] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.038 seconds
[2022-06-07 08:13:22,103] {processor.py:163} INFO - Started process (PID=1188727) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:13:22,103] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:13:22,104] {logging_mixin.py:109} INFO - [2022-06-07 08:13:22,104] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:13:52,124] {logging_mixin.py:109} INFO - [2022-06-07 08:13:52,124] {timeout.py:36} ERROR - Process timed out, PID: 1188727
[2022-06-07 08:13:52,125] {logging_mixin.py:109} INFO - [2022-06-07 08:13:52,124] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1188727
[2022-06-07 08:13:52,125] {logging_mixin.py:109} INFO - [2022-06-07 08:13:52,125] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:13:52,125] {logging_mixin.py:109} INFO - [2022-06-07 08:13:52,125] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1188727

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:13:52,126] {logging_mixin.py:109} INFO - [2022-06-07 08:13:52,126] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:13:52,126] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:13:52,137] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.036 seconds
[2022-06-07 08:14:22,216] {processor.py:163} INFO - Started process (PID=1189821) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:14:22,216] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:14:22,216] {logging_mixin.py:109} INFO - [2022-06-07 08:14:22,216] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:14:52,226] {logging_mixin.py:109} INFO - [2022-06-07 08:14:52,226] {timeout.py:36} ERROR - Process timed out, PID: 1189821
[2022-06-07 08:14:52,227] {logging_mixin.py:109} INFO - [2022-06-07 08:14:52,226] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1189821
[2022-06-07 08:14:52,227] {logging_mixin.py:109} INFO - [2022-06-07 08:14:52,227] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:14:52,227] {logging_mixin.py:109} INFO - [2022-06-07 08:14:52,227] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1189821

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:14:52,228] {logging_mixin.py:109} INFO - [2022-06-07 08:14:52,227] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:14:52,228] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:14:52,240] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 08:15:22,698] {processor.py:163} INFO - Started process (PID=1190915) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:15:22,699] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:15:22,699] {logging_mixin.py:109} INFO - [2022-06-07 08:15:22,699] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:15:52,703] {logging_mixin.py:109} INFO - [2022-06-07 08:15:52,703] {timeout.py:36} ERROR - Process timed out, PID: 1190915
[2022-06-07 08:15:52,704] {logging_mixin.py:109} INFO - [2022-06-07 08:15:52,703] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1190915
[2022-06-07 08:15:52,704] {logging_mixin.py:109} INFO - [2022-06-07 08:15:52,704] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:15:52,704] {logging_mixin.py:109} INFO - [2022-06-07 08:15:52,704] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1190915

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:15:52,705] {logging_mixin.py:109} INFO - [2022-06-07 08:15:52,704] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:15:52,705] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:15:52,716] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 08:16:23,595] {processor.py:163} INFO - Started process (PID=1192011) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:16:23,596] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:16:23,596] {logging_mixin.py:109} INFO - [2022-06-07 08:16:23,596] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:16:53,603] {logging_mixin.py:109} INFO - [2022-06-07 08:16:53,603] {timeout.py:36} ERROR - Process timed out, PID: 1192011
[2022-06-07 08:16:53,604] {logging_mixin.py:109} INFO - [2022-06-07 08:16:53,603] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1192011
[2022-06-07 08:16:53,604] {logging_mixin.py:109} INFO - [2022-06-07 08:16:53,604] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:16:53,604] {logging_mixin.py:109} INFO - [2022-06-07 08:16:53,604] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1192011

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:16:53,605] {logging_mixin.py:109} INFO - [2022-06-07 08:16:53,605] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:16:53,605] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:16:53,617] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 08:17:23,992] {processor.py:163} INFO - Started process (PID=1193105) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:17:23,992] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:17:23,993] {logging_mixin.py:109} INFO - [2022-06-07 08:17:23,993] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:17:53,995] {logging_mixin.py:109} INFO - [2022-06-07 08:17:53,994] {timeout.py:36} ERROR - Process timed out, PID: 1193105
[2022-06-07 08:17:53,995] {logging_mixin.py:109} INFO - [2022-06-07 08:17:53,995] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1193105
[2022-06-07 08:17:53,995] {logging_mixin.py:109} INFO - [2022-06-07 08:17:53,995] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:17:53,996] {logging_mixin.py:109} INFO - [2022-06-07 08:17:53,996] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1193105

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:17:53,996] {logging_mixin.py:109} INFO - [2022-06-07 08:17:53,996] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:17:53,997] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:17:54,008] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:18:24,626] {processor.py:163} INFO - Started process (PID=1194199) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:18:24,626] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:18:24,627] {logging_mixin.py:109} INFO - [2022-06-07 08:18:24,627] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:18:54,635] {logging_mixin.py:109} INFO - [2022-06-07 08:18:54,635] {timeout.py:36} ERROR - Process timed out, PID: 1194199
[2022-06-07 08:18:54,636] {logging_mixin.py:109} INFO - [2022-06-07 08:18:54,635] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1194199
[2022-06-07 08:18:54,636] {logging_mixin.py:109} INFO - [2022-06-07 08:18:54,636] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:18:54,636] {logging_mixin.py:109} INFO - [2022-06-07 08:18:54,636] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1194199

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:18:54,637] {logging_mixin.py:109} INFO - [2022-06-07 08:18:54,636] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:18:54,637] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:18:54,649] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 08:19:24,938] {processor.py:163} INFO - Started process (PID=1195292) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:19:24,939] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:19:24,939] {logging_mixin.py:109} INFO - [2022-06-07 08:19:24,939] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:19:54,945] {logging_mixin.py:109} INFO - [2022-06-07 08:19:54,944] {timeout.py:36} ERROR - Process timed out, PID: 1195292
[2022-06-07 08:19:54,945] {logging_mixin.py:109} INFO - [2022-06-07 08:19:54,945] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1195292
[2022-06-07 08:19:54,945] {logging_mixin.py:109} INFO - [2022-06-07 08:19:54,945] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:19:54,946] {logging_mixin.py:109} INFO - [2022-06-07 08:19:54,945] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1195292

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:19:54,946] {logging_mixin.py:109} INFO - [2022-06-07 08:19:54,946] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:19:54,946] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:19:54,958] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 08:20:25,266] {processor.py:163} INFO - Started process (PID=1196386) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:20:25,266] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:20:25,266] {logging_mixin.py:109} INFO - [2022-06-07 08:20:25,266] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:20:55,279] {logging_mixin.py:109} INFO - [2022-06-07 08:20:55,279] {timeout.py:36} ERROR - Process timed out, PID: 1196386
[2022-06-07 08:20:55,280] {logging_mixin.py:109} INFO - [2022-06-07 08:20:55,280] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1196386
[2022-06-07 08:20:55,280] {logging_mixin.py:109} INFO - [2022-06-07 08:20:55,280] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:20:55,281] {logging_mixin.py:109} INFO - [2022-06-07 08:20:55,280] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1196386

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:20:55,281] {logging_mixin.py:109} INFO - [2022-06-07 08:20:55,281] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:20:55,281] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:20:55,292] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 08:21:25,551] {processor.py:163} INFO - Started process (PID=1197481) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:21:25,552] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:21:25,552] {logging_mixin.py:109} INFO - [2022-06-07 08:21:25,552] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:21:55,554] {logging_mixin.py:109} INFO - [2022-06-07 08:21:55,553] {timeout.py:36} ERROR - Process timed out, PID: 1197481
[2022-06-07 08:21:55,554] {logging_mixin.py:109} INFO - [2022-06-07 08:21:55,554] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1197481
[2022-06-07 08:21:55,554] {logging_mixin.py:109} INFO - [2022-06-07 08:21:55,554] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:21:55,555] {logging_mixin.py:109} INFO - [2022-06-07 08:21:55,554] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1197481

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:21:55,555] {logging_mixin.py:109} INFO - [2022-06-07 08:21:55,555] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:21:55,555] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:21:55,566] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 08:22:25,881] {processor.py:163} INFO - Started process (PID=1198575) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:22:25,881] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:22:25,882] {logging_mixin.py:109} INFO - [2022-06-07 08:22:25,881] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:22:55,885] {logging_mixin.py:109} INFO - [2022-06-07 08:22:55,885] {timeout.py:36} ERROR - Process timed out, PID: 1198575
[2022-06-07 08:22:55,886] {logging_mixin.py:109} INFO - [2022-06-07 08:22:55,885] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1198575
[2022-06-07 08:22:55,886] {logging_mixin.py:109} INFO - [2022-06-07 08:22:55,886] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:22:55,886] {logging_mixin.py:109} INFO - [2022-06-07 08:22:55,886] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1198575

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:22:55,887] {logging_mixin.py:109} INFO - [2022-06-07 08:22:55,887] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:22:55,887] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:22:55,899] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 08:23:26,536] {processor.py:163} INFO - Started process (PID=1199668) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:23:26,537] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:23:26,537] {logging_mixin.py:109} INFO - [2022-06-07 08:23:26,537] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:23:56,539] {logging_mixin.py:109} INFO - [2022-06-07 08:23:56,539] {timeout.py:36} ERROR - Process timed out, PID: 1199668
[2022-06-07 08:23:56,540] {logging_mixin.py:109} INFO - [2022-06-07 08:23:56,539] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1199668
[2022-06-07 08:23:56,540] {logging_mixin.py:109} INFO - [2022-06-07 08:23:56,540] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:23:56,540] {logging_mixin.py:109} INFO - [2022-06-07 08:23:56,540] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1199668

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:23:56,541] {logging_mixin.py:109} INFO - [2022-06-07 08:23:56,540] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:23:56,541] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:23:56,553] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 08:24:26,772] {processor.py:163} INFO - Started process (PID=1200761) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:24:26,773] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:24:26,773] {logging_mixin.py:109} INFO - [2022-06-07 08:24:26,773] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:24:56,775] {logging_mixin.py:109} INFO - [2022-06-07 08:24:56,774] {timeout.py:36} ERROR - Process timed out, PID: 1200761
[2022-06-07 08:24:56,775] {logging_mixin.py:109} INFO - [2022-06-07 08:24:56,775] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1200761
[2022-06-07 08:24:56,775] {logging_mixin.py:109} INFO - [2022-06-07 08:24:56,775] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:24:56,776] {logging_mixin.py:109} INFO - [2022-06-07 08:24:56,775] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1200761

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:24:56,776] {logging_mixin.py:109} INFO - [2022-06-07 08:24:56,776] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:24:56,777] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:24:56,787] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 08:25:27,018] {processor.py:163} INFO - Started process (PID=1201854) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:25:27,019] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:25:27,019] {logging_mixin.py:109} INFO - [2022-06-07 08:25:27,019] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:25:57,021] {logging_mixin.py:109} INFO - [2022-06-07 08:25:57,021] {timeout.py:36} ERROR - Process timed out, PID: 1201854
[2022-06-07 08:25:57,022] {logging_mixin.py:109} INFO - [2022-06-07 08:25:57,021] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1201854
[2022-06-07 08:25:57,022] {logging_mixin.py:109} INFO - [2022-06-07 08:25:57,022] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:25:57,023] {logging_mixin.py:109} INFO - [2022-06-07 08:25:57,022] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1201854

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:25:57,023] {logging_mixin.py:109} INFO - [2022-06-07 08:25:57,023] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:25:57,023] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:25:57,035] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 08:26:27,844] {processor.py:163} INFO - Started process (PID=1202947) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:26:27,845] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:26:27,845] {logging_mixin.py:109} INFO - [2022-06-07 08:26:27,845] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:26:57,853] {logging_mixin.py:109} INFO - [2022-06-07 08:26:57,852] {timeout.py:36} ERROR - Process timed out, PID: 1202947
[2022-06-07 08:26:57,853] {logging_mixin.py:109} INFO - [2022-06-07 08:26:57,853] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1202947
[2022-06-07 08:26:57,853] {logging_mixin.py:109} INFO - [2022-06-07 08:26:57,853] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:26:57,854] {logging_mixin.py:109} INFO - [2022-06-07 08:26:57,854] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1202947

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:26:57,854] {logging_mixin.py:109} INFO - [2022-06-07 08:26:57,854] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:26:57,855] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:26:57,866] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 08:27:28,725] {processor.py:163} INFO - Started process (PID=1204041) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:27:28,725] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:27:28,726] {logging_mixin.py:109} INFO - [2022-06-07 08:27:28,726] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:27:58,727] {logging_mixin.py:109} INFO - [2022-06-07 08:27:58,726] {timeout.py:36} ERROR - Process timed out, PID: 1204041
[2022-06-07 08:27:58,727] {logging_mixin.py:109} INFO - [2022-06-07 08:27:58,727] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1204041
[2022-06-07 08:27:58,727] {logging_mixin.py:109} INFO - [2022-06-07 08:27:58,727] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:27:58,728] {logging_mixin.py:109} INFO - [2022-06-07 08:27:58,728] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1204041

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:27:58,728] {logging_mixin.py:109} INFO - [2022-06-07 08:27:58,728] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:27:58,729] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:27:58,741] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:28:29,067] {processor.py:163} INFO - Started process (PID=1205135) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:28:29,067] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:28:29,067] {logging_mixin.py:109} INFO - [2022-06-07 08:28:29,067] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:28:59,079] {logging_mixin.py:109} INFO - [2022-06-07 08:28:59,078] {timeout.py:36} ERROR - Process timed out, PID: 1205135
[2022-06-07 08:28:59,079] {logging_mixin.py:109} INFO - [2022-06-07 08:28:59,079] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1205135
[2022-06-07 08:28:59,080] {logging_mixin.py:109} INFO - [2022-06-07 08:28:59,079] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:28:59,080] {logging_mixin.py:109} INFO - [2022-06-07 08:28:59,080] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1205135

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:28:59,081] {logging_mixin.py:109} INFO - [2022-06-07 08:28:59,080] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:28:59,081] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:28:59,092] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.027 seconds
[2022-06-07 08:29:29,584] {processor.py:163} INFO - Started process (PID=1206231) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:29:29,585] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:29:29,585] {logging_mixin.py:109} INFO - [2022-06-07 08:29:29,585] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:29:59,598] {logging_mixin.py:109} INFO - [2022-06-07 08:29:59,597] {timeout.py:36} ERROR - Process timed out, PID: 1206231
[2022-06-07 08:29:59,598] {logging_mixin.py:109} INFO - [2022-06-07 08:29:59,598] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1206231
[2022-06-07 08:29:59,598] {logging_mixin.py:109} INFO - [2022-06-07 08:29:59,598] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:29:59,599] {logging_mixin.py:109} INFO - [2022-06-07 08:29:59,598] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1206231

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:29:59,599] {logging_mixin.py:109} INFO - [2022-06-07 08:29:59,599] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:29:59,599] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:29:59,610] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 08:30:30,406] {processor.py:163} INFO - Started process (PID=1207325) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:30:30,407] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:30:30,407] {logging_mixin.py:109} INFO - [2022-06-07 08:30:30,407] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:31:00,409] {logging_mixin.py:109} INFO - [2022-06-07 08:31:00,409] {timeout.py:36} ERROR - Process timed out, PID: 1207325
[2022-06-07 08:31:00,409] {logging_mixin.py:109} INFO - [2022-06-07 08:31:00,409] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1207325
[2022-06-07 08:31:00,410] {logging_mixin.py:109} INFO - [2022-06-07 08:31:00,410] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:31:00,410] {logging_mixin.py:109} INFO - [2022-06-07 08:31:00,410] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1207325

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:31:00,410] {logging_mixin.py:109} INFO - [2022-06-07 08:31:00,410] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:31:00,411] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:31:00,422] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:31:30,464] {processor.py:163} INFO - Started process (PID=1208419) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:31:30,465] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:31:30,465] {logging_mixin.py:109} INFO - [2022-06-07 08:31:30,465] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:32:00,469] {logging_mixin.py:109} INFO - [2022-06-07 08:32:00,468] {timeout.py:36} ERROR - Process timed out, PID: 1208419
[2022-06-07 08:32:00,469] {logging_mixin.py:109} INFO - [2022-06-07 08:32:00,469] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1208419
[2022-06-07 08:32:00,469] {logging_mixin.py:109} INFO - [2022-06-07 08:32:00,469] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:32:00,470] {logging_mixin.py:109} INFO - [2022-06-07 08:32:00,469] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1208419

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:32:00,470] {logging_mixin.py:109} INFO - [2022-06-07 08:32:00,470] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:32:00,470] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:32:00,481] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 08:32:31,257] {processor.py:163} INFO - Started process (PID=1209515) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:32:31,257] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:32:31,257] {logging_mixin.py:109} INFO - [2022-06-07 08:32:31,257] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:33:01,259] {logging_mixin.py:109} INFO - [2022-06-07 08:33:01,259] {timeout.py:36} ERROR - Process timed out, PID: 1209515
[2022-06-07 08:33:01,260] {logging_mixin.py:109} INFO - [2022-06-07 08:33:01,259] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1209515
[2022-06-07 08:33:01,260] {logging_mixin.py:109} INFO - [2022-06-07 08:33:01,260] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:33:01,260] {logging_mixin.py:109} INFO - [2022-06-07 08:33:01,260] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1209515

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:33:01,261] {logging_mixin.py:109} INFO - [2022-06-07 08:33:01,260] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:33:01,261] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:33:01,273] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:33:32,096] {processor.py:163} INFO - Started process (PID=1210610) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:33:32,096] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:33:32,097] {logging_mixin.py:109} INFO - [2022-06-07 08:33:32,097] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:34:02,106] {logging_mixin.py:109} INFO - [2022-06-07 08:34:02,106] {timeout.py:36} ERROR - Process timed out, PID: 1210610
[2022-06-07 08:34:02,107] {logging_mixin.py:109} INFO - [2022-06-07 08:34:02,106] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1210610
[2022-06-07 08:34:02,107] {logging_mixin.py:109} INFO - [2022-06-07 08:34:02,107] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:34:02,107] {logging_mixin.py:109} INFO - [2022-06-07 08:34:02,107] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1210610

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:34:02,108] {logging_mixin.py:109} INFO - [2022-06-07 08:34:02,107] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:34:02,108] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:34:02,119] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 08:34:32,949] {processor.py:163} INFO - Started process (PID=1211705) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:34:32,950] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:34:32,950] {logging_mixin.py:109} INFO - [2022-06-07 08:34:32,950] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:35:02,960] {logging_mixin.py:109} INFO - [2022-06-07 08:35:02,959] {timeout.py:36} ERROR - Process timed out, PID: 1211705
[2022-06-07 08:35:02,960] {logging_mixin.py:109} INFO - [2022-06-07 08:35:02,960] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1211705
[2022-06-07 08:35:02,961] {logging_mixin.py:109} INFO - [2022-06-07 08:35:02,960] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:35:02,961] {logging_mixin.py:109} INFO - [2022-06-07 08:35:02,961] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1211705

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:35:02,961] {logging_mixin.py:109} INFO - [2022-06-07 08:35:02,961] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:35:02,962] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:35:02,973] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 08:35:33,778] {processor.py:163} INFO - Started process (PID=1212798) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:35:33,778] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:35:33,778] {logging_mixin.py:109} INFO - [2022-06-07 08:35:33,778] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:36:03,780] {logging_mixin.py:109} INFO - [2022-06-07 08:36:03,780] {timeout.py:36} ERROR - Process timed out, PID: 1212798
[2022-06-07 08:36:03,781] {logging_mixin.py:109} INFO - [2022-06-07 08:36:03,780] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1212798
[2022-06-07 08:36:03,781] {logging_mixin.py:109} INFO - [2022-06-07 08:36:03,781] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:36:03,781] {logging_mixin.py:109} INFO - [2022-06-07 08:36:03,781] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1212798

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:36:03,782] {logging_mixin.py:109} INFO - [2022-06-07 08:36:03,781] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:36:03,782] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:36:03,793] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:36:33,912] {processor.py:163} INFO - Started process (PID=1213891) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:36:33,913] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:36:33,913] {logging_mixin.py:109} INFO - [2022-06-07 08:36:33,913] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:37:03,914] {logging_mixin.py:109} INFO - [2022-06-07 08:37:03,914] {timeout.py:36} ERROR - Process timed out, PID: 1213891
[2022-06-07 08:37:03,915] {logging_mixin.py:109} INFO - [2022-06-07 08:37:03,914] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1213891
[2022-06-07 08:37:03,915] {logging_mixin.py:109} INFO - [2022-06-07 08:37:03,915] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:37:03,915] {logging_mixin.py:109} INFO - [2022-06-07 08:37:03,915] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1213891

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:37:03,916] {logging_mixin.py:109} INFO - [2022-06-07 08:37:03,916] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:37:03,916] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:37:03,931] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 08:37:34,181] {processor.py:163} INFO - Started process (PID=1214898) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:37:34,181] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:37:34,182] {logging_mixin.py:109} INFO - [2022-06-07 08:37:34,182] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:38:04,183] {logging_mixin.py:109} INFO - [2022-06-07 08:38:04,182] {timeout.py:36} ERROR - Process timed out, PID: 1214898
[2022-06-07 08:38:04,183] {logging_mixin.py:109} INFO - [2022-06-07 08:38:04,183] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1214898
[2022-06-07 08:38:04,183] {logging_mixin.py:109} INFO - [2022-06-07 08:38:04,183] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:38:04,184] {logging_mixin.py:109} INFO - [2022-06-07 08:38:04,183] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1214898

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:38:04,184] {logging_mixin.py:109} INFO - [2022-06-07 08:38:04,184] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:38:04,184] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:38:04,196] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 08:38:34,691] {processor.py:163} INFO - Started process (PID=1215985) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:38:34,691] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:38:34,692] {logging_mixin.py:109} INFO - [2022-06-07 08:38:34,692] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:39:04,701] {logging_mixin.py:109} INFO - [2022-06-07 08:39:04,700] {timeout.py:36} ERROR - Process timed out, PID: 1215985
[2022-06-07 08:39:04,701] {logging_mixin.py:109} INFO - [2022-06-07 08:39:04,701] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1215985
[2022-06-07 08:39:04,701] {logging_mixin.py:109} INFO - [2022-06-07 08:39:04,701] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:39:04,702] {logging_mixin.py:109} INFO - [2022-06-07 08:39:04,702] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1215985

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:39:04,702] {logging_mixin.py:109} INFO - [2022-06-07 08:39:04,702] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:39:04,703] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:39:04,714] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 08:39:35,203] {processor.py:163} INFO - Started process (PID=1217078) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:39:35,203] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:39:35,204] {logging_mixin.py:109} INFO - [2022-06-07 08:39:35,204] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:40:05,208] {logging_mixin.py:109} INFO - [2022-06-07 08:40:05,208] {timeout.py:36} ERROR - Process timed out, PID: 1217078
[2022-06-07 08:40:05,209] {logging_mixin.py:109} INFO - [2022-06-07 08:40:05,208] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1217078
[2022-06-07 08:40:05,209] {logging_mixin.py:109} INFO - [2022-06-07 08:40:05,209] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:40:05,209] {logging_mixin.py:109} INFO - [2022-06-07 08:40:05,209] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1217078

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:40:05,210] {logging_mixin.py:109} INFO - [2022-06-07 08:40:05,209] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:40:05,210] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:40:05,222] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 08:40:35,780] {processor.py:163} INFO - Started process (PID=1218172) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:40:35,781] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:40:35,781] {logging_mixin.py:109} INFO - [2022-06-07 08:40:35,781] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:41:05,809] {logging_mixin.py:109} INFO - [2022-06-07 08:41:05,808] {timeout.py:36} ERROR - Process timed out, PID: 1218172
[2022-06-07 08:41:05,809] {logging_mixin.py:109} INFO - [2022-06-07 08:41:05,809] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1218172
[2022-06-07 08:41:05,809] {logging_mixin.py:109} INFO - [2022-06-07 08:41:05,809] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:41:05,810] {logging_mixin.py:109} INFO - [2022-06-07 08:41:05,809] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1218172

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:41:05,810] {logging_mixin.py:109} INFO - [2022-06-07 08:41:05,810] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:41:05,810] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:41:05,822] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.043 seconds
[2022-06-07 08:41:36,422] {processor.py:163} INFO - Started process (PID=1219267) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:41:36,423] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:41:36,423] {logging_mixin.py:109} INFO - [2022-06-07 08:41:36,423] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:42:06,435] {logging_mixin.py:109} INFO - [2022-06-07 08:42:06,435] {timeout.py:36} ERROR - Process timed out, PID: 1219267
[2022-06-07 08:42:06,436] {logging_mixin.py:109} INFO - [2022-06-07 08:42:06,435] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1219267
[2022-06-07 08:42:06,436] {logging_mixin.py:109} INFO - [2022-06-07 08:42:06,436] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:42:06,436] {logging_mixin.py:109} INFO - [2022-06-07 08:42:06,436] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1219267

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:42:06,437] {logging_mixin.py:109} INFO - [2022-06-07 08:42:06,437] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:42:06,437] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:42:06,450] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.029 seconds
[2022-06-07 08:42:37,212] {processor.py:163} INFO - Started process (PID=1220362) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:42:37,212] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:42:37,212] {logging_mixin.py:109} INFO - [2022-06-07 08:42:37,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:43:07,223] {logging_mixin.py:109} INFO - [2022-06-07 08:43:07,223] {timeout.py:36} ERROR - Process timed out, PID: 1220362
[2022-06-07 08:43:07,224] {logging_mixin.py:109} INFO - [2022-06-07 08:43:07,223] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1220362
[2022-06-07 08:43:07,224] {logging_mixin.py:109} INFO - [2022-06-07 08:43:07,224] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:43:07,224] {logging_mixin.py:109} INFO - [2022-06-07 08:43:07,224] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1220362

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:43:07,225] {logging_mixin.py:109} INFO - [2022-06-07 08:43:07,225] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:43:07,225] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:43:07,238] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 08:43:37,691] {processor.py:163} INFO - Started process (PID=1221456) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:43:37,692] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:43:37,692] {logging_mixin.py:109} INFO - [2022-06-07 08:43:37,692] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:44:07,693] {logging_mixin.py:109} INFO - [2022-06-07 08:44:07,693] {timeout.py:36} ERROR - Process timed out, PID: 1221456
[2022-06-07 08:44:07,694] {logging_mixin.py:109} INFO - [2022-06-07 08:44:07,693] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1221456
[2022-06-07 08:44:07,694] {logging_mixin.py:109} INFO - [2022-06-07 08:44:07,694] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:44:07,694] {logging_mixin.py:109} INFO - [2022-06-07 08:44:07,694] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1221456

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:44:07,695] {logging_mixin.py:109} INFO - [2022-06-07 08:44:07,695] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:44:07,695] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:44:07,706] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 08:44:38,407] {processor.py:163} INFO - Started process (PID=1222551) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:44:38,408] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:44:38,408] {logging_mixin.py:109} INFO - [2022-06-07 08:44:38,408] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:45:08,409] {logging_mixin.py:109} INFO - [2022-06-07 08:45:08,409] {timeout.py:36} ERROR - Process timed out, PID: 1222551
[2022-06-07 08:45:08,410] {logging_mixin.py:109} INFO - [2022-06-07 08:45:08,410] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1222551
[2022-06-07 08:45:08,410] {logging_mixin.py:109} INFO - [2022-06-07 08:45:08,410] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:45:08,411] {logging_mixin.py:109} INFO - [2022-06-07 08:45:08,410] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1222551

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:45:08,411] {logging_mixin.py:109} INFO - [2022-06-07 08:45:08,411] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:45:08,411] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:45:08,423] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:45:38,958] {processor.py:163} INFO - Started process (PID=1223645) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:45:38,958] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:45:38,958] {logging_mixin.py:109} INFO - [2022-06-07 08:45:38,958] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:46:08,959] {logging_mixin.py:109} INFO - [2022-06-07 08:46:08,959] {timeout.py:36} ERROR - Process timed out, PID: 1223645
[2022-06-07 08:46:08,960] {logging_mixin.py:109} INFO - [2022-06-07 08:46:08,959] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1223645
[2022-06-07 08:46:08,960] {logging_mixin.py:109} INFO - [2022-06-07 08:46:08,960] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:46:08,960] {logging_mixin.py:109} INFO - [2022-06-07 08:46:08,960] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1223645

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:46:08,961] {logging_mixin.py:109} INFO - [2022-06-07 08:46:08,961] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:46:08,961] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:46:08,974] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 08:46:39,791] {processor.py:163} INFO - Started process (PID=1224737) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:46:39,792] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:46:39,792] {logging_mixin.py:109} INFO - [2022-06-07 08:46:39,792] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:47:09,794] {logging_mixin.py:109} INFO - [2022-06-07 08:47:09,794] {timeout.py:36} ERROR - Process timed out, PID: 1224737
[2022-06-07 08:47:09,795] {logging_mixin.py:109} INFO - [2022-06-07 08:47:09,794] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1224737
[2022-06-07 08:47:09,795] {logging_mixin.py:109} INFO - [2022-06-07 08:47:09,795] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:47:09,795] {logging_mixin.py:109} INFO - [2022-06-07 08:47:09,795] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1224737

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:47:09,796] {logging_mixin.py:109} INFO - [2022-06-07 08:47:09,795] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:47:09,796] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:47:09,807] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:47:40,435] {processor.py:163} INFO - Started process (PID=1225831) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:47:40,436] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:47:40,436] {logging_mixin.py:109} INFO - [2022-06-07 08:47:40,436] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:48:10,438] {logging_mixin.py:109} INFO - [2022-06-07 08:48:10,437] {timeout.py:36} ERROR - Process timed out, PID: 1225831
[2022-06-07 08:48:10,438] {logging_mixin.py:109} INFO - [2022-06-07 08:48:10,438] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1225831
[2022-06-07 08:48:10,438] {logging_mixin.py:109} INFO - [2022-06-07 08:48:10,438] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:48:10,439] {logging_mixin.py:109} INFO - [2022-06-07 08:48:10,439] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1225831

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:48:10,439] {logging_mixin.py:109} INFO - [2022-06-07 08:48:10,439] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:48:10,440] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:48:10,451] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:48:41,014] {processor.py:163} INFO - Started process (PID=1226925) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:48:41,015] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:48:41,015] {logging_mixin.py:109} INFO - [2022-06-07 08:48:41,015] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:49:11,016] {logging_mixin.py:109} INFO - [2022-06-07 08:49:11,015] {timeout.py:36} ERROR - Process timed out, PID: 1226925
[2022-06-07 08:49:11,016] {logging_mixin.py:109} INFO - [2022-06-07 08:49:11,016] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1226925
[2022-06-07 08:49:11,016] {logging_mixin.py:109} INFO - [2022-06-07 08:49:11,016] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:49:11,017] {logging_mixin.py:109} INFO - [2022-06-07 08:49:11,017] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1226925

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:49:11,017] {logging_mixin.py:109} INFO - [2022-06-07 08:49:11,017] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:49:11,018] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:49:11,030] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:49:41,482] {processor.py:163} INFO - Started process (PID=1228018) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:49:41,482] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:49:41,483] {logging_mixin.py:109} INFO - [2022-06-07 08:49:41,483] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:50:11,486] {logging_mixin.py:109} INFO - [2022-06-07 08:50:11,485] {timeout.py:36} ERROR - Process timed out, PID: 1228018
[2022-06-07 08:50:11,486] {logging_mixin.py:109} INFO - [2022-06-07 08:50:11,486] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1228018
[2022-06-07 08:50:11,486] {logging_mixin.py:109} INFO - [2022-06-07 08:50:11,486] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:50:11,487] {logging_mixin.py:109} INFO - [2022-06-07 08:50:11,486] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1228018

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:50:11,487] {logging_mixin.py:109} INFO - [2022-06-07 08:50:11,487] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:50:11,487] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:50:11,499] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 08:50:42,117] {processor.py:163} INFO - Started process (PID=1229112) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:50:42,118] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:50:42,119] {logging_mixin.py:109} INFO - [2022-06-07 08:50:42,119] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:51:12,122] {logging_mixin.py:109} INFO - [2022-06-07 08:51:12,121] {timeout.py:36} ERROR - Process timed out, PID: 1229112
[2022-06-07 08:51:12,122] {logging_mixin.py:109} INFO - [2022-06-07 08:51:12,122] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1229112
[2022-06-07 08:51:12,122] {logging_mixin.py:109} INFO - [2022-06-07 08:51:12,122] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:51:12,123] {logging_mixin.py:109} INFO - [2022-06-07 08:51:12,123] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1229112

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:51:12,123] {logging_mixin.py:109} INFO - [2022-06-07 08:51:12,123] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:51:12,123] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:51:12,135] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 08:51:42,204] {processor.py:163} INFO - Started process (PID=1230203) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:51:42,204] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:51:42,204] {logging_mixin.py:109} INFO - [2022-06-07 08:51:42,204] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:52:12,206] {logging_mixin.py:109} INFO - [2022-06-07 08:52:12,206] {timeout.py:36} ERROR - Process timed out, PID: 1230203
[2022-06-07 08:52:12,207] {logging_mixin.py:109} INFO - [2022-06-07 08:52:12,206] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1230203
[2022-06-07 08:52:12,207] {logging_mixin.py:109} INFO - [2022-06-07 08:52:12,207] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:52:12,207] {logging_mixin.py:109} INFO - [2022-06-07 08:52:12,207] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1230203

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:52:12,208] {logging_mixin.py:109} INFO - [2022-06-07 08:52:12,208] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:52:12,208] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:52:12,219] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 08:52:42,802] {processor.py:163} INFO - Started process (PID=1231296) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:52:42,802] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:52:42,803] {logging_mixin.py:109} INFO - [2022-06-07 08:52:42,803] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:53:12,823] {logging_mixin.py:109} INFO - [2022-06-07 08:53:12,822] {timeout.py:36} ERROR - Process timed out, PID: 1231296
[2022-06-07 08:53:12,823] {logging_mixin.py:109} INFO - [2022-06-07 08:53:12,823] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1231296
[2022-06-07 08:53:12,823] {logging_mixin.py:109} INFO - [2022-06-07 08:53:12,823] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:53:12,824] {logging_mixin.py:109} INFO - [2022-06-07 08:53:12,824] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1231296

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:53:12,824] {logging_mixin.py:109} INFO - [2022-06-07 08:53:12,824] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:53:12,825] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:53:12,837] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.036 seconds
[2022-06-07 08:53:43,442] {processor.py:163} INFO - Started process (PID=1232391) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:53:43,442] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:53:43,443] {logging_mixin.py:109} INFO - [2022-06-07 08:53:43,443] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:54:13,449] {logging_mixin.py:109} INFO - [2022-06-07 08:54:13,448] {timeout.py:36} ERROR - Process timed out, PID: 1232391
[2022-06-07 08:54:13,449] {logging_mixin.py:109} INFO - [2022-06-07 08:54:13,449] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1232391
[2022-06-07 08:54:13,449] {logging_mixin.py:109} INFO - [2022-06-07 08:54:13,449] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:54:13,450] {logging_mixin.py:109} INFO - [2022-06-07 08:54:13,450] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1232391

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:54:13,450] {logging_mixin.py:109} INFO - [2022-06-07 08:54:13,450] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:54:13,451] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:54:13,464] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 08:54:44,215] {processor.py:163} INFO - Started process (PID=1233486) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:54:44,216] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:54:44,216] {logging_mixin.py:109} INFO - [2022-06-07 08:54:44,216] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:55:14,224] {logging_mixin.py:109} INFO - [2022-06-07 08:55:14,224] {timeout.py:36} ERROR - Process timed out, PID: 1233486
[2022-06-07 08:55:14,225] {logging_mixin.py:109} INFO - [2022-06-07 08:55:14,224] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1233486
[2022-06-07 08:55:14,225] {logging_mixin.py:109} INFO - [2022-06-07 08:55:14,225] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:55:14,225] {logging_mixin.py:109} INFO - [2022-06-07 08:55:14,225] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1233486

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:55:14,226] {logging_mixin.py:109} INFO - [2022-06-07 08:55:14,225] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:55:14,226] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:55:14,237] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 08:55:44,696] {processor.py:163} INFO - Started process (PID=1234579) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:55:44,697] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:55:44,697] {logging_mixin.py:109} INFO - [2022-06-07 08:55:44,697] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:56:14,700] {logging_mixin.py:109} INFO - [2022-06-07 08:56:14,699] {timeout.py:36} ERROR - Process timed out, PID: 1234579
[2022-06-07 08:56:14,700] {logging_mixin.py:109} INFO - [2022-06-07 08:56:14,700] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1234579
[2022-06-07 08:56:14,700] {logging_mixin.py:109} INFO - [2022-06-07 08:56:14,700] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:56:14,701] {logging_mixin.py:109} INFO - [2022-06-07 08:56:14,700] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1234579

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:56:14,701] {logging_mixin.py:109} INFO - [2022-06-07 08:56:14,701] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:56:14,701] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:56:14,713] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 08:56:45,222] {processor.py:163} INFO - Started process (PID=1235673) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:56:45,223] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:56:45,223] {logging_mixin.py:109} INFO - [2022-06-07 08:56:45,223] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:57:15,229] {logging_mixin.py:109} INFO - [2022-06-07 08:57:15,229] {timeout.py:36} ERROR - Process timed out, PID: 1235673
[2022-06-07 08:57:15,230] {logging_mixin.py:109} INFO - [2022-06-07 08:57:15,229] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1235673
[2022-06-07 08:57:15,230] {logging_mixin.py:109} INFO - [2022-06-07 08:57:15,230] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:57:15,231] {logging_mixin.py:109} INFO - [2022-06-07 08:57:15,230] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1235673

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:57:15,231] {logging_mixin.py:109} INFO - [2022-06-07 08:57:15,231] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:57:15,231] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:57:15,243] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 08:57:45,660] {processor.py:163} INFO - Started process (PID=1236766) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:57:45,660] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:57:45,660] {logging_mixin.py:109} INFO - [2022-06-07 08:57:45,660] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:58:15,673] {logging_mixin.py:109} INFO - [2022-06-07 08:58:15,673] {timeout.py:36} ERROR - Process timed out, PID: 1236766
[2022-06-07 08:58:15,674] {logging_mixin.py:109} INFO - [2022-06-07 08:58:15,674] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1236766
[2022-06-07 08:58:15,674] {logging_mixin.py:109} INFO - [2022-06-07 08:58:15,674] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:58:15,675] {logging_mixin.py:109} INFO - [2022-06-07 08:58:15,674] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1236766

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:58:15,675] {logging_mixin.py:109} INFO - [2022-06-07 08:58:15,675] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:58:15,675] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:58:15,686] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 08:58:46,193] {processor.py:163} INFO - Started process (PID=1237861) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:58:46,193] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:58:46,194] {logging_mixin.py:109} INFO - [2022-06-07 08:58:46,194] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:59:16,197] {logging_mixin.py:109} INFO - [2022-06-07 08:59:16,197] {timeout.py:36} ERROR - Process timed out, PID: 1237861
[2022-06-07 08:59:16,198] {logging_mixin.py:109} INFO - [2022-06-07 08:59:16,197] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1237861
[2022-06-07 08:59:16,198] {logging_mixin.py:109} INFO - [2022-06-07 08:59:16,198] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 08:59:16,199] {logging_mixin.py:109} INFO - [2022-06-07 08:59:16,198] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1237861

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 08:59:16,199] {logging_mixin.py:109} INFO - [2022-06-07 08:59:16,199] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 08:59:16,199] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 08:59:16,211] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 08:59:46,718] {processor.py:163} INFO - Started process (PID=1238957) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 08:59:46,719] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 08:59:46,719] {logging_mixin.py:109} INFO - [2022-06-07 08:59:46,719] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:00:16,721] {logging_mixin.py:109} INFO - [2022-06-07 09:00:16,721] {timeout.py:36} ERROR - Process timed out, PID: 1238957
[2022-06-07 09:00:16,722] {logging_mixin.py:109} INFO - [2022-06-07 09:00:16,722] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1238957
[2022-06-07 09:00:16,722] {logging_mixin.py:109} INFO - [2022-06-07 09:00:16,722] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:00:16,723] {logging_mixin.py:109} INFO - [2022-06-07 09:00:16,722] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1238957

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:00:16,723] {logging_mixin.py:109} INFO - [2022-06-07 09:00:16,723] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:00:16,723] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:00:16,735] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:00:47,287] {processor.py:163} INFO - Started process (PID=1240051) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:00:47,288] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:00:47,288] {logging_mixin.py:109} INFO - [2022-06-07 09:00:47,288] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:01:17,289] {logging_mixin.py:109} INFO - [2022-06-07 09:01:17,289] {timeout.py:36} ERROR - Process timed out, PID: 1240051
[2022-06-07 09:01:17,295] {logging_mixin.py:109} INFO - [2022-06-07 09:01:17,289] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1240051
[2022-06-07 09:01:17,295] {logging_mixin.py:109} INFO - [2022-06-07 09:01:17,295] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:01:17,295] {logging_mixin.py:109} INFO - [2022-06-07 09:01:17,295] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1240051

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:01:17,296] {logging_mixin.py:109} INFO - [2022-06-07 09:01:17,295] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:01:17,296] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:01:17,308] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 09:01:47,508] {processor.py:163} INFO - Started process (PID=1241145) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:01:47,508] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:01:47,508] {logging_mixin.py:109} INFO - [2022-06-07 09:01:47,508] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:02:17,509] {logging_mixin.py:109} INFO - [2022-06-07 09:02:17,509] {timeout.py:36} ERROR - Process timed out, PID: 1241145
[2022-06-07 09:02:17,510] {logging_mixin.py:109} INFO - [2022-06-07 09:02:17,509] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1241145
[2022-06-07 09:02:17,510] {logging_mixin.py:109} INFO - [2022-06-07 09:02:17,510] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:02:17,510] {logging_mixin.py:109} INFO - [2022-06-07 09:02:17,510] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1241145

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:02:17,511] {logging_mixin.py:109} INFO - [2022-06-07 09:02:17,511] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:02:17,511] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:02:17,522] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 09:02:47,854] {processor.py:163} INFO - Started process (PID=1242209) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:02:47,855] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:02:47,855] {logging_mixin.py:109} INFO - [2022-06-07 09:02:47,855] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:03:17,856] {logging_mixin.py:109} INFO - [2022-06-07 09:03:17,856] {timeout.py:36} ERROR - Process timed out, PID: 1242209
[2022-06-07 09:03:17,857] {logging_mixin.py:109} INFO - [2022-06-07 09:03:17,856] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1242209
[2022-06-07 09:03:17,857] {logging_mixin.py:109} INFO - [2022-06-07 09:03:17,857] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:03:17,857] {logging_mixin.py:109} INFO - [2022-06-07 09:03:17,857] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1242209

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:03:17,858] {logging_mixin.py:109} INFO - [2022-06-07 09:03:17,858] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:03:17,858] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:03:17,870] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:03:48,034] {processor.py:163} INFO - Started process (PID=1243303) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:03:48,035] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:03:48,035] {logging_mixin.py:109} INFO - [2022-06-07 09:03:48,035] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:04:18,037] {logging_mixin.py:109} INFO - [2022-06-07 09:04:18,037] {timeout.py:36} ERROR - Process timed out, PID: 1243303
[2022-06-07 09:04:18,038] {logging_mixin.py:109} INFO - [2022-06-07 09:04:18,037] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1243303
[2022-06-07 09:04:18,038] {logging_mixin.py:109} INFO - [2022-06-07 09:04:18,038] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:04:18,038] {logging_mixin.py:109} INFO - [2022-06-07 09:04:18,038] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1243303

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:04:18,039] {logging_mixin.py:109} INFO - [2022-06-07 09:04:18,038] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:04:18,039] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:04:18,050] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:04:48,136] {processor.py:163} INFO - Started process (PID=1244394) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:04:48,137] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:04:48,137] {logging_mixin.py:109} INFO - [2022-06-07 09:04:48,137] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:05:18,138] {logging_mixin.py:109} INFO - [2022-06-07 09:05:18,138] {timeout.py:36} ERROR - Process timed out, PID: 1244394
[2022-06-07 09:05:18,139] {logging_mixin.py:109} INFO - [2022-06-07 09:05:18,138] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1244394
[2022-06-07 09:05:18,139] {logging_mixin.py:109} INFO - [2022-06-07 09:05:18,139] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:05:18,139] {logging_mixin.py:109} INFO - [2022-06-07 09:05:18,139] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1244394

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:05:18,140] {logging_mixin.py:109} INFO - [2022-06-07 09:05:18,139] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:05:18,140] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:05:18,153] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:05:48,236] {processor.py:163} INFO - Started process (PID=1245415) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:05:48,237] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:05:48,237] {logging_mixin.py:109} INFO - [2022-06-07 09:05:48,237] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:06:18,240] {logging_mixin.py:109} INFO - [2022-06-07 09:06:18,239] {timeout.py:36} ERROR - Process timed out, PID: 1245415
[2022-06-07 09:06:18,240] {logging_mixin.py:109} INFO - [2022-06-07 09:06:18,240] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1245415
[2022-06-07 09:06:18,240] {logging_mixin.py:109} INFO - [2022-06-07 09:06:18,240] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:06:18,241] {logging_mixin.py:109} INFO - [2022-06-07 09:06:18,240] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1245415

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:06:18,241] {logging_mixin.py:109} INFO - [2022-06-07 09:06:18,241] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:06:18,241] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:06:18,256] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 09:06:49,175] {processor.py:163} INFO - Started process (PID=1246508) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:06:49,175] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:06:49,176] {logging_mixin.py:109} INFO - [2022-06-07 09:06:49,176] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:07:19,178] {logging_mixin.py:109} INFO - [2022-06-07 09:07:19,177] {timeout.py:36} ERROR - Process timed out, PID: 1246508
[2022-06-07 09:07:19,178] {logging_mixin.py:109} INFO - [2022-06-07 09:07:19,178] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1246508
[2022-06-07 09:07:19,178] {logging_mixin.py:109} INFO - [2022-06-07 09:07:19,178] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:07:19,179] {logging_mixin.py:109} INFO - [2022-06-07 09:07:19,178] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1246508

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:07:19,179] {logging_mixin.py:109} INFO - [2022-06-07 09:07:19,179] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:07:19,179] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:07:19,190] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:07:49,350] {processor.py:163} INFO - Started process (PID=1247599) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:07:49,351] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:07:49,351] {logging_mixin.py:109} INFO - [2022-06-07 09:07:49,351] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:08:19,352] {logging_mixin.py:109} INFO - [2022-06-07 09:08:19,352] {timeout.py:36} ERROR - Process timed out, PID: 1247599
[2022-06-07 09:08:19,352] {logging_mixin.py:109} INFO - [2022-06-07 09:08:19,352] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1247599
[2022-06-07 09:08:19,353] {logging_mixin.py:109} INFO - [2022-06-07 09:08:19,353] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:08:19,353] {logging_mixin.py:109} INFO - [2022-06-07 09:08:19,353] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1247599

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:08:19,353] {logging_mixin.py:109} INFO - [2022-06-07 09:08:19,353] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:08:19,354] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:08:19,365] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 09:08:49,897] {processor.py:163} INFO - Started process (PID=1248639) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:08:49,898] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:08:49,898] {logging_mixin.py:109} INFO - [2022-06-07 09:08:49,898] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:09:19,899] {logging_mixin.py:109} INFO - [2022-06-07 09:09:19,899] {timeout.py:36} ERROR - Process timed out, PID: 1248639
[2022-06-07 09:09:19,900] {logging_mixin.py:109} INFO - [2022-06-07 09:09:19,899] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1248639
[2022-06-07 09:09:19,900] {logging_mixin.py:109} INFO - [2022-06-07 09:09:19,900] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:09:19,900] {logging_mixin.py:109} INFO - [2022-06-07 09:09:19,900] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1248639

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:09:19,901] {logging_mixin.py:109} INFO - [2022-06-07 09:09:19,901] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:09:19,901] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:09:19,914] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 09:09:50,334] {processor.py:163} INFO - Started process (PID=1249730) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:09:50,335] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:09:50,335] {logging_mixin.py:109} INFO - [2022-06-07 09:09:50,335] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:10:20,338] {logging_mixin.py:109} INFO - [2022-06-07 09:10:20,338] {timeout.py:36} ERROR - Process timed out, PID: 1249730
[2022-06-07 09:10:20,339] {logging_mixin.py:109} INFO - [2022-06-07 09:10:20,338] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1249730
[2022-06-07 09:10:20,339] {logging_mixin.py:109} INFO - [2022-06-07 09:10:20,339] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:10:20,339] {logging_mixin.py:109} INFO - [2022-06-07 09:10:20,339] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1249730

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:10:20,339] {logging_mixin.py:109} INFO - [2022-06-07 09:10:20,339] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:10:20,340] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:10:20,351] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:10:51,339] {processor.py:163} INFO - Started process (PID=1250823) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:10:51,339] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:10:51,340] {logging_mixin.py:109} INFO - [2022-06-07 09:10:51,340] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:11:21,347] {logging_mixin.py:109} INFO - [2022-06-07 09:11:21,346] {timeout.py:36} ERROR - Process timed out, PID: 1250823
[2022-06-07 09:11:21,347] {logging_mixin.py:109} INFO - [2022-06-07 09:11:21,347] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1250823
[2022-06-07 09:11:21,347] {logging_mixin.py:109} INFO - [2022-06-07 09:11:21,347] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:11:21,348] {logging_mixin.py:109} INFO - [2022-06-07 09:11:21,348] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1250823

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:11:21,348] {logging_mixin.py:109} INFO - [2022-06-07 09:11:21,348] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:11:21,348] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:11:21,359] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 09:11:52,284] {processor.py:163} INFO - Started process (PID=1251916) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:11:52,285] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:11:52,285] {logging_mixin.py:109} INFO - [2022-06-07 09:11:52,285] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:12:22,287] {logging_mixin.py:109} INFO - [2022-06-07 09:12:22,286] {timeout.py:36} ERROR - Process timed out, PID: 1251916
[2022-06-07 09:12:22,287] {logging_mixin.py:109} INFO - [2022-06-07 09:12:22,287] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1251916
[2022-06-07 09:12:22,287] {logging_mixin.py:109} INFO - [2022-06-07 09:12:22,287] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:12:22,288] {logging_mixin.py:109} INFO - [2022-06-07 09:12:22,287] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1251916

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:12:22,288] {logging_mixin.py:109} INFO - [2022-06-07 09:12:22,288] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:12:22,288] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:12:22,300] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:12:53,319] {processor.py:163} INFO - Started process (PID=1253010) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:12:53,319] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:12:53,319] {logging_mixin.py:109} INFO - [2022-06-07 09:12:53,319] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:13:23,320] {logging_mixin.py:109} INFO - [2022-06-07 09:13:23,320] {timeout.py:36} ERROR - Process timed out, PID: 1253010
[2022-06-07 09:13:23,321] {logging_mixin.py:109} INFO - [2022-06-07 09:13:23,320] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1253010
[2022-06-07 09:13:23,321] {logging_mixin.py:109} INFO - [2022-06-07 09:13:23,321] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:13:23,321] {logging_mixin.py:109} INFO - [2022-06-07 09:13:23,321] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1253010

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:13:23,322] {logging_mixin.py:109} INFO - [2022-06-07 09:13:23,322] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:13:23,322] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:13:23,334] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 09:13:54,211] {processor.py:163} INFO - Started process (PID=1254104) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:13:54,212] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:13:54,212] {logging_mixin.py:109} INFO - [2022-06-07 09:13:54,212] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:14:24,215] {logging_mixin.py:109} INFO - [2022-06-07 09:14:24,215] {timeout.py:36} ERROR - Process timed out, PID: 1254104
[2022-06-07 09:14:24,216] {logging_mixin.py:109} INFO - [2022-06-07 09:14:24,215] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1254104
[2022-06-07 09:14:24,216] {logging_mixin.py:109} INFO - [2022-06-07 09:14:24,216] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:14:24,216] {logging_mixin.py:109} INFO - [2022-06-07 09:14:24,216] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1254104

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:14:24,217] {logging_mixin.py:109} INFO - [2022-06-07 09:14:24,217] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:14:24,217] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:14:24,228] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:14:54,389] {processor.py:163} INFO - Started process (PID=1255199) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:14:54,389] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:14:54,389] {logging_mixin.py:109} INFO - [2022-06-07 09:14:54,389] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:15:24,399] {logging_mixin.py:109} INFO - [2022-06-07 09:15:24,399] {timeout.py:36} ERROR - Process timed out, PID: 1255199
[2022-06-07 09:15:24,400] {logging_mixin.py:109} INFO - [2022-06-07 09:15:24,399] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1255199
[2022-06-07 09:15:24,400] {logging_mixin.py:109} INFO - [2022-06-07 09:15:24,400] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:15:24,400] {logging_mixin.py:109} INFO - [2022-06-07 09:15:24,400] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1255199

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:15:24,401] {logging_mixin.py:109} INFO - [2022-06-07 09:15:24,400] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:15:24,401] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:15:24,413] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 09:15:54,680] {processor.py:163} INFO - Started process (PID=1256292) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:15:54,681] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:15:54,681] {logging_mixin.py:109} INFO - [2022-06-07 09:15:54,681] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:16:24,683] {logging_mixin.py:109} INFO - [2022-06-07 09:16:24,682] {timeout.py:36} ERROR - Process timed out, PID: 1256292
[2022-06-07 09:16:24,683] {logging_mixin.py:109} INFO - [2022-06-07 09:16:24,683] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1256292
[2022-06-07 09:16:24,683] {logging_mixin.py:109} INFO - [2022-06-07 09:16:24,683] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:16:24,684] {logging_mixin.py:109} INFO - [2022-06-07 09:16:24,683] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1256292

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:16:24,684] {logging_mixin.py:109} INFO - [2022-06-07 09:16:24,684] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:16:24,685] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:16:24,696] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:16:54,860] {processor.py:163} INFO - Started process (PID=1257387) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:16:54,860] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:16:54,860] {logging_mixin.py:109} INFO - [2022-06-07 09:16:54,860] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:17:24,877] {logging_mixin.py:109} INFO - [2022-06-07 09:17:24,877] {timeout.py:36} ERROR - Process timed out, PID: 1257387
[2022-06-07 09:17:24,877] {logging_mixin.py:109} INFO - [2022-06-07 09:17:24,877] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1257387
[2022-06-07 09:17:24,878] {logging_mixin.py:109} INFO - [2022-06-07 09:17:24,878] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:17:24,878] {logging_mixin.py:109} INFO - [2022-06-07 09:17:24,878] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1257387

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:17:24,878] {logging_mixin.py:109} INFO - [2022-06-07 09:17:24,878] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:17:24,879] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:17:24,891] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.033 seconds
[2022-06-07 09:17:54,991] {processor.py:163} INFO - Started process (PID=1258481) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:17:54,992] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:17:54,992] {logging_mixin.py:109} INFO - [2022-06-07 09:17:54,992] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:18:24,993] {logging_mixin.py:109} INFO - [2022-06-07 09:18:24,992] {timeout.py:36} ERROR - Process timed out, PID: 1258481
[2022-06-07 09:18:24,994] {logging_mixin.py:109} INFO - [2022-06-07 09:18:24,993] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1258481
[2022-06-07 09:18:24,994] {logging_mixin.py:109} INFO - [2022-06-07 09:18:24,994] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:18:24,995] {logging_mixin.py:109} INFO - [2022-06-07 09:18:24,994] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1258481

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:18:24,995] {logging_mixin.py:109} INFO - [2022-06-07 09:18:24,995] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:18:24,995] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:18:25,007] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:18:55,702] {processor.py:163} INFO - Started process (PID=1259576) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:18:55,703] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:18:55,703] {logging_mixin.py:109} INFO - [2022-06-07 09:18:55,703] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:19:25,710] {logging_mixin.py:109} INFO - [2022-06-07 09:19:25,709] {timeout.py:36} ERROR - Process timed out, PID: 1259576
[2022-06-07 09:19:25,710] {logging_mixin.py:109} INFO - [2022-06-07 09:19:25,710] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1259576
[2022-06-07 09:19:25,710] {logging_mixin.py:109} INFO - [2022-06-07 09:19:25,710] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:19:25,711] {logging_mixin.py:109} INFO - [2022-06-07 09:19:25,711] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1259576

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:19:25,711] {logging_mixin.py:109} INFO - [2022-06-07 09:19:25,711] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:19:25,711] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:19:25,723] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 09:19:56,711] {processor.py:163} INFO - Started process (PID=1260670) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:19:56,711] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:19:56,711] {logging_mixin.py:109} INFO - [2022-06-07 09:19:56,711] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:20:26,713] {logging_mixin.py:109} INFO - [2022-06-07 09:20:26,712] {timeout.py:36} ERROR - Process timed out, PID: 1260670
[2022-06-07 09:20:26,713] {logging_mixin.py:109} INFO - [2022-06-07 09:20:26,713] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1260670
[2022-06-07 09:20:26,713] {logging_mixin.py:109} INFO - [2022-06-07 09:20:26,713] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:20:26,714] {logging_mixin.py:109} INFO - [2022-06-07 09:20:26,714] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1260670

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:20:26,714] {logging_mixin.py:109} INFO - [2022-06-07 09:20:26,714] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:20:26,715] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:20:26,726] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:20:57,327] {processor.py:163} INFO - Started process (PID=1261763) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:20:57,327] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:20:57,328] {logging_mixin.py:109} INFO - [2022-06-07 09:20:57,327] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:21:27,331] {logging_mixin.py:109} INFO - [2022-06-07 09:21:27,330] {timeout.py:36} ERROR - Process timed out, PID: 1261763
[2022-06-07 09:21:27,331] {logging_mixin.py:109} INFO - [2022-06-07 09:21:27,331] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1261763
[2022-06-07 09:21:27,331] {logging_mixin.py:109} INFO - [2022-06-07 09:21:27,331] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:21:27,332] {logging_mixin.py:109} INFO - [2022-06-07 09:21:27,331] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1261763

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:21:27,332] {logging_mixin.py:109} INFO - [2022-06-07 09:21:27,332] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:21:27,332] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:21:27,343] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:21:57,982] {processor.py:163} INFO - Started process (PID=1262856) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:21:57,982] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:21:57,983] {logging_mixin.py:109} INFO - [2022-06-07 09:21:57,983] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:22:27,984] {logging_mixin.py:109} INFO - [2022-06-07 09:22:27,984] {timeout.py:36} ERROR - Process timed out, PID: 1262856
[2022-06-07 09:22:27,985] {logging_mixin.py:109} INFO - [2022-06-07 09:22:27,985] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1262856
[2022-06-07 09:22:27,985] {logging_mixin.py:109} INFO - [2022-06-07 09:22:27,985] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:22:27,986] {logging_mixin.py:109} INFO - [2022-06-07 09:22:27,985] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1262856

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:22:27,986] {logging_mixin.py:109} INFO - [2022-06-07 09:22:27,986] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:22:27,986] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:22:27,998] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:22:58,861] {processor.py:163} INFO - Started process (PID=1263950) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:22:58,861] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:22:58,862] {logging_mixin.py:109} INFO - [2022-06-07 09:22:58,862] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:23:28,866] {logging_mixin.py:109} INFO - [2022-06-07 09:23:28,865] {timeout.py:36} ERROR - Process timed out, PID: 1263950
[2022-06-07 09:23:28,866] {logging_mixin.py:109} INFO - [2022-06-07 09:23:28,866] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1263950
[2022-06-07 09:23:28,867] {logging_mixin.py:109} INFO - [2022-06-07 09:23:28,867] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:23:28,867] {logging_mixin.py:109} INFO - [2022-06-07 09:23:28,867] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1263950

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:23:28,868] {logging_mixin.py:109} INFO - [2022-06-07 09:23:28,867] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:23:28,868] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:23:28,883] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 09:23:58,931] {processor.py:163} INFO - Started process (PID=1265044) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:23:58,931] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:23:58,932] {logging_mixin.py:109} INFO - [2022-06-07 09:23:58,932] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:24:28,933] {logging_mixin.py:109} INFO - [2022-06-07 09:24:28,933] {timeout.py:36} ERROR - Process timed out, PID: 1265044
[2022-06-07 09:24:28,934] {logging_mixin.py:109} INFO - [2022-06-07 09:24:28,933] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1265044
[2022-06-07 09:24:28,934] {logging_mixin.py:109} INFO - [2022-06-07 09:24:28,934] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:24:28,934] {logging_mixin.py:109} INFO - [2022-06-07 09:24:28,934] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1265044

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:24:28,935] {logging_mixin.py:109} INFO - [2022-06-07 09:24:28,935] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:24:28,935] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:24:28,947] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:24:59,409] {processor.py:163} INFO - Started process (PID=1266137) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:24:59,410] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:24:59,410] {logging_mixin.py:109} INFO - [2022-06-07 09:24:59,410] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:25:29,412] {logging_mixin.py:109} INFO - [2022-06-07 09:25:29,411] {timeout.py:36} ERROR - Process timed out, PID: 1266137
[2022-06-07 09:25:29,412] {logging_mixin.py:109} INFO - [2022-06-07 09:25:29,412] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1266137
[2022-06-07 09:25:29,412] {logging_mixin.py:109} INFO - [2022-06-07 09:25:29,412] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:25:29,413] {logging_mixin.py:109} INFO - [2022-06-07 09:25:29,413] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1266137

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:25:29,413] {logging_mixin.py:109} INFO - [2022-06-07 09:25:29,413] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:25:29,414] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:25:29,425] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:26:00,335] {processor.py:163} INFO - Started process (PID=1267232) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:26:00,336] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:26:00,336] {logging_mixin.py:109} INFO - [2022-06-07 09:26:00,336] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:26:30,337] {logging_mixin.py:109} INFO - [2022-06-07 09:26:30,337] {timeout.py:36} ERROR - Process timed out, PID: 1267232
[2022-06-07 09:26:30,338] {logging_mixin.py:109} INFO - [2022-06-07 09:26:30,337] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1267232
[2022-06-07 09:26:30,338] {logging_mixin.py:109} INFO - [2022-06-07 09:26:30,338] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:26:30,338] {logging_mixin.py:109} INFO - [2022-06-07 09:26:30,338] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1267232

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:26:30,339] {logging_mixin.py:109} INFO - [2022-06-07 09:26:30,338] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:26:30,339] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:26:30,350] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 09:27:00,379] {processor.py:163} INFO - Started process (PID=1268326) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:27:00,379] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:27:00,379] {logging_mixin.py:109} INFO - [2022-06-07 09:27:00,379] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:27:30,388] {logging_mixin.py:109} INFO - [2022-06-07 09:27:30,387] {timeout.py:36} ERROR - Process timed out, PID: 1268326
[2022-06-07 09:27:30,388] {logging_mixin.py:109} INFO - [2022-06-07 09:27:30,388] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1268326
[2022-06-07 09:27:30,388] {logging_mixin.py:109} INFO - [2022-06-07 09:27:30,388] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:27:30,389] {logging_mixin.py:109} INFO - [2022-06-07 09:27:30,388] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1268326

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:27:30,389] {logging_mixin.py:109} INFO - [2022-06-07 09:27:30,389] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:27:30,389] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:27:30,401] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 09:28:01,000] {processor.py:163} INFO - Started process (PID=1269420) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:28:01,000] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:28:01,000] {logging_mixin.py:109} INFO - [2022-06-07 09:28:01,000] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:28:31,004] {logging_mixin.py:109} INFO - [2022-06-07 09:28:31,004] {timeout.py:36} ERROR - Process timed out, PID: 1269420
[2022-06-07 09:28:31,005] {logging_mixin.py:109} INFO - [2022-06-07 09:28:31,004] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1269420
[2022-06-07 09:28:31,005] {logging_mixin.py:109} INFO - [2022-06-07 09:28:31,005] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:28:31,006] {logging_mixin.py:109} INFO - [2022-06-07 09:28:31,005] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1269420

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:28:31,006] {logging_mixin.py:109} INFO - [2022-06-07 09:28:31,006] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:28:31,006] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:28:31,018] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 09:29:01,749] {processor.py:163} INFO - Started process (PID=1270515) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:29:01,750] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:29:01,750] {logging_mixin.py:109} INFO - [2022-06-07 09:29:01,750] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:29:31,752] {logging_mixin.py:109} INFO - [2022-06-07 09:29:31,751] {timeout.py:36} ERROR - Process timed out, PID: 1270515
[2022-06-07 09:29:31,752] {logging_mixin.py:109} INFO - [2022-06-07 09:29:31,752] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1270515
[2022-06-07 09:29:31,752] {logging_mixin.py:109} INFO - [2022-06-07 09:29:31,752] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:29:31,753] {logging_mixin.py:109} INFO - [2022-06-07 09:29:31,753] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1270515

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:29:31,753] {logging_mixin.py:109} INFO - [2022-06-07 09:29:31,753] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:29:31,754] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:29:31,766] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:30:02,157] {processor.py:163} INFO - Started process (PID=1271610) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:30:02,158] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:30:02,158] {logging_mixin.py:109} INFO - [2022-06-07 09:30:02,158] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:30:32,160] {logging_mixin.py:109} INFO - [2022-06-07 09:30:32,160] {timeout.py:36} ERROR - Process timed out, PID: 1271610
[2022-06-07 09:30:32,160] {logging_mixin.py:109} INFO - [2022-06-07 09:30:32,160] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1271610
[2022-06-07 09:30:32,161] {logging_mixin.py:109} INFO - [2022-06-07 09:30:32,161] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:30:32,161] {logging_mixin.py:109} INFO - [2022-06-07 09:30:32,161] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1271610

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:30:32,161] {logging_mixin.py:109} INFO - [2022-06-07 09:30:32,161] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:30:32,162] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:30:32,174] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:31:02,895] {processor.py:163} INFO - Started process (PID=1272703) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:31:02,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:31:02,896] {logging_mixin.py:109} INFO - [2022-06-07 09:31:02,896] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:31:32,903] {logging_mixin.py:109} INFO - [2022-06-07 09:31:32,903] {timeout.py:36} ERROR - Process timed out, PID: 1272703
[2022-06-07 09:31:32,904] {logging_mixin.py:109} INFO - [2022-06-07 09:31:32,903] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1272703
[2022-06-07 09:31:32,904] {logging_mixin.py:109} INFO - [2022-06-07 09:31:32,904] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:31:32,904] {logging_mixin.py:109} INFO - [2022-06-07 09:31:32,904] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1272703

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:31:32,905] {logging_mixin.py:109} INFO - [2022-06-07 09:31:32,904] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:31:32,905] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:31:32,916] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 09:32:03,498] {processor.py:163} INFO - Started process (PID=1273797) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:32:03,498] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:32:03,498] {logging_mixin.py:109} INFO - [2022-06-07 09:32:03,498] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:32:33,499] {logging_mixin.py:109} INFO - [2022-06-07 09:32:33,499] {timeout.py:36} ERROR - Process timed out, PID: 1273797
[2022-06-07 09:32:33,500] {logging_mixin.py:109} INFO - [2022-06-07 09:32:33,500] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1273797
[2022-06-07 09:32:33,500] {logging_mixin.py:109} INFO - [2022-06-07 09:32:33,500] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:32:33,501] {logging_mixin.py:109} INFO - [2022-06-07 09:32:33,500] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1273797

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:32:33,501] {logging_mixin.py:109} INFO - [2022-06-07 09:32:33,501] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:32:33,501] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:32:33,512] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 09:33:04,105] {processor.py:163} INFO - Started process (PID=1274891) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:33:04,105] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:33:04,105] {logging_mixin.py:109} INFO - [2022-06-07 09:33:04,105] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:33:34,109] {logging_mixin.py:109} INFO - [2022-06-07 09:33:34,108] {timeout.py:36} ERROR - Process timed out, PID: 1274891
[2022-06-07 09:33:34,109] {logging_mixin.py:109} INFO - [2022-06-07 09:33:34,109] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1274891
[2022-06-07 09:33:34,109] {logging_mixin.py:109} INFO - [2022-06-07 09:33:34,109] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:33:34,110] {logging_mixin.py:109} INFO - [2022-06-07 09:33:34,110] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1274891

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:33:34,110] {logging_mixin.py:109} INFO - [2022-06-07 09:33:34,110] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:33:34,111] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:33:34,122] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 09:34:04,655] {processor.py:163} INFO - Started process (PID=1275984) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:34:04,655] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:34:04,656] {logging_mixin.py:109} INFO - [2022-06-07 09:34:04,656] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:34:34,657] {logging_mixin.py:109} INFO - [2022-06-07 09:34:34,656] {timeout.py:36} ERROR - Process timed out, PID: 1275984
[2022-06-07 09:34:34,657] {logging_mixin.py:109} INFO - [2022-06-07 09:34:34,657] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1275984
[2022-06-07 09:34:34,657] {logging_mixin.py:109} INFO - [2022-06-07 09:34:34,657] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:34:34,658] {logging_mixin.py:109} INFO - [2022-06-07 09:34:34,658] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1275984

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:34:34,658] {logging_mixin.py:109} INFO - [2022-06-07 09:34:34,658] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:34:34,659] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:34:34,670] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 09:35:04,970] {processor.py:163} INFO - Started process (PID=1277039) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:35:04,970] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:35:04,970] {logging_mixin.py:109} INFO - [2022-06-07 09:35:04,970] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:35:34,972] {logging_mixin.py:109} INFO - [2022-06-07 09:35:34,972] {timeout.py:36} ERROR - Process timed out, PID: 1277039
[2022-06-07 09:35:34,973] {logging_mixin.py:109} INFO - [2022-06-07 09:35:34,972] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1277039
[2022-06-07 09:35:34,973] {logging_mixin.py:109} INFO - [2022-06-07 09:35:34,973] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:35:34,973] {logging_mixin.py:109} INFO - [2022-06-07 09:35:34,973] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1277039

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:35:34,974] {logging_mixin.py:109} INFO - [2022-06-07 09:35:34,974] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:35:34,974] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:35:34,986] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:36:05,655] {processor.py:163} INFO - Started process (PID=1278114) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:36:05,656] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:36:05,656] {logging_mixin.py:109} INFO - [2022-06-07 09:36:05,656] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:36:35,661] {logging_mixin.py:109} INFO - [2022-06-07 09:36:35,661] {timeout.py:36} ERROR - Process timed out, PID: 1278114
[2022-06-07 09:36:35,662] {logging_mixin.py:109} INFO - [2022-06-07 09:36:35,662] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1278114
[2022-06-07 09:36:35,662] {logging_mixin.py:109} INFO - [2022-06-07 09:36:35,662] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:36:35,663] {logging_mixin.py:109} INFO - [2022-06-07 09:36:35,662] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1278114

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:36:35,663] {logging_mixin.py:109} INFO - [2022-06-07 09:36:35,663] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:36:35,663] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:36:35,675] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 09:37:06,147] {processor.py:163} INFO - Started process (PID=1279208) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:37:06,147] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:37:06,147] {logging_mixin.py:109} INFO - [2022-06-07 09:37:06,147] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:37:36,149] {logging_mixin.py:109} INFO - [2022-06-07 09:37:36,148] {timeout.py:36} ERROR - Process timed out, PID: 1279208
[2022-06-07 09:37:36,149] {logging_mixin.py:109} INFO - [2022-06-07 09:37:36,149] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1279208
[2022-06-07 09:37:36,149] {logging_mixin.py:109} INFO - [2022-06-07 09:37:36,149] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:37:36,150] {logging_mixin.py:109} INFO - [2022-06-07 09:37:36,149] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1279208

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:37:36,150] {logging_mixin.py:109} INFO - [2022-06-07 09:37:36,150] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:37:36,150] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:37:36,161] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 09:38:06,957] {processor.py:163} INFO - Started process (PID=1280302) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:38:06,957] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:38:06,957] {logging_mixin.py:109} INFO - [2022-06-07 09:38:06,957] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:38:36,958] {logging_mixin.py:109} INFO - [2022-06-07 09:38:36,958] {timeout.py:36} ERROR - Process timed out, PID: 1280302
[2022-06-07 09:38:36,959] {logging_mixin.py:109} INFO - [2022-06-07 09:38:36,958] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1280302
[2022-06-07 09:38:36,959] {logging_mixin.py:109} INFO - [2022-06-07 09:38:36,959] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:38:36,959] {logging_mixin.py:109} INFO - [2022-06-07 09:38:36,959] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1280302

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:38:36,960] {logging_mixin.py:109} INFO - [2022-06-07 09:38:36,960] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:38:36,960] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:38:36,972] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 09:39:07,792] {processor.py:163} INFO - Started process (PID=1281395) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:39:07,792] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:39:07,793] {logging_mixin.py:109} INFO - [2022-06-07 09:39:07,792] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:39:37,810] {logging_mixin.py:109} INFO - [2022-06-07 09:39:37,810] {timeout.py:36} ERROR - Process timed out, PID: 1281395
[2022-06-07 09:39:37,811] {logging_mixin.py:109} INFO - [2022-06-07 09:39:37,810] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1281395
[2022-06-07 09:39:37,811] {logging_mixin.py:109} INFO - [2022-06-07 09:39:37,811] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:39:37,811] {logging_mixin.py:109} INFO - [2022-06-07 09:39:37,811] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1281395

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:39:37,812] {logging_mixin.py:109} INFO - [2022-06-07 09:39:37,811] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:39:37,812] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:39:37,824] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.033 seconds
[2022-06-07 09:40:08,731] {processor.py:163} INFO - Started process (PID=1282489) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:40:08,731] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:40:08,731] {logging_mixin.py:109} INFO - [2022-06-07 09:40:08,731] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:40:38,758] {logging_mixin.py:109} INFO - [2022-06-07 09:40:38,758] {timeout.py:36} ERROR - Process timed out, PID: 1282489
[2022-06-07 09:40:38,759] {logging_mixin.py:109} INFO - [2022-06-07 09:40:38,758] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1282489
[2022-06-07 09:40:38,759] {logging_mixin.py:109} INFO - [2022-06-07 09:40:38,759] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:40:38,759] {logging_mixin.py:109} INFO - [2022-06-07 09:40:38,759] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1282489

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:40:38,760] {logging_mixin.py:109} INFO - [2022-06-07 09:40:38,759] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:40:38,760] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:40:38,771] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.042 seconds
[2022-06-07 09:41:09,576] {processor.py:163} INFO - Started process (PID=1283584) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:41:09,577] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:41:09,577] {logging_mixin.py:109} INFO - [2022-06-07 09:41:09,577] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:41:39,579] {logging_mixin.py:109} INFO - [2022-06-07 09:41:39,579] {timeout.py:36} ERROR - Process timed out, PID: 1283584
[2022-06-07 09:41:39,580] {logging_mixin.py:109} INFO - [2022-06-07 09:41:39,579] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1283584
[2022-06-07 09:41:39,580] {logging_mixin.py:109} INFO - [2022-06-07 09:41:39,580] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:41:39,580] {logging_mixin.py:109} INFO - [2022-06-07 09:41:39,580] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1283584

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:41:39,581] {logging_mixin.py:109} INFO - [2022-06-07 09:41:39,580] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:41:39,581] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:41:39,592] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:42:10,404] {processor.py:163} INFO - Started process (PID=1284678) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:42:10,405] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:42:10,405] {logging_mixin.py:109} INFO - [2022-06-07 09:42:10,405] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:42:40,406] {logging_mixin.py:109} INFO - [2022-06-07 09:42:40,406] {timeout.py:36} ERROR - Process timed out, PID: 1284678
[2022-06-07 09:42:40,407] {logging_mixin.py:109} INFO - [2022-06-07 09:42:40,406] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1284678
[2022-06-07 09:42:40,407] {logging_mixin.py:109} INFO - [2022-06-07 09:42:40,407] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:42:40,407] {logging_mixin.py:109} INFO - [2022-06-07 09:42:40,407] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1284678

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:42:40,408] {logging_mixin.py:109} INFO - [2022-06-07 09:42:40,407] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:42:40,408] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:42:40,419] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 09:43:10,655] {processor.py:163} INFO - Started process (PID=1285772) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:43:10,655] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:43:10,656] {logging_mixin.py:109} INFO - [2022-06-07 09:43:10,656] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:43:40,667] {logging_mixin.py:109} INFO - [2022-06-07 09:43:40,666] {timeout.py:36} ERROR - Process timed out, PID: 1285772
[2022-06-07 09:43:40,667] {logging_mixin.py:109} INFO - [2022-06-07 09:43:40,667] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1285772
[2022-06-07 09:43:40,667] {logging_mixin.py:109} INFO - [2022-06-07 09:43:40,667] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:43:40,668] {logging_mixin.py:109} INFO - [2022-06-07 09:43:40,668] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1285772

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:43:40,668] {logging_mixin.py:109} INFO - [2022-06-07 09:43:40,668] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:43:40,668] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:43:40,679] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.026 seconds
[2022-06-07 09:44:11,402] {processor.py:163} INFO - Started process (PID=1286865) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:44:11,402] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:44:11,402] {logging_mixin.py:109} INFO - [2022-06-07 09:44:11,402] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:44:41,406] {logging_mixin.py:109} INFO - [2022-06-07 09:44:41,406] {timeout.py:36} ERROR - Process timed out, PID: 1286865
[2022-06-07 09:44:41,407] {logging_mixin.py:109} INFO - [2022-06-07 09:44:41,407] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1286865
[2022-06-07 09:44:41,407] {logging_mixin.py:109} INFO - [2022-06-07 09:44:41,407] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:44:41,408] {logging_mixin.py:109} INFO - [2022-06-07 09:44:41,407] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1286865

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:44:41,408] {logging_mixin.py:109} INFO - [2022-06-07 09:44:41,408] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:44:41,408] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:44:41,420] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 09:45:11,776] {processor.py:163} INFO - Started process (PID=1287959) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:45:11,776] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:45:11,776] {logging_mixin.py:109} INFO - [2022-06-07 09:45:11,776] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:45:41,777] {logging_mixin.py:109} INFO - [2022-06-07 09:45:41,777] {timeout.py:36} ERROR - Process timed out, PID: 1287959
[2022-06-07 09:45:41,778] {logging_mixin.py:109} INFO - [2022-06-07 09:45:41,777] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1287959
[2022-06-07 09:45:41,778] {logging_mixin.py:109} INFO - [2022-06-07 09:45:41,778] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:45:41,778] {logging_mixin.py:109} INFO - [2022-06-07 09:45:41,778] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1287959

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:45:41,779] {logging_mixin.py:109} INFO - [2022-06-07 09:45:41,779] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:45:41,779] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:45:41,791] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:46:12,554] {processor.py:163} INFO - Started process (PID=1289052) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:46:12,555] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:46:12,555] {logging_mixin.py:109} INFO - [2022-06-07 09:46:12,555] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:46:42,556] {logging_mixin.py:109} INFO - [2022-06-07 09:46:42,556] {timeout.py:36} ERROR - Process timed out, PID: 1289052
[2022-06-07 09:46:42,557] {logging_mixin.py:109} INFO - [2022-06-07 09:46:42,556] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1289052
[2022-06-07 09:46:42,557] {logging_mixin.py:109} INFO - [2022-06-07 09:46:42,557] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:46:42,558] {logging_mixin.py:109} INFO - [2022-06-07 09:46:42,557] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1289052

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:46:42,558] {logging_mixin.py:109} INFO - [2022-06-07 09:46:42,558] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:46:42,558] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:46:42,571] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:47:12,784] {processor.py:163} INFO - Started process (PID=1290145) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:47:12,784] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:47:12,785] {logging_mixin.py:109} INFO - [2022-06-07 09:47:12,785] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:47:42,789] {logging_mixin.py:109} INFO - [2022-06-07 09:47:42,789] {timeout.py:36} ERROR - Process timed out, PID: 1290145
[2022-06-07 09:47:42,790] {logging_mixin.py:109} INFO - [2022-06-07 09:47:42,789] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1290145
[2022-06-07 09:47:42,790] {logging_mixin.py:109} INFO - [2022-06-07 09:47:42,790] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:47:42,790] {logging_mixin.py:109} INFO - [2022-06-07 09:47:42,790] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1290145

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:47:42,791] {logging_mixin.py:109} INFO - [2022-06-07 09:47:42,791] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:47:42,791] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:47:42,802] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 09:48:12,980] {processor.py:163} INFO - Started process (PID=1291239) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:48:12,980] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:48:12,980] {logging_mixin.py:109} INFO - [2022-06-07 09:48:12,980] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:48:42,987] {logging_mixin.py:109} INFO - [2022-06-07 09:48:42,986] {timeout.py:36} ERROR - Process timed out, PID: 1291239
[2022-06-07 09:48:42,987] {logging_mixin.py:109} INFO - [2022-06-07 09:48:42,987] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1291239
[2022-06-07 09:48:42,987] {logging_mixin.py:109} INFO - [2022-06-07 09:48:42,987] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:48:42,988] {logging_mixin.py:109} INFO - [2022-06-07 09:48:42,987] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1291239

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:48:42,988] {logging_mixin.py:109} INFO - [2022-06-07 09:48:42,988] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:48:42,988] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:48:43,000] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 09:49:13,178] {processor.py:163} INFO - Started process (PID=1292333) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:49:13,179] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:49:13,179] {logging_mixin.py:109} INFO - [2022-06-07 09:49:13,179] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:49:43,180] {logging_mixin.py:109} INFO - [2022-06-07 09:49:43,180] {timeout.py:36} ERROR - Process timed out, PID: 1292333
[2022-06-07 09:49:43,181] {logging_mixin.py:109} INFO - [2022-06-07 09:49:43,180] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1292333
[2022-06-07 09:49:43,181] {logging_mixin.py:109} INFO - [2022-06-07 09:49:43,181] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:49:43,182] {logging_mixin.py:109} INFO - [2022-06-07 09:49:43,181] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1292333

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:49:43,182] {logging_mixin.py:109} INFO - [2022-06-07 09:49:43,182] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:49:43,182] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:49:43,194] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:50:13,904] {processor.py:163} INFO - Started process (PID=1293376) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:50:13,904] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:50:13,904] {logging_mixin.py:109} INFO - [2022-06-07 09:50:13,904] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:50:43,905] {logging_mixin.py:109} INFO - [2022-06-07 09:50:43,905] {timeout.py:36} ERROR - Process timed out, PID: 1293376
[2022-06-07 09:50:43,906] {logging_mixin.py:109} INFO - [2022-06-07 09:50:43,906] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1293376
[2022-06-07 09:50:43,906] {logging_mixin.py:109} INFO - [2022-06-07 09:50:43,906] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:50:43,907] {logging_mixin.py:109} INFO - [2022-06-07 09:50:43,906] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1293376

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:50:43,907] {logging_mixin.py:109} INFO - [2022-06-07 09:50:43,907] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:50:43,907] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:50:43,919] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:51:14,121] {processor.py:163} INFO - Started process (PID=1294417) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:51:14,122] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:51:14,122] {logging_mixin.py:109} INFO - [2022-06-07 09:51:14,122] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:51:44,123] {logging_mixin.py:109} INFO - [2022-06-07 09:51:44,123] {timeout.py:36} ERROR - Process timed out, PID: 1294417
[2022-06-07 09:51:44,124] {logging_mixin.py:109} INFO - [2022-06-07 09:51:44,123] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1294417
[2022-06-07 09:51:44,124] {logging_mixin.py:109} INFO - [2022-06-07 09:51:44,124] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:51:44,124] {logging_mixin.py:109} INFO - [2022-06-07 09:51:44,124] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1294417

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:51:44,125] {logging_mixin.py:109} INFO - [2022-06-07 09:51:44,125] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:51:44,125] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:51:44,137] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 09:52:14,705] {processor.py:163} INFO - Started process (PID=1295511) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:52:14,705] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:52:14,706] {logging_mixin.py:109} INFO - [2022-06-07 09:52:14,706] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:52:44,709] {logging_mixin.py:109} INFO - [2022-06-07 09:52:44,709] {timeout.py:36} ERROR - Process timed out, PID: 1295511
[2022-06-07 09:52:44,710] {logging_mixin.py:109} INFO - [2022-06-07 09:52:44,709] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1295511
[2022-06-07 09:52:44,710] {logging_mixin.py:109} INFO - [2022-06-07 09:52:44,710] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:52:44,711] {logging_mixin.py:109} INFO - [2022-06-07 09:52:44,710] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1295511

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:52:44,711] {logging_mixin.py:109} INFO - [2022-06-07 09:52:44,711] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:52:44,711] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:52:44,722] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 09:53:15,318] {processor.py:163} INFO - Started process (PID=1296604) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:53:15,319] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:53:15,319] {logging_mixin.py:109} INFO - [2022-06-07 09:53:15,319] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:53:45,320] {logging_mixin.py:109} INFO - [2022-06-07 09:53:45,320] {timeout.py:36} ERROR - Process timed out, PID: 1296604
[2022-06-07 09:53:45,321] {logging_mixin.py:109} INFO - [2022-06-07 09:53:45,320] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1296604
[2022-06-07 09:53:45,321] {logging_mixin.py:109} INFO - [2022-06-07 09:53:45,321] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:53:45,321] {logging_mixin.py:109} INFO - [2022-06-07 09:53:45,321] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1296604

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:53:45,322] {logging_mixin.py:109} INFO - [2022-06-07 09:53:45,321] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:53:45,322] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:53:45,334] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:54:15,870] {processor.py:163} INFO - Started process (PID=1297698) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:54:15,870] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:54:15,870] {logging_mixin.py:109} INFO - [2022-06-07 09:54:15,870] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:54:45,872] {logging_mixin.py:109} INFO - [2022-06-07 09:54:45,872] {timeout.py:36} ERROR - Process timed out, PID: 1297698
[2022-06-07 09:54:45,873] {logging_mixin.py:109} INFO - [2022-06-07 09:54:45,872] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1297698
[2022-06-07 09:54:45,873] {logging_mixin.py:109} INFO - [2022-06-07 09:54:45,873] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:54:45,873] {logging_mixin.py:109} INFO - [2022-06-07 09:54:45,873] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1297698

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:54:45,874] {logging_mixin.py:109} INFO - [2022-06-07 09:54:45,874] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:54:45,874] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:54:45,886] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:55:16,556] {processor.py:163} INFO - Started process (PID=1298792) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:55:16,557] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:55:16,557] {logging_mixin.py:109} INFO - [2022-06-07 09:55:16,557] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:55:46,558] {logging_mixin.py:109} INFO - [2022-06-07 09:55:46,558] {timeout.py:36} ERROR - Process timed out, PID: 1298792
[2022-06-07 09:55:46,559] {logging_mixin.py:109} INFO - [2022-06-07 09:55:46,558] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1298792
[2022-06-07 09:55:46,559] {logging_mixin.py:109} INFO - [2022-06-07 09:55:46,559] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:55:46,559] {logging_mixin.py:109} INFO - [2022-06-07 09:55:46,559] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1298792

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:55:46,560] {logging_mixin.py:109} INFO - [2022-06-07 09:55:46,559] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:55:46,560] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:55:46,573] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 09:56:16,909] {processor.py:163} INFO - Started process (PID=1299883) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:56:16,909] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:56:16,910] {logging_mixin.py:109} INFO - [2022-06-07 09:56:16,910] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:56:46,916] {logging_mixin.py:109} INFO - [2022-06-07 09:56:46,916] {timeout.py:36} ERROR - Process timed out, PID: 1299883
[2022-06-07 09:56:46,917] {logging_mixin.py:109} INFO - [2022-06-07 09:56:46,916] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1299883
[2022-06-07 09:56:46,917] {logging_mixin.py:109} INFO - [2022-06-07 09:56:46,917] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:56:46,917] {logging_mixin.py:109} INFO - [2022-06-07 09:56:46,917] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1299883

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:56:46,918] {logging_mixin.py:109} INFO - [2022-06-07 09:56:46,918] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:56:46,918] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:56:46,930] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 09:57:17,260] {processor.py:163} INFO - Started process (PID=1300976) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:57:17,260] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:57:17,261] {logging_mixin.py:109} INFO - [2022-06-07 09:57:17,260] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:57:47,273] {logging_mixin.py:109} INFO - [2022-06-07 09:57:47,273] {timeout.py:36} ERROR - Process timed out, PID: 1300976
[2022-06-07 09:57:47,274] {logging_mixin.py:109} INFO - [2022-06-07 09:57:47,273] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1300976
[2022-06-07 09:57:47,274] {logging_mixin.py:109} INFO - [2022-06-07 09:57:47,274] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:57:47,275] {logging_mixin.py:109} INFO - [2022-06-07 09:57:47,274] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1300976

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:57:47,275] {logging_mixin.py:109} INFO - [2022-06-07 09:57:47,275] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:57:47,275] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:57:47,286] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.028 seconds
[2022-06-07 09:58:17,683] {processor.py:163} INFO - Started process (PID=1302070) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:58:17,683] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:58:17,684] {logging_mixin.py:109} INFO - [2022-06-07 09:58:17,684] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:58:47,695] {logging_mixin.py:109} INFO - [2022-06-07 09:58:47,695] {timeout.py:36} ERROR - Process timed out, PID: 1302070
[2022-06-07 09:58:47,696] {logging_mixin.py:109} INFO - [2022-06-07 09:58:47,695] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1302070
[2022-06-07 09:58:47,696] {logging_mixin.py:109} INFO - [2022-06-07 09:58:47,696] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:58:47,697] {logging_mixin.py:109} INFO - [2022-06-07 09:58:47,696] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1302070

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:58:47,697] {logging_mixin.py:109} INFO - [2022-06-07 09:58:47,697] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:58:47,697] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:58:47,709] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.027 seconds
[2022-06-07 09:59:18,712] {processor.py:163} INFO - Started process (PID=1303165) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 09:59:18,712] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 09:59:18,713] {logging_mixin.py:109} INFO - [2022-06-07 09:59:18,713] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:59:48,715] {logging_mixin.py:109} INFO - [2022-06-07 09:59:48,715] {timeout.py:36} ERROR - Process timed out, PID: 1303165
[2022-06-07 09:59:48,716] {logging_mixin.py:109} INFO - [2022-06-07 09:59:48,716] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1303165
[2022-06-07 09:59:48,716] {logging_mixin.py:109} INFO - [2022-06-07 09:59:48,716] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 09:59:48,717] {logging_mixin.py:109} INFO - [2022-06-07 09:59:48,716] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1303165

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 09:59:48,717] {logging_mixin.py:109} INFO - [2022-06-07 09:59:48,717] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 09:59:48,717] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 09:59:48,728] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 10:00:19,233] {processor.py:163} INFO - Started process (PID=1304258) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:00:19,234] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:00:19,234] {logging_mixin.py:109} INFO - [2022-06-07 10:00:19,234] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:00:49,237] {logging_mixin.py:109} INFO - [2022-06-07 10:00:49,236] {timeout.py:36} ERROR - Process timed out, PID: 1304258
[2022-06-07 10:00:49,237] {logging_mixin.py:109} INFO - [2022-06-07 10:00:49,237] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1304258
[2022-06-07 10:00:49,237] {logging_mixin.py:109} INFO - [2022-06-07 10:00:49,237] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:00:49,238] {logging_mixin.py:109} INFO - [2022-06-07 10:00:49,237] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1304258

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:00:49,238] {logging_mixin.py:109} INFO - [2022-06-07 10:00:49,238] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:00:49,238] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:00:49,250] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 10:01:19,501] {processor.py:163} INFO - Started process (PID=1305352) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:01:19,501] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:01:19,502] {logging_mixin.py:109} INFO - [2022-06-07 10:01:19,501] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:01:49,506] {logging_mixin.py:109} INFO - [2022-06-07 10:01:49,505] {timeout.py:36} ERROR - Process timed out, PID: 1305352
[2022-06-07 10:01:49,506] {logging_mixin.py:109} INFO - [2022-06-07 10:01:49,506] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1305352
[2022-06-07 10:01:49,506] {logging_mixin.py:109} INFO - [2022-06-07 10:01:49,506] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:01:49,507] {logging_mixin.py:109} INFO - [2022-06-07 10:01:49,507] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1305352

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:01:49,507] {logging_mixin.py:109} INFO - [2022-06-07 10:01:49,507] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:01:49,508] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:01:49,520] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.021 seconds
[2022-06-07 10:02:19,815] {processor.py:163} INFO - Started process (PID=1306445) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:02:19,816] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:02:19,816] {logging_mixin.py:109} INFO - [2022-06-07 10:02:19,816] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:02:49,817] {logging_mixin.py:109} INFO - [2022-06-07 10:02:49,816] {timeout.py:36} ERROR - Process timed out, PID: 1306445
[2022-06-07 10:02:49,817] {logging_mixin.py:109} INFO - [2022-06-07 10:02:49,817] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1306445
[2022-06-07 10:02:49,818] {logging_mixin.py:109} INFO - [2022-06-07 10:02:49,817] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:02:49,818] {logging_mixin.py:109} INFO - [2022-06-07 10:02:49,818] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1306445

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:02:49,818] {logging_mixin.py:109} INFO - [2022-06-07 10:02:49,818] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:02:49,819] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:02:49,830] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 10:03:20,028] {processor.py:163} INFO - Started process (PID=1307539) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:03:20,029] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:03:20,029] {logging_mixin.py:109} INFO - [2022-06-07 10:03:20,029] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:03:50,031] {logging_mixin.py:109} INFO - [2022-06-07 10:03:50,030] {timeout.py:36} ERROR - Process timed out, PID: 1307539
[2022-06-07 10:03:50,031] {logging_mixin.py:109} INFO - [2022-06-07 10:03:50,031] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1307539
[2022-06-07 10:03:50,032] {logging_mixin.py:109} INFO - [2022-06-07 10:03:50,031] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:03:50,032] {logging_mixin.py:109} INFO - [2022-06-07 10:03:50,032] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1307539

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:03:50,032] {logging_mixin.py:109} INFO - [2022-06-07 10:03:50,032] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:03:50,033] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:03:50,045] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 10:04:20,328] {processor.py:163} INFO - Started process (PID=1308632) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:04:20,329] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:04:20,329] {logging_mixin.py:109} INFO - [2022-06-07 10:04:20,329] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:04:50,331] {logging_mixin.py:109} INFO - [2022-06-07 10:04:50,330] {timeout.py:36} ERROR - Process timed out, PID: 1308632
[2022-06-07 10:04:50,331] {logging_mixin.py:109} INFO - [2022-06-07 10:04:50,331] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1308632
[2022-06-07 10:04:50,331] {logging_mixin.py:109} INFO - [2022-06-07 10:04:50,331] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:04:50,332] {logging_mixin.py:109} INFO - [2022-06-07 10:04:50,331] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1308632

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:04:50,332] {logging_mixin.py:109} INFO - [2022-06-07 10:04:50,332] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:04:50,332] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:04:50,344] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 10:05:21,150] {processor.py:163} INFO - Started process (PID=1309725) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:05:21,151] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:05:21,151] {logging_mixin.py:109} INFO - [2022-06-07 10:05:21,151] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:05:51,152] {logging_mixin.py:109} INFO - [2022-06-07 10:05:51,151] {timeout.py:36} ERROR - Process timed out, PID: 1309725
[2022-06-07 10:05:51,152] {logging_mixin.py:109} INFO - [2022-06-07 10:05:51,152] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1309725
[2022-06-07 10:05:51,152] {logging_mixin.py:109} INFO - [2022-06-07 10:05:51,152] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:05:51,153] {logging_mixin.py:109} INFO - [2022-06-07 10:05:51,153] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1309725

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:05:51,153] {logging_mixin.py:109} INFO - [2022-06-07 10:05:51,153] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:05:51,154] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:05:51,165] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 10:06:21,507] {processor.py:163} INFO - Started process (PID=1310820) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:06:21,508] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:06:21,508] {logging_mixin.py:109} INFO - [2022-06-07 10:06:21,508] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:06:51,510] {logging_mixin.py:109} INFO - [2022-06-07 10:06:51,510] {timeout.py:36} ERROR - Process timed out, PID: 1310820
[2022-06-07 10:06:51,511] {logging_mixin.py:109} INFO - [2022-06-07 10:06:51,510] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1310820
[2022-06-07 10:06:51,511] {logging_mixin.py:109} INFO - [2022-06-07 10:06:51,511] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:06:51,512] {logging_mixin.py:109} INFO - [2022-06-07 10:06:51,511] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1310820

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:06:51,512] {logging_mixin.py:109} INFO - [2022-06-07 10:06:51,512] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:06:51,512] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:06:51,525] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 10:07:21,840] {processor.py:163} INFO - Started process (PID=1311913) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:07:21,841] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:07:21,841] {logging_mixin.py:109} INFO - [2022-06-07 10:07:21,841] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:07:51,842] {logging_mixin.py:109} INFO - [2022-06-07 10:07:51,842] {timeout.py:36} ERROR - Process timed out, PID: 1311913
[2022-06-07 10:07:51,843] {logging_mixin.py:109} INFO - [2022-06-07 10:07:51,842] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1311913
[2022-06-07 10:07:51,843] {logging_mixin.py:109} INFO - [2022-06-07 10:07:51,843] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:07:51,843] {logging_mixin.py:109} INFO - [2022-06-07 10:07:51,843] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1311913

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:07:51,844] {logging_mixin.py:109} INFO - [2022-06-07 10:07:51,843] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:07:51,844] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:07:51,856] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 10:08:21,896] {processor.py:163} INFO - Started process (PID=1312975) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:08:21,896] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:08:21,897] {logging_mixin.py:109} INFO - [2022-06-07 10:08:21,897] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:08:51,898] {logging_mixin.py:109} INFO - [2022-06-07 10:08:51,897] {timeout.py:36} ERROR - Process timed out, PID: 1312975
[2022-06-07 10:08:51,898] {logging_mixin.py:109} INFO - [2022-06-07 10:08:51,898] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1312975
[2022-06-07 10:08:51,898] {logging_mixin.py:109} INFO - [2022-06-07 10:08:51,898] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:08:51,899] {logging_mixin.py:109} INFO - [2022-06-07 10:08:51,898] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1312975

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:08:51,899] {logging_mixin.py:109} INFO - [2022-06-07 10:08:51,899] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:08:51,900] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:08:51,913] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.019 seconds
[2022-06-07 10:09:21,941] {processor.py:163} INFO - Started process (PID=1314037) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:09:21,941] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:09:21,941] {logging_mixin.py:109} INFO - [2022-06-07 10:09:21,941] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:09:51,963] {logging_mixin.py:109} INFO - [2022-06-07 10:09:51,963] {timeout.py:36} ERROR - Process timed out, PID: 1314037
[2022-06-07 10:09:51,964] {logging_mixin.py:109} INFO - [2022-06-07 10:09:51,963] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1314037
[2022-06-07 10:09:51,964] {logging_mixin.py:109} INFO - [2022-06-07 10:09:51,964] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:09:51,965] {logging_mixin.py:109} INFO - [2022-06-07 10:09:51,964] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1314037

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:09:51,965] {logging_mixin.py:109} INFO - [2022-06-07 10:09:51,965] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:09:51,965] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:09:51,976] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.037 seconds
[2022-06-07 10:10:22,442] {processor.py:163} INFO - Started process (PID=1315131) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:10:22,443] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:10:22,443] {logging_mixin.py:109} INFO - [2022-06-07 10:10:22,443] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:10:52,447] {logging_mixin.py:109} INFO - [2022-06-07 10:10:52,446] {timeout.py:36} ERROR - Process timed out, PID: 1315131
[2022-06-07 10:10:52,447] {logging_mixin.py:109} INFO - [2022-06-07 10:10:52,447] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1315131
[2022-06-07 10:10:52,448] {logging_mixin.py:109} INFO - [2022-06-07 10:10:52,447] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:10:52,448] {logging_mixin.py:109} INFO - [2022-06-07 10:10:52,448] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1315131

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:10:52,448] {logging_mixin.py:109} INFO - [2022-06-07 10:10:52,448] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:10:52,449] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:10:52,460] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 10:11:23,440] {processor.py:163} INFO - Started process (PID=1316224) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:11:23,440] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:11:23,440] {logging_mixin.py:109} INFO - [2022-06-07 10:11:23,440] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:11:53,443] {logging_mixin.py:109} INFO - [2022-06-07 10:11:53,442] {timeout.py:36} ERROR - Process timed out, PID: 1316224
[2022-06-07 10:11:53,443] {logging_mixin.py:109} INFO - [2022-06-07 10:11:53,443] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1316224
[2022-06-07 10:11:53,444] {logging_mixin.py:109} INFO - [2022-06-07 10:11:53,443] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:11:53,444] {logging_mixin.py:109} INFO - [2022-06-07 10:11:53,444] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1316224

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:11:53,444] {logging_mixin.py:109} INFO - [2022-06-07 10:11:53,444] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:11:53,445] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:11:53,455] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 10:12:23,904] {processor.py:163} INFO - Started process (PID=1317319) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:12:23,904] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:12:23,905] {logging_mixin.py:109} INFO - [2022-06-07 10:12:23,905] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:12:53,911] {logging_mixin.py:109} INFO - [2022-06-07 10:12:53,910] {timeout.py:36} ERROR - Process timed out, PID: 1317319
[2022-06-07 10:12:53,912] {logging_mixin.py:109} INFO - [2022-06-07 10:12:53,911] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1317319
[2022-06-07 10:12:53,912] {logging_mixin.py:109} INFO - [2022-06-07 10:12:53,912] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:12:53,912] {logging_mixin.py:109} INFO - [2022-06-07 10:12:53,912] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1317319

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:12:53,913] {logging_mixin.py:109} INFO - [2022-06-07 10:12:53,912] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:12:53,913] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:12:53,925] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.023 seconds
[2022-06-07 10:13:24,244] {processor.py:163} INFO - Started process (PID=1318415) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:13:24,244] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:13:24,245] {logging_mixin.py:109} INFO - [2022-06-07 10:13:24,244] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:13:54,261] {logging_mixin.py:109} INFO - [2022-06-07 10:13:54,260] {timeout.py:36} ERROR - Process timed out, PID: 1318415
[2022-06-07 10:13:54,261] {logging_mixin.py:109} INFO - [2022-06-07 10:13:54,261] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1318415
[2022-06-07 10:13:54,261] {logging_mixin.py:109} INFO - [2022-06-07 10:13:54,261] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:13:54,262] {logging_mixin.py:109} INFO - [2022-06-07 10:13:54,261] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1318415

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:13:54,262] {logging_mixin.py:109} INFO - [2022-06-07 10:13:54,262] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:13:54,262] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:13:54,274] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.032 seconds
[2022-06-07 10:14:24,518] {processor.py:163} INFO - Started process (PID=1319511) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:14:24,518] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:14:24,518] {logging_mixin.py:109} INFO - [2022-06-07 10:14:24,518] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:14:54,519] {logging_mixin.py:109} INFO - [2022-06-07 10:14:54,519] {timeout.py:36} ERROR - Process timed out, PID: 1319511
[2022-06-07 10:14:54,520] {logging_mixin.py:109} INFO - [2022-06-07 10:14:54,519] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1319511
[2022-06-07 10:14:54,520] {logging_mixin.py:109} INFO - [2022-06-07 10:14:54,520] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:14:54,521] {logging_mixin.py:109} INFO - [2022-06-07 10:14:54,520] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1319511

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:14:54,521] {logging_mixin.py:109} INFO - [2022-06-07 10:14:54,521] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:14:54,522] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:14:54,534] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 10:15:24,804] {processor.py:163} INFO - Started process (PID=1320607) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:15:24,805] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:15:24,805] {logging_mixin.py:109} INFO - [2022-06-07 10:15:24,805] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:15:54,812] {logging_mixin.py:109} INFO - [2022-06-07 10:15:54,812] {timeout.py:36} ERROR - Process timed out, PID: 1320607
[2022-06-07 10:15:54,813] {logging_mixin.py:109} INFO - [2022-06-07 10:15:54,813] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1320607
[2022-06-07 10:15:54,813] {logging_mixin.py:109} INFO - [2022-06-07 10:15:54,813] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:15:54,814] {logging_mixin.py:109} INFO - [2022-06-07 10:15:54,813] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1320607

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:15:54,814] {logging_mixin.py:109} INFO - [2022-06-07 10:15:54,814] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:15:54,814] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:15:54,827] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.025 seconds
[2022-06-07 10:16:25,056] {processor.py:163} INFO - Started process (PID=1321701) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:16:25,056] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:16:25,057] {logging_mixin.py:109} INFO - [2022-06-07 10:16:25,057] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:16:55,058] {logging_mixin.py:109} INFO - [2022-06-07 10:16:55,057] {timeout.py:36} ERROR - Process timed out, PID: 1321701
[2022-06-07 10:16:55,058] {logging_mixin.py:109} INFO - [2022-06-07 10:16:55,058] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1321701
[2022-06-07 10:16:55,058] {logging_mixin.py:109} INFO - [2022-06-07 10:16:55,058] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:16:55,059] {logging_mixin.py:109} INFO - [2022-06-07 10:16:55,058] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1321701

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:16:55,059] {logging_mixin.py:109} INFO - [2022-06-07 10:16:55,059] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:16:55,059] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:16:55,071] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 10:17:25,302] {processor.py:163} INFO - Started process (PID=1322794) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:17:25,303] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:17:25,303] {logging_mixin.py:109} INFO - [2022-06-07 10:17:25,303] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:17:55,304] {logging_mixin.py:109} INFO - [2022-06-07 10:17:55,304] {timeout.py:36} ERROR - Process timed out, PID: 1322794
[2022-06-07 10:17:55,305] {logging_mixin.py:109} INFO - [2022-06-07 10:17:55,304] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1322794
[2022-06-07 10:17:55,305] {logging_mixin.py:109} INFO - [2022-06-07 10:17:55,305] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:17:55,306] {logging_mixin.py:109} INFO - [2022-06-07 10:17:55,305] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1322794

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:17:55,306] {logging_mixin.py:109} INFO - [2022-06-07 10:17:55,306] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:17:55,306] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:17:55,317] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.016 seconds
[2022-06-07 10:18:25,507] {processor.py:163} INFO - Started process (PID=1323889) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:18:25,508] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:18:25,508] {logging_mixin.py:109} INFO - [2022-06-07 10:18:25,508] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:18:55,514] {logging_mixin.py:109} INFO - [2022-06-07 10:18:55,514] {timeout.py:36} ERROR - Process timed out, PID: 1323889
[2022-06-07 10:18:55,515] {logging_mixin.py:109} INFO - [2022-06-07 10:18:55,514] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1323889
[2022-06-07 10:18:55,515] {logging_mixin.py:109} INFO - [2022-06-07 10:18:55,515] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:18:55,515] {logging_mixin.py:109} INFO - [2022-06-07 10:18:55,515] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1323889

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:18:55,516] {logging_mixin.py:109} INFO - [2022-06-07 10:18:55,515] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:18:55,516] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:18:55,528] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.022 seconds
[2022-06-07 10:19:25,551] {processor.py:163} INFO - Started process (PID=1324983) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:19:25,552] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:19:25,552] {logging_mixin.py:109} INFO - [2022-06-07 10:19:25,552] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:19:55,554] {logging_mixin.py:109} INFO - [2022-06-07 10:19:55,553] {timeout.py:36} ERROR - Process timed out, PID: 1324983
[2022-06-07 10:19:55,554] {logging_mixin.py:109} INFO - [2022-06-07 10:19:55,554] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1324983
[2022-06-07 10:19:55,555] {logging_mixin.py:109} INFO - [2022-06-07 10:19:55,555] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:19:55,555] {logging_mixin.py:109} INFO - [2022-06-07 10:19:55,555] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1324983

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:19:55,555] {logging_mixin.py:109} INFO - [2022-06-07 10:19:55,555] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:19:55,556] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:19:55,567] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.017 seconds
[2022-06-07 10:20:25,918] {processor.py:163} INFO - Started process (PID=1326077) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:20:25,918] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:20:25,919] {logging_mixin.py:109} INFO - [2022-06-07 10:20:25,918] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:20:55,923] {logging_mixin.py:109} INFO - [2022-06-07 10:20:55,923] {timeout.py:36} ERROR - Process timed out, PID: 1326077
[2022-06-07 10:20:55,924] {logging_mixin.py:109} INFO - [2022-06-07 10:20:55,923] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1326077
[2022-06-07 10:20:55,924] {logging_mixin.py:109} INFO - [2022-06-07 10:20:55,924] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:20:55,924] {logging_mixin.py:109} INFO - [2022-06-07 10:20:55,924] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1326077

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:20:55,924] {logging_mixin.py:109} INFO - [2022-06-07 10:20:55,924] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:20:55,925] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:20:55,936] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.020 seconds
[2022-06-07 10:21:26,252] {processor.py:163} INFO - Started process (PID=1327170) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:21:26,252] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:21:26,252] {logging_mixin.py:109} INFO - [2022-06-07 10:21:26,252] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:21:56,254] {logging_mixin.py:109} INFO - [2022-06-07 10:21:56,254] {timeout.py:36} ERROR - Process timed out, PID: 1327170
[2022-06-07 10:21:56,255] {logging_mixin.py:109} INFO - [2022-06-07 10:21:56,254] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1327170
[2022-06-07 10:21:56,255] {logging_mixin.py:109} INFO - [2022-06-07 10:21:56,255] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:21:56,255] {logging_mixin.py:109} INFO - [2022-06-07 10:21:56,255] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1327170

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:21:56,256] {logging_mixin.py:109} INFO - [2022-06-07 10:21:56,255] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:21:56,256] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:21:56,268] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.018 seconds
[2022-06-07 10:22:26,658] {processor.py:163} INFO - Started process (PID=1328264) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:22:26,659] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:22:26,659] {logging_mixin.py:109} INFO - [2022-06-07 10:22:26,659] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:22:56,667] {logging_mixin.py:109} INFO - [2022-06-07 10:22:56,666] {timeout.py:36} ERROR - Process timed out, PID: 1328264
[2022-06-07 10:22:56,667] {logging_mixin.py:109} INFO - [2022-06-07 10:22:56,667] {clientserver.py:502} INFO - Error while receiving.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1328264
[2022-06-07 10:22:56,667] {logging_mixin.py:109} INFO - [2022-06-07 10:22:56,667] {clientserver.py:507} INFO - Closing down clientserver connection
[2022-06-07 10:22:56,668] {logging_mixin.py:109} INFO - [2022-06-07 10:22:56,667] {java_gateway.py:1055} ERROR - Exception while sending command.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 475, in send_command
    answer = smart_decode(self.stream.readline()[:-1])
  File "/usr/local/lib/python3.9/socket.py", line 704, in readinto
    return self._sock.recv_into(b)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/timeout.py", line 37, in handle_timeout
    raise AirflowTaskTimeout(self.error_message)
airflow.exceptions.AirflowTaskTimeout: DagBag import timeout for /opt/airflow/dags/spark_dag.py after 30.0s.
Please take a look at these docs to improve your DAG import time:
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#top-level-python-code
* https://airflow.apache.org/docs/apache-airflow/2.2.5/best-practices.html#reducing-dag-complexity, PID: 1328264

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1038, in send_command
    response = connection.send_command(command)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/clientserver.py", line 503, in send_command
    raise Py4JNetworkError(
py4j.protocol.Py4JNetworkError: Error while sending or receiving
[2022-06-07 10:22:56,668] {logging_mixin.py:109} INFO - [2022-06-07 10:22:56,668] {dagbag.py:334} ERROR - Failed to import: /opt/airflow/dags/spark_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dagbag.py", line 331, in _load_modules_from_file
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/opt/airflow/dags/spark_dag.py", line 31, in <module>
    session = create_spark_session(spark_master)
  File "/opt/airflow/dags/spark_funcs.py", line 9, in create_spark_session
    spark = SparkSession \
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/sql/session.py", line 228, in getOrCreate
    sc = SparkContext.getOrCreate(sparkConf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 392, in getOrCreate
    SparkContext(conf=conf or SparkConf())
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 146, in __init__
    self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 209, in _do_init
    self._jsc = jsc or self._initialize_context(self._conf._jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/pyspark/context.py", line 329, in _initialize_context
    return self._jvm.JavaSparkContext(jconf)
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/java_gateway.py", line 1585, in __call__
    return_value = get_return_value(
  File "/home/airflow/.local/lib/python3.9/site-packages/py4j/protocol.py", line 334, in get_return_value
    raise Py4JError(
py4j.protocol.Py4JError: An error occurred while calling None.org.apache.spark.api.java.JavaSparkContext
[2022-06-07 10:22:56,669] {processor.py:654} WARNING - No viable dags retrieved from /opt/airflow/dags/spark_dag.py
[2022-06-07 10:22:56,681] {processor.py:171} INFO - Processing /opt/airflow/dags/spark_dag.py took 30.024 seconds
[2022-06-07 10:23:26,975] {processor.py:163} INFO - Started process (PID=1329358) to work on /opt/airflow/dags/spark_dag.py
[2022-06-07 10:23:26,975] {processor.py:642} INFO - Processing file /opt/airflow/dags/spark_dag.py for tasks to queue
[2022-06-07 10:23:26,976] {logging_mixin.py:109} INFO - [2022-06-07 10:23:26,976] {dagbag.py:500} INFO - Filling up the DagBag from /opt/airflow/dags/spark_dag.py
